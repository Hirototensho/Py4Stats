[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Py4Stats",
    "section": "",
    "text": "Readme\nPy4Stats は、主に実証研究で用いられる、探索的データ分析および回帰結果レポート用のユーティリティライブラリです。回帰分析を中心とする分析でよく使われるR言語の機能を Python で実装しています。\n本ライブラリの主な機能は Get Started を、実装されている関数の一覧は Function reference を参照してください。",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Readme</span>"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Py4Stats",
    "section": "Installation",
    "text": "Installation\nuv をお使いの場合、次のコードで py4stats をインストールできます。\n! uv add git+https://github.com/Hirototensho/py4stats.git\n一方で、pip をお使いの場合には、次のコードで py4stats をインストールできます。\n! pip install git+https://github.com/Hirototensho/py4stats.git",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Readme</span>"
    ]
  },
  {
    "objectID": "index.html#使用例-example",
    "href": "index.html#使用例-example",
    "title": "Py4Stats",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\npy4stats.diagnose() 関数はデータの全般的な状態についての要約を提供します。\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込み\n\nprint(py4st.diagnose(penguins).round(4))\n#&gt;              columns    dtype  missing_count  missing_percent  unique_count  unique_rate\n#&gt; 0            species   object              0           0.0000             3       0.8721\n#&gt; 1             island   object              0           0.0000             3       0.8721\n#&gt; 2     bill_length_mm  float64              2           0.5814           165      47.9651\n#&gt; 3      bill_depth_mm  float64              2           0.5814            81      23.5465\n#&gt; 4  flipper_length_mm  float64              2           0.5814            56      16.2791\n#&gt; 5        body_mass_g  float64              2           0.5814            95      27.6163\n#&gt; 6                sex   object             11           3.1977             3       0.8721\n#&gt; 7               year    int64              0           0.0000             3       0.8721\npy4stats.compare_ols() 関数は、計量経済学の実証論文でよく用いられる、回帰分析の結果を列方向に並べて比較する表を作成します。\nimport statsmodels.formula.api as smf\n\n# 回帰分析の実行\nfit1 = smf.ols('body_mass_g ~ bill_length_mm + species', data = penguins).fit()\nfit2 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species', data = penguins).fit()\nfit3 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex', data = penguins).fit()\n\ncompare_tab1 = py4st.compare_ols(list_models = [fit1, fit2, fit3]) # 表の作成\ncompare_tab1\n\n\n\n\n\n\n\n\n\nterm\nmodel 1\nmodel 2\nmodel 3\n\n\n\n\nIntercept\n153.7397\n-1,742.7202 ***\n843.9812 **\n\n\n\n(268.9012)\n(313.7697)\n(403.5956)\n\n\nspecies[T.Chinstrap]\n-885.8121 ***\n-539.6864 ***\n-245.1516 ***\n\n\n\n(88.2502)\n(86.9425)\n(84.5952)\n\n\nspecies[T.Gentoo]\n578.6292 ***\n1,492.8283 ***\n1,443.3525 ***\n\n\n\n(75.3623)\n(118.4442)\n(107.7844)\n\n\nbill_length_mm\n91.4358 ***\n55.6461 ***\n26.5366 ***\n\n\n\n(6.8871)\n(7.2326)\n(7.2436)\n\n\nbill_depth_mm\n\n179.0434 ***\n87.9328 ***\n\n\n\n\n(19.0997)\n(20.2192)\n\n\nsex[T.male]\n\n\n437.2007 ***\n\n\n\n\n\n(49.1098)\n\n\nrsquared_adj\n0.7810\n0.8258\n0.8613\n\n\nnobs\n342\n342\n333\n\n\ndf\n3\n4\n5\n\n\n\n詳細は、py4stats.compare_ols() を参照してください。　\n\nJump to Get Started.\nJump to Function reference.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Readme</span>"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction to Py4Stats",
    "section": "",
    "text": "py4stats.eda_tools\nここでは Py4Stats の主な機能を紹介します。実装されている関数の一覧は Function reference を参照してください。\n探索的データ解析と前処理に関する機能を提供するモジュールです。このモジュールは、複数の DataFrame バックエンドに対して共通の API を提供することを目的として、narwhals ライブラリを用いて実装されています。詳細は Technical Notes: py4stats.eda_tools における narwhals ベースの実装 を参照してください。\npy4stats.diagnose()：R言語のdlookr::diagnose()を再現した関数で、データの全般的な状態についての要約を提供します。\npy4stats.tabyl()：R言語の janitor::tabyl()を参考にした、クロス集計表を作成する関数です。\npy4stats.freq_table()：R言語のDescTools::Freq()をオマージュした、1変数の度数分布表を計算する関数。度数 freq と相対度数 perc に加えて、それぞれの累積値を計算します。\n引数 group を指定すると、グループ別の度数分布表を計算できます。\npy4stats.remove_empty()：完全に空白な列や行の削除する関数。R言語の janitor::remove_empty() をオマージュした関数で、全ての要素が NaN である列や行をデータフレームから除外します。\npy4stats.remove_constant()：定数列の削除。R言語の janitor::remove_constant() をオマージュした関数で、1種類だけの要素からなる列をデータフレームから除外します。\npy4stats.filtering_out()：列名に特定の文字列を含む列や、特定の文字列で始まる/終わる列を除外します。実装の一部はR言語の dplyr::select() を参考にしました。\npy4stats.review_wrangling():データ前処理（wrangling）による変更点をレビュー形式で要約して、文字列として出力する関数です。データフレームの形状（行数・列数）の変化に加えて、データ型（dtype）の変化欠測値やカテゴリー変数における水準の増減を報告します。",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to Py4Stats</span>"
    ]
  },
  {
    "objectID": "introduction.html#py4stats.eda_tools",
    "href": "introduction.html#py4stats.eda_tools",
    "title": "Introduction to Py4Stats",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込み\n\nprint(py4st.diagnose(penguins).round(4))\n#&gt;                      dtype  missing_count  missing_percent  unique_count  unique_rate\n#&gt; species             object              0           0.0000             3       0.8721\n#&gt; island              object              0           0.0000             3       0.8721\n#&gt; bill_length_mm     float64              2           0.5814           164      47.6744\n#&gt; bill_depth_mm      float64              2           0.5814            80      23.2558\n#&gt; flipper_length_mm  float64              2           0.5814            55      15.9884\n#&gt; body_mass_g        float64              2           0.5814            94      27.3256\n#&gt; sex                 object             11           3.1977             2       0.5814\n#&gt; year                 int64              0           0.0000             3       0.8721\n\nprint(py4st.tabyl(penguins, 'island', 'species'))\n#&gt; species         Adelie   Chinstrap       Gentoo  All\n#&gt; island                                              \n#&gt; Biscoe      44 (26.2%)    0 (0.0%)  124 (73.8%)  168\n#&gt; Dream       56 (45.2%)  68 (54.8%)     0 (0.0%)  124\n#&gt; Torgersen  52 (100.0%)    0 (0.0%)     0 (0.0%)   52\n#&gt; All        152 (44.2%)  68 (19.8%)  124 (36.0%)  344\n\nprint(py4st.freq_table(penguins, 'species'))\n#&gt;            freq      perc  cumfreq   cumperc\n#&gt; species                                     \n#&gt; Adelie      152  0.441860      152  0.441860\n#&gt; Gentoo      124  0.360465      276  0.802326\n#&gt; Chinstrap    68  0.197674      344  1.000000\n\npenguins2 = penguins.assign(bill_length_mm2 = pd.cut(penguins['bill_length_mm'], 6))\n\nprint(\n    py4st.freq_table(penguins2, ['species', 'bill_length_mm2'], sort = False)\n    )\n#&gt;                             freq      perc  cumfreq   cumperc\n#&gt; species   bill_length_mm2\n#&gt; Adelie    (32.072, 38.975]    79  0.523179       79  0.523179\n#&gt;           (38.975, 45.85]     71  0.470199      150  0.993377\n#&gt;           (45.85, 52.725]      1  0.006623      151  1.000000\n#&gt;           (52.725, 59.6]       0  0.000000      151  1.000000\n#&gt; Chinstrap (32.072, 38.975]     0  0.000000        0  0.000000\n#&gt;           (38.975, 45.85]     13  0.191176       13  0.191176\n#&gt;           (45.85, 52.725]     50  0.735294       63  0.926471\n#&gt;           (52.725, 59.6]       5  0.073529       68  1.000000\n#&gt; Gentoo    (32.072, 38.975]     0  0.000000        0  0.000000\n#&gt;           (38.975, 45.85]     40  0.325203       40  0.325203\n#&gt;           (45.85, 52.725]     78  0.634146      118  0.959350\n#&gt;           (52.725, 59.6]       5  0.040650      123  1.000000\n\npenguins2 = penguins.loc[:, ['species', 'body_mass_g']].copy()\npenguins2.loc[:, 'empty'] = np.nan\npenguins2.loc[344, :] = np.nan\n\nprint(penguins2.tail(3))\n#&gt;        species  body_mass_g  empty\n#&gt; 342  Chinstrap       4100.0    NaN\n#&gt; 343  Chinstrap       3775.0    NaN\n#&gt; 344        NaN          NaN    NaN\n\n# 完全に空白な行と列を削除。\nprint(py4st.remove_empty(penguins2, quiet = False).tail(3))\n#&gt; Removing 1 empty column(s) out of 3 columns(Removed: empty).\n#&gt; Removing 1 empty row(s) out of 345 rows(Removed: 344). \n#&gt;        species  body_mass_g\n#&gt; 341  Chinstrap       3775.0\n#&gt; 342  Chinstrap       4100.0\n#&gt; 343  Chinstrap       3775.0\n\n# 完全に空白な列のみ削除。\nprint(py4st.remove_empty(penguins2, rows = False, quiet = False).tail(3))\n#&gt; Removing 1 empty column(s) out of 3 columns(Removed: empty).\n#&gt;        species  body_mass_g\n#&gt; 342  Chinstrap       4100.0\n#&gt; 343  Chinstrap       3775.0\n#&gt; 344        NaN          NaN\n\n# 完全に空白な行のみ削除。\nprint(py4st.remove_empty(penguins2, cols = False, quiet = False).tail(3))\n#&gt; Removing 1 empty row(s) out of 345 rows(Removed: 344). \n#&gt;        species  body_mass_g  empty\n#&gt; 341  Chinstrap       3775.0    NaN\n#&gt; 342  Chinstrap       4100.0    NaN\n#&gt; 343  Chinstrap       3775.0    NaN\n\npenguins2 = penguins.loc[:, ['species', 'body_mass_g']].copy()\npenguins2.loc[:, 'constant'] = 'c'\n\nprint(penguins2.head(3))\n#&gt;   species  body_mass_g constant\n#&gt; 0  Adelie       3750.0        c\n#&gt; 1  Adelie       3800.0        c\n#&gt; 2  Adelie       3250.0        c\n\nprint(py4st.remove_constant(penguins2, quiet = False).head(3))\n#&gt; Removing 1 constant column(s) out of 3 column(s)(Removed: constant). \n#&gt;   species  body_mass_g\n#&gt; 0  Adelie       3750.0\n#&gt; 1  Adelie       3800.0\n#&gt; 2  Adelie       3250.0\n\n# 列名に 'length' を含む列を除外\nprint(py4st.filtering_out(penguins, contains = 'length').head(3))\n#&gt;   species     island  bill_depth_mm  body_mass_g     sex  year  female\n#&gt; 0  Adelie  Torgersen           18.7       3750.0    male  2007       0\n#&gt; 1  Adelie  Torgersen           17.4       3800.0  female  2007       1\n#&gt; 2  Adelie  Torgersen           18.0       3250.0  female  2007       1\n\n# 列名が 'bill' から始まる列を除外\nprint(py4st.filtering_out(penguins, starts_with = 'bill').head(3))\n#&gt;   species     island  flipper_length_mm  body_mass_g     sex  year  female\n#&gt; 0  Adelie  Torgersen              181.0       3750.0    male  2007       0\n#&gt; 1  Adelie  Torgersen              186.0       3800.0  female  2007       1\n#&gt; 2  Adelie  Torgersen              195.0       3250.0  female  2007       1\n\n# 列名が '_mm' で終わる列を除外\nprint(py4st.filtering_out(penguins, ends_with = '_mm').head(3))\n#&gt;   species     island  body_mass_g     sex  year  female\n#&gt; 0  Adelie  Torgersen       3750.0    male  2007       0\n#&gt; 1  Adelie  Torgersen       3800.0  female  2007       1\n#&gt; 2  Adelie  Torgersen       3250.0  female  2007       1\n\ngentoo = penguins.query(\"species == 'Gentoo'\")\nprint(py4st.review_wrangling(penguins, gentoo))\n#&gt; ========================= Review of wrangling ==========================\n#&gt; The shape of DataFrame:\n#&gt;    Rows: before 344 -&gt; after 124 (-220)\n#&gt;    Cols: before   8 -&gt; after   8 (No change)\n#&gt; \n#&gt; No columns were added or removed.\n#&gt; \n#&gt; No existing columns had their type changed.\n#&gt; \n#&gt; Increase in missing values:\n#&gt;   bill_length_mm     before  2 (0.58%) -&gt; after  1 (0.81%)\n#&gt;   bill_depth_mm      before  2 (0.58%) -&gt; after  1 (0.81%)\n#&gt;   flipper_length_mm  before  2 (0.58%) -&gt; after  1 (0.81%)\n#&gt;   body_mass_g        before  2 (0.58%) -&gt; after  1 (0.81%)\n#&gt;   sex                before 11 (3.20%) -&gt; after  5 (4.03%)\n#&gt; \n#&gt; None of the existing columns decreases in the number of missing values.\n#&gt; \n#&gt; The following columns show changes in categories:\n#&gt;   species:\n#&gt;     addition:  None\n#&gt;     removal:  'Adelie' and 'Chinstrap'\n#&gt;   island:\n#&gt;     addition:  None\n#&gt;     removal:  'Torgersen' and 'Dream'\n#&gt; ========================================================================",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to Py4Stats</span>"
    ]
  },
  {
    "objectID": "introduction.html#py4stats.regression_tools",
    "href": "introduction.html#py4stats.regression_tools",
    "title": "Introduction to Py4Stats",
    "section": "py4stats.regression_tools",
    "text": "py4stats.regression_tools\n　py4stats.regression_tools は statsmodelsライブラリで作成された回帰分析の結果についての表作成と可視化を補助する機能を提供するモジュールです。\n　py4stats.compare_ols() ：計量経済学の実証論文でよく用いられる、回帰分析の結果を列方向に並べて比較する表を作成します。表のフォーマットについてはR言語のtexreg::screenreg()やmodelsummary::modelsummary()を参考にしています。同種の機能を提供する Python ライブラリーとしては、R言語の stargazer パッケージをもとにした stargazer ライブラリがあります。\nimport statsmodels.formula.api as smf\n\n# 回帰分析の実行\nfit1 = smf.ols('body_mass_g ~ bill_length_mm + species', data = penguins).fit()\nfit2 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species', data = penguins).fit()\nfit3 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex', data = penguins).fit()\n\ncompare_tab1 = py4st.compare_ols(list_models = [fit1, fit2, fit3]) # 表の作成\ncompare_tab1\n\n\n\n\n\n\n\n\n\nterm\nmodel 1\nmodel 2\nmodel 3\n\n\n\n\nIntercept\n153.7397\n-1,742.7202 ***\n843.9812 **\n\n\n\n(268.9012)\n(313.7697)\n(403.5956)\n\n\nspecies[T.Chinstrap]\n-885.8121 ***\n-539.6864 ***\n-245.1516 ***\n\n\n\n(88.2502)\n(86.9425)\n(84.5952)\n\n\nspecies[T.Gentoo]\n578.6292 ***\n1,492.8283 ***\n1,443.3525 ***\n\n\n\n(75.3623)\n(118.4442)\n(107.7844)\n\n\nbill_length_mm\n91.4358 ***\n55.6461 ***\n26.5366 ***\n\n\n\n(6.8871)\n(7.2326)\n(7.2436)\n\n\nbill_depth_mm\n\n179.0434 ***\n87.9328 ***\n\n\n\n\n(19.0997)\n(20.2192)\n\n\nsex[T.male]\n\n\n437.2007 ***\n\n\n\n\n\n(49.1098)\n\n\nrsquared_adj\n0.7810\n0.8258\n0.8613\n\n\nnobs\n342\n342\n333\n\n\ndf\n3\n4\n5\n\n\n\npy4stats.compare_ols() の実行結果は Pandas の DataFrame として出力されるため、.xlsx. ファイルなどに変換することができます。また、用途に応じて表の体裁を調整できるようにしています。詳細については 「回帰分析の比較」 を参照してください。\ncompare_tab2 = py4st.compare_ols(\n    list_models = [fit1, fit2, fit3],\n    model_name = ['基本モデル', '嘴の高さ追加', '性別追加'], # モデル名を変更\n    stats = 'p_value',        # () 内の値をP-値に変更する\n    add_stars = False,        # 有意性のアスタリスクなし\n    table_style = 'one_line', # 表スタイルを1行表示に設定 'one' でも可能\n    digits = 3                # 小数点以下の桁数を3に設定\n    )\ncompare_tab2\n\n\n\n\n\n\n\n\n\nterm\n基本モデル\n嘴の高さ追加\n性別追加\n\n\n\n\nIntercept\n153.740(0.568)\n-1,742.720(0.000)\n843.981(0.037)\n\n\nspecies[T.Chinstrap]\n-885.812(0.000)\n-539.686(0.000)\n-245.152(0.004)\n\n\nspecies[T.Gentoo]\n578.629(0.000)\n1,492.828(0.000)\n1,443.353(0.000)\n\n\nbill_length_mm\n91.436(0.000)\n55.646(0.000)\n26.537(0.000)\n\n\nbill_depth_mm\n\n179.043(0.000)\n87.933(0.000)\n\n\nsex[T.male]\n\n\n437.201(0.000)\n\n\nrsquared_adj\n0.781\n0.826\n0.861\n\n\nnobs\n342\n342\n333\n\n\ndf\n3\n4\n5\n\n\n\npy4stats.coefplot()：回帰係数の可視化。R言語の coefplot::coefplot() を参考にしました。\nimport matplotlib.pyplot as plt\npy4st.coefplot(fit3)\n\n\n\ncoefplot1\n\n\nplt.rcParams[\"figure.autolayout\"] = True\n\nfig, ax = plt.subplots(1, 2, figsize = (2.2 * 5, 5), dpi = 100)\n\npy4st.coefplot(fit2, ax = ax[0])\nax[0].set_xlim(-900, 1800)\n\npy4st.coefplot(fit3, ax = ax[1], palette = ['#FF6F91', '#F2E5EB'])\nax[1].set_xlim(-900, 1800);\n\n\n\ncoefplot2\n\n\n　py4stats.compare_mfx() と py4stats.mfxplot() は、それぞれ py4stats.compare_ols() と py4stats.coefplot() の一般化線型モデルバージョンです。statsmodels ライブラリの.get_margeff() メソッドから得られた限界効果の推定値を表示します。\npenguins['female'] = np.where(penguins['sex'] == 'female', 1, 0)\n\n# ロジスティック回帰の実行\nfit_logit1 = smf.logit('female ~ body_mass_g + bill_length_mm + bill_depth_mm', data = penguins).fit()\nfit_logit2 = smf.logit('female ~ body_mass_g + bill_length_mm + bill_depth_mm + species', data = penguins).fit()\n\npy4st.compare_mfx([fit_logit1, fit_logit2])\n\n\n\nterm\nmodel 1\nmodel 2\n\n\n\n\nbody_mass_g\n-0.0004 ***\n-0.0003 ***\n\n\n\n(0.0000)\n(0.0000)\n\n\nbill_length_mm\n-0.0053\n-0.0357 ***\n\n\n\n(0.0036)\n(0.0070)\n\n\nbill_depth_mm\n-0.1490 ***\n-0.1098 ***\n\n\n\n(0.0051)\n(0.0175)\n\n\nspecies[T.Chinstrap]\n\n0.4172 ***\n\n\n\n\n(0.0848)\n\n\nspecies[T.Gentoo]\n\n0.3527 ***\n\n\n\n\n(0.1308)\n\n\nprsquared\n0.5647\n0.6187\n\n\nnobs\n342\n342\n\n\ndf\n3\n5\n\n\n\nplt.rcParams[\"figure.autolayout\"] = True\n\nfig, ax = plt.subplots(1, 2, figsize = (2.2 * 5, 5), dpi = 100)\n\npy4st.mfxplot(fit_logit1, ax = ax[0])\nax[0].set_xlim(-0.2, 0.85)\n\npy4st.mfxplot(fit_logit2, ax = ax[1], palette = ['#FF6F91', '#F2E5EB'])\nax[1].set_xlim(-0.2, 0.85);\n\n\n\ncoefplot3\n\n\n\nJump to Function reference.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to Py4Stats</span>"
    ]
  },
  {
    "objectID": "reference.html",
    "href": "reference.html",
    "title": "Function reference",
    "section": "",
    "text": "Main Module",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Function reference</span>"
    ]
  },
  {
    "objectID": "reference.html#main-module",
    "href": "reference.html#main-module",
    "title": "Function reference",
    "section": "",
    "text": "py4stats.eda_tools\npy4stats.eda_tools モジュールは、探索的データ解析と前処理に関する機能を提供します。複数の DataFrame バックエンドに対して共通の API を提供することを目的として、narwhals ライブラリを用いて実装されています。詳細は Technical Notes を参照してください。\n\nデータフレームの概要\npy4stats.diagnose()\npy4stats.diagnose_category()\n\n\nクロス集計\npy4stats.tabyl()\npy4stats.freq_table()\npy4stats.Pareto_plot()\npy4stats.plot_category()\n\n\n\n数値変数の点推定と区間推定\npy4stats.mean_qi() py4stats.median_qi() py4stats.mean_ci()\n\nデータフレームの列や行の削除\npy4stats.remove_empty()\npy4stats.remove_constant()\npy4stats.filtering_out()\n\n\nデータフレームの列の並べ替え\npy4stats.relocate()\n\n\n複数のデータフレームの比較\npy4stats.compare_df_cols() py4stats.compare_df_stats()\npy4stats.review_wrangling()\n\n\n簡易なグループ別統計量の比較\npy4stats.compare_group_means() py4stats.compare_group_median()\npy4stats.plot_mean_diff() py4stats.plot_median_diff()\n\n\n簡易な欠測値の可視化\npy4stats.plot_miss_var()\npy4stats.set_miss()\n\n\n数値変数の集計と標準化\npy4stats.weighted_mean() py4stats.scale() py4stats.min_max()\n\n\n論理関数\npy4stats.is_number() py4stats.is_ymd() py4stats.is_ymd_like()\npy4stats.is_dummy()\n\n\n簡易なルールベースのデータ検証ツール\npy4stats.check_that() py4stats.check_viorate()\n\n\n\n\npy4stats.regression_tools\npy4stats.regression_tools は statsmodels ライブラリで作成された回帰分析の結果についての可視化と表作成を補助する機能を提供するモジュールです。\n\n線形モデルの比較\npy4stats.compare_ols()\npy4stats.compare_mfx()\n\n\n線形モデルの可視化\npy4stats.coefplot() py4stats.mfxplot()\n\n\n線形モデルを作表するためのバックエンド関数\npy4stats.tidy()py4stats.tidy_mfx()\npy4stats.tidy_test()\npy4stats.glance()\n\n\nBlinder-Oaxaca分解\npy4stats.Blinder_Oaxaca() py4stats.plot_Blinder_Oaxaca()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Function reference</span>"
    ]
  },
  {
    "objectID": "reference.html#sub-module",
    "href": "reference.html#sub-module",
    "title": "Function reference",
    "section": "Sub Module",
    "text": "Sub Module\n\npy4stats.heckit_helper\npy4stats.regression_tools の関数を py4etrics.heckit ライブラリで実装された Heckit モデルに対応させるためのメソッドを提供します。\nheckit_helper.Heckit_from_formula()\nheckit_helper.tidy_heckit()\nheckit_helper.heckitmfx_compute()\n\n\n\npy4stats.building_block\npy4stats ライブラリの実装に使用するアサーション関数やユーティリティ関数を提供します。 building_block モジュール自体は外部から呼び出すことなく内部実装に使用することを想定しています。\n\n\n引数のアサーション関数\nbuilding_block.arg_match()\nbuilding_block.assert_character() building_block.assert_logical() building_block.assert_numeric() building_block.assert_integer() building_block.assert_count() building_block.assert_float()\n\n\nデータ型を判定する論理関数\nbuilding_block.is_character() building_block.is_logical() building_block.is_numeric() building_block.is_integer() building_block.is_float()\n\n\n数字のフォーマット\nbuilding_block.style_number() building_block.style_currency() building_block.style_percent()\nbuilding_block.style_pvalue() building_block.p_stars()\n\n\n並列文の作成\nbuilding_block.oxford_comma() building_block.oxford_comma_and() building_block.oxford_comma_or()\n\nJump to Get started.\nJump to Readme.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Function reference</span>"
    ]
  },
  {
    "objectID": "man/diagnose.html",
    "href": "man/diagnose.html",
    "title": "diagnose",
    "section": "",
    "text": "概要\nデータフレームの概要\nR言語の dlookr::diagnose() を再現した関数で、データの全般的な状態についての要約を提供します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>diagnose</span>"
    ]
  },
  {
    "objectID": "man/diagnose.html#概要",
    "href": "man/diagnose.html#概要",
    "title": "diagnose",
    "section": "",
    "text": "diagnose(data: IntoFrameT, to_native: bool = True)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>diagnose</span>"
    ]
  },
  {
    "objectID": "man/diagnose.html#引数-argument",
    "href": "man/diagnose.html#引数-argument",
    "title": "diagnose",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>diagnose</span>"
    ]
  },
  {
    "objectID": "man/diagnose.html#返り値-value",
    "href": "man/diagnose.html#返り値-value",
    "title": "diagnose",
    "section": "返り値 Value",
    "text": "返り値 Value\n\ndtype：該当する列のpandasにおけるデータの型。「〇〇の個数」や「〇〇の金額」といったデータの dtype が object や String になっていたら、文字列として読み込まれているので要注意です。\nmissing_count：1列のなかで NaN などの欠測値になっている数\nmissing_percent：1列のなかで欠測値が占めている割合でmissing_percent = (missing_count / 行数) * 100 として計算されます。もし missing_percent = 100 なら、その列は完全に空白です。\nunique_count：その列で重複を除外したユニークな値の数。例えばある列の中身が「a, a, b」であればユニークな値は a と b の2つなので unique_count = 2 です。もし unique_count = 1 であれば、その行にはたった1種類の値しか含まれていないことが分かりますし、例えば都道府県を表す列の unique_count が47より多ければ、都道府県以外のものが混ざっていると考えられます。\nunique_rate： サンプルに占めるユニークな値の割合。 unique_rate = unique_count / 行数 で計算されます。unique_rate = 1 であれば、全ての行に異なる値が入っています。一般的に、実数値の列は unique_rate が高くなりますが、年齢の「20代」や価格の「200円代」のように階級に分けられている場合には unique_rate が低くなります。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>diagnose</span>"
    ]
  },
  {
    "objectID": "man/diagnose.html#使用例-examples",
    "href": "man/diagnose.html#使用例-examples",
    "title": "diagnose",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport py4stats as py4st\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込み\n\nprint(py4st.diagnose(penguins).round(4))\n#&gt;              columns    dtype  missing_count  missing_percent  unique_count  unique_rate\n#&gt; 0            species   object              0           0.0000             3       0.8721\n#&gt; 1             island   object              0           0.0000             3       0.8721\n#&gt; 2     bill_length_mm  float64              2           0.5814           165      47.9651\n#&gt; 3      bill_depth_mm  float64              2           0.5814            81      23.5465\n#&gt; 4  flipper_length_mm  float64              2           0.5814            56      16.2791\n#&gt; 5        body_mass_g  float64              2           0.5814            95      27.6163\n#&gt; 6                sex   object             11           3.1977             3       0.8721\n#&gt; 7               year    int64              0           0.0000             3       0.8721\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>diagnose</span>"
    ]
  },
  {
    "objectID": "man/tabyl.html",
    "href": "man/tabyl.html",
    "title": "tabyl",
    "section": "",
    "text": "概要\nレポートティング向けのクロス集計表を作成\nデータフレームのクロス集計表を作成します。R言語の janitor::tabyl()にいくつかの adorn_ 関数を追加した状態を再現した関数です。初期設定ではクロス集計表の各セルに度数と相対度数を 「度数(相対度数%)`」 の形式で表示します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>tabyl</span>"
    ]
  },
  {
    "objectID": "man/tabyl.html#概要",
    "href": "man/tabyl.html#概要",
    "title": "tabyl",
    "section": "",
    "text": "tabyl(\n    data: IntoFrameT,\n    index: str,\n    columns: str,\n    margins: bool = True,\n    margins_name: str = 'All',\n    normalize: Union[bool, Literal[\"index\", \"columns\", \"all\"]] = \"index\",\n    dropna: bool = False,\n    digits: int = 1,\n    **kwargs: Any\n)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>tabyl</span>"
    ]
  },
  {
    "objectID": "man/tabyl.html#引数-argument",
    "href": "man/tabyl.html#引数-argument",
    "title": "tabyl",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\nindex：str 　集計に使用するデータフレームの変数名（必須）。\ncolumns：str 　集計に使用するデータフレームの変数名（必須）。\nmargins：bool 　行または列の合計を追加するかどうかを表すブール値。初期設定は True です。\nmargins_name：bool 　行や列の合計の名前。初期設定は 'All' です。\ndropna：bool 　 欠測値（NaN）を集計から除外するかどうかを表すブール値。初期設定は False です。\nnormalize：str 　丸括弧( )に表示する相対度数の計算方式。\n\nindex 各セルの度数を行の和で割り、横方向の相対度数の和が100%になるように計算します。\ncolumns 各セルの度数を行の列で割り、縦方向の相対度数の和が100%になるように計算します。\nall 各セルの度数を総度数で割り、全てのセルの相対度数の和が100%になるように計算します。\n\ndigits：int 　丸括弧( )に表示する相対度数の小数点以下の桁数。初期設定は1です。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>tabyl</span>"
    ]
  },
  {
    "objectID": "man/tabyl.html#使用例-example",
    "href": "man/tabyl.html#使用例-example",
    "title": "tabyl",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込\n\n# 横方向の和を100%として計算（初期設定）\nprint(py4st.tabyl(penguins, 'island', 'species', normalize = 'index'))\n#&gt; species         Adelie   Chinstrap       Gentoo  All\n#&gt; island                                              \n#&gt; Biscoe      44 (26.2%)    0 (0.0%)  124 (73.8%)  168\n#&gt; Dream       56 (45.2%)  68 (54.8%)     0 (0.0%)  124\n#&gt; Torgersen  52 (100.0%)    0 (0.0%)     0 (0.0%)   52\n#&gt; All        152 (44.2%)  68 (19.8%)  124 (36.0%)  344\n\n# 縦方向の和を100%として計算\nprint(py4st.tabyl(penguins, 'island', 'species', normalize = 'columns'))\n#&gt; species        Adelie    Chinstrap        Gentoo          All\n#&gt; island                                                       \n#&gt; Biscoe     44 (28.9%)     0 (0.0%)  124 (100.0%)  168 (48.8%)\n#&gt; Dream      56 (36.8%)  68 (100.0%)      0 (0.0%)  124 (36.0%)\n#&gt; Torgersen  52 (34.2%)     0 (0.0%)      0 (0.0%)   52 (15.1%)\n#&gt; All               152           68           124          344\n\n# 全体の和を100%として計算\nprint(py4st.tabyl(penguins, 'island', 'species', normalize = 'all'))\n#&gt; species         Adelie   Chinstrap       Gentoo           All\n#&gt; island                                                       \n#&gt; Biscoe      44 (12.8%)    0 (0.0%)  124 (36.0%)   168 (48.8%)\n#&gt; Dream       56 (16.3%)  68 (19.8%)     0 (0.0%)   124 (36.0%)\n#&gt; Torgersen   52 (15.1%)    0 (0.0%)     0 (0.0%)    52 (15.1%)\n#&gt; All        152 (44.2%)  68 (19.8%)  124 (36.0%)  344 (100.0%)\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>tabyl</span>"
    ]
  },
  {
    "objectID": "man/freq_table.html",
    "href": "man/freq_table.html",
    "title": "freq_table",
    "section": "",
    "text": "概要\n1変数の度数分布表\nR言語のDescTools::Freq()をオマージュした、1変数の度数分布表を計算する関数。度数 freq と相対度数 perc に加えて、それぞれの累積値を計算します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>freq_table</span>"
    ]
  },
  {
    "objectID": "man/freq_table.html#概要",
    "href": "man/freq_table.html#概要",
    "title": "freq_table",
    "section": "",
    "text": "freq_table(\n    data: IntoFrameT,\n    subset: Union[str, Sequence[str]],\n    sort_by: Literal['frequency', 'values'] = 'frequency',\n    descending: bool = False,\n    dropna: bool = False,\n    to_native: bool = True,\n    *,\n    sort: Optional[bool] = None\n)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>freq_table</span>"
    ]
  },
  {
    "objectID": "man/freq_table.html#引数-argument",
    "href": "man/freq_table.html#引数-argument",
    "title": "freq_table",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\nsubset：str or list of str 　集計に使用するデータフレームの列名（必須）。\nsort_by：str 　sort_by = 'frequency' なら度数分布表を頻度に応じてソートし、sort_by = 'values' なら subset で指定した列の値に応じてソートします。\ndescending：bool 　ソートの方式。True なら降順でソートし、False（初期設定）なら昇順でソートします。\ndropna：bool 　欠測値（NaN, None など）を集計から除外するかどうかを表すブール値。初期設定は False です。\nsort：Deprecated.. 　sort_by の使用を推奨しています。この引数は後方互換性のために保持されおり、指定された場合は FutureWarningが発生します。デフォルトは None です。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>freq_table</span>"
    ]
  },
  {
    "objectID": "man/freq_table.html#返り値-value",
    "href": "man/freq_table.html#返り値-value",
    "title": "freq_table",
    "section": "返り値 Value",
    "text": "返り値 Value\n　freq_table()関数は、次の値をもつ DataFrame を出力します。\n\nfreq: 度数\nperc: 相対度数\ncumfreq: 累積度数\ncumperc: 累積相対度数",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>freq_table</span>"
    ]
  },
  {
    "objectID": "man/freq_table.html#使用例-example",
    "href": "man/freq_table.html#使用例-example",
    "title": "freq_table",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込\n\nprint(py4st.freq_table(penguins, 'species'))\n#&gt;      species  freq      perc  cumfreq   cumperc\n#&gt; 0  Chinstrap    68  0.197674       68  0.197674\n#&gt; 1     Gentoo   124  0.360465      192  0.558140\n#&gt; 2     Adelie   152  0.441860      344  1.000000\n\nprint(py4st.freq_table(penguins, ['island', 'species']))\n#&gt;       island    species  freq      perc  cumfreq   cumperc\n#&gt; 0     Biscoe     Adelie    44  0.127907       44  0.127907\n#&gt; 1  Torgersen     Adelie    52  0.151163       96  0.279070\n#&gt; 2      Dream     Adelie    56  0.162791      152  0.441860\n#&gt; 3      Dream  Chinstrap    68  0.197674      220  0.639535\n#&gt; 4     Biscoe     Gentoo   124  0.360465      344  1.000000\npenguins2 = penguins.assign(bill_length_mm2 = pd.cut(penguins['bill_length_mm'], 6))\n\nprint(\n    py4st.freq_table(\n        penguins2, ['species', 'bill_length_mm2'], \n        sort_by = 'values',  dropna = True\n        )\n    )\n#&gt;       species   bill_length_mm2  freq      perc  cumfreq   cumperc\n#&gt; 0      Adelie  (32.072, 36.683]    36  0.105263       36  0.105263\n#&gt; 1      Adelie  (36.683, 41.267]    89  0.260234      125  0.365497\n#&gt; 2      Adelie   (41.267, 45.85]    25  0.073099      150  0.438596\n#&gt; 3      Adelie   (45.85, 50.433]     1  0.002924      151  0.441520\n#&gt; 4   Chinstrap  (36.683, 41.267]     1  0.002924      152  0.444444\n#&gt; 5   Chinstrap   (41.267, 45.85]    12  0.035088      164  0.479532\n#&gt; 6   Chinstrap   (45.85, 50.433]    29  0.084795      193  0.564327\n#&gt; 7   Chinstrap  (50.433, 55.017]    24  0.070175      217  0.634503\n#&gt; 8   Chinstrap    (55.017, 59.6]     2  0.005848      219  0.640351\n#&gt; 9      Gentoo  (36.683, 41.267]     1  0.002924      220  0.643275\n#&gt; 10     Gentoo   (41.267, 45.85]    39  0.114035      259  0.757310\n#&gt; 11     Gentoo   (45.85, 50.433]    65  0.190058      324  0.947368\n#&gt; 12     Gentoo  (50.433, 55.017]    15  0.043860      339  0.991228\n#&gt; 13     Gentoo    (55.017, 59.6]     3  0.008772      342  1.000000\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>freq_table</span>"
    ]
  },
  {
    "objectID": "man/Pareto_plot.html",
    "href": "man/Pareto_plot.html",
    "title": "Pareto_plot",
    "section": "",
    "text": "概要\nパレート図の作成\nデータフレームからパレート図を作図する関数です。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pareto_plot</span>"
    ]
  },
  {
    "objectID": "man/Pareto_plot.html#概要",
    "href": "man/Pareto_plot.html#概要",
    "title": "Pareto_plot",
    "section": "",
    "text": "Pareto_plot(\n    data: IntoFrameT,\n    group: str,\n    values: Optional[str] = None,\n    top_n: Optional[int] = None,\n    aggfunc: Callable[..., Any] = np.mean,\n    ax: Optional[Axes] = None,\n    fontsize: int = 12,\n    xlab_rotation: Union[int, float] = 0,\n    palette: Sequence[str] = (\"#478FCE\", \"#252525\"),\n    )\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\ngroup：str 　集計に使用するデータフレームの列名（必須）。\nvalues：str 　集計に使用するデータフレームの列名。values = None（初期設定）の場合、group 別の度数が表示され、values が指定された場合、group 別に values を aggfuncで集計した値がグラフに表示されます。\ntop_n：int 　棒グラフを表示するカテゴリーの件数。top_n = None（初期設定）の場合、すべてのカテゴリーを表示し、整数値が指定された場合、上位 top_n 件が表示されます。\naggfunc：callable values が指定された際に、集計に使用する集計関数。np.mean など values 列を1次元配列として受け取って単一の数値を返す任意の関数が使用できるほか、nw.mean など narwhals.functions モジュールで実装された関数を使用できます。\nax 描画先となる matplotlib の Axes。複数のグラフを並べる場合などに使用します。デフォルトの None の場合は、新しい Figure と Axes が作成されます。\nfontsize：int 　軸ラベルなどのフォントサイズ。\nxlab_rotation：int or float 横軸ラベルの角度。matplotlib の ax.xaxis.set_tick_params() に引数 rotation として渡されます。\npalette：list of str グラフの描画に使用する色コード。1つ目の要素が棒グラフの色に、2つ目の累積値を表す折線グラフの色に対応します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pareto_plot</span>"
    ]
  },
  {
    "objectID": "man/Pareto_plot.html#使用例-example",
    "href": "man/Pareto_plot.html#使用例-example",
    "title": "Pareto_plot",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込\n\npenguins['group'] = penguins['species'] + '\\n' + penguins['island']\n\npy4st.Pareto_plot(penguins, group = 'group')\n\n\n\nPareto_plot1\n\n\npy4st.Pareto_plot(\n    penguins, group = 'group', \n    values = 'bill_length_mm',\n    aggfunc = np.mean,\n    palette = ['#FF6F91', '#252525']\n    )\n\n\n\nPareto_plot2\n\n\npy4st.Pareto_plot(\n    penguins, \n    values = 'bill_length_mm',\n    group = 'group',\n    aggfunc = lambda x: x.std()\n    )\n\n\n\nPareto_plot3\n\n\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pareto_plot</span>"
    ]
  },
  {
    "objectID": "man/plot_category.html",
    "href": "man/plot_category.html",
    "title": "plot_category",
    "section": "",
    "text": "概要\nカテゴリ変数の回答分布を 100% 積み上げ横棒グラフとして描画します。\n本関数は、複数のカテゴリ変数について回答分布を集計し、各変数を1本の100%積み上げ横棒グラフとして可視化します。リッカート尺度による設問や、共通のカテゴリをもつ、アンケートの回答データの可視化を主な用途としています。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>plot_category</span>"
    ]
  },
  {
    "objectID": "man/plot_category.html#概要",
    "href": "man/plot_category.html#概要",
    "title": "plot_category",
    "section": "",
    "text": "plot_category(\n    data: IntoFrameT,\n    palette: Optional[sns.palettes._ColorPalette] = None,\n    legend_type: Literal['horizontal', 'vertical', 'none'] = 'horizontal',\n    show_vline: bool = True,\n    ax: Optional[Axes] = None,\n):",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>plot_category</span>"
    ]
  },
  {
    "objectID": "man/plot_category.html#引数-argument",
    "href": "man/plot_category.html#引数-argument",
    "title": "plot_category",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） カテゴリ変数を含む入力データフレーム（1列につき1変数）。 narwhals がサポートする任意のデータフレーム型（例：pandas.DataFrame、polars.DataFrame）を指定できます。 すべての列は、同一のカテゴリ体系（共通のカテゴリラベル）を共有している必要があります。 注意：pyarrow.Table については、その仕様による機能制限があります。詳細は「注意 Notes」セクションを参照してください。\nsort_by: str 回答カテゴリの並び順を決定する基準。'values'：カテゴリの値（ラベル）でソートします。'frequency'：出現頻度の高い順にソートします。デフォルトは 'values' です。\npalette sns.palettes._ColorPalette: 回答カテゴリに使用するカラーパレット。 None の場合は、内部でデフォルトの発散型パレットを生成します。 指定する場合は、カテゴリ数と同じ長さの配列である必要があります。 デフォルトは None です。\nlegend_typestr: 凡例の配置方法。デフォルトは 'horizontal' です。\n\n'horizontal'：凡例をグラフ下部に横並びで表示します。\n'vertical'：凡例をグラフ右側に縦並びで表示します。\n'none'：凡例を表示しません。\n\nshow_vline:bool True の場合、x = 0.5（50%）の位置に基準となる垂直線を描画します。 割合の中点を視覚的に示す目的で使用できます。デフォルトは True です。\nax: 描画先となる matplotlib の Axes。複数のグラフを並べる場合などに使用します。デフォルトの None の場合は、新しい Figure と Axes が作成されます。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>plot_category</span>"
    ]
  },
  {
    "objectID": "man/plot_category.html#使用例-example",
    "href": "man/plot_category.html#使用例-example",
    "title": "plot_category",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nimport itertools\n\nQ1 = [70 * ['Strongly agree'], 200 * ['Agree'], 235 * ['Disagree'], 149 * ['Strongly disagree']]\nQ2 = [74 * ['Strongly agree'], 209 * ['Agree'], 238 * ['Disagree'], 133 * ['Strongly disagree']]\nQ3 = [59 * ['Strongly agree'], 235 * ['Agree'], 220 * ['Disagree'], 140 * ['Strongly disagree']]\nQ4 = [40 * ['Strongly agree'], 72 * ['Agree'], 266 * ['Disagree'], 276 * ['Strongly disagree']]\n\ndata = pd.DataFrame({\n    'I read only if I have to.':list(itertools.chain.from_iterable(Q1)),\n    'Reading is one of my favorite hobbies.':list(itertools.chain.from_iterable(Q2)),\n    'I like talking about books with other people.':list(itertools.chain.from_iterable(Q3)),\n    'For me, reading is a waste of time.':list(itertools.chain.from_iterable(Q4))\n})\ncateg_list = ['Strongly disagree', 'Disagree', 'Agree', 'Strongly agree']\n\ndata_pd = data.apply(pd.Categorical, categories = categ_list)\n\npy4st.plot_category(data_pd)\n\n\n\nplot_category1\n\n\nimport polars as pl\nimport textwrap\n\ndata_pl = pl.from_pandas(data)\ndata_pl = data_pl.with_columns(\n        pl.all().cast(pl.Enum(categ_list))\n    )\\\n    .rename(lambda x: textwrap.fill(x, width = 25))\n\nfig, ax = plt.subplots()\n\npy4st.plot_category(\n    data_pl, \n    palette = sns.color_palette('RdBu', n_colors = 4),\n    ax = ax\n    )\n\nax.set_title('Survey on attitudes toward reading');\n\n\n\nplot_category2",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>plot_category</span>"
    ]
  },
  {
    "objectID": "man/plot_category.html#注意-notes",
    "href": "man/plot_category.html#注意-notes",
    "title": "plot_category",
    "section": "注意 Notes",
    "text": "注意 Notes\n\nsort_by=\"values\" は、カテゴリの順序情報（例：pandas の ordered categorical、Polars の Enum で定義した順序）を前提に、カテゴリ順で描画します。\n推奨： sort_by=“values” を利用する場合は、入力として pandas.DataFrame（各列を pd.Categorical に設定）または polars.DataFrame（各列を Enum に設定）を推奨します。\npolars.Categorical の列では、カテゴリ順が期待通りに保持されず、辞書順（例：Agree, Disagree, …）で描画される場合があります。\npyarrow.Table を入力した場合、sort_by = 'values’ は dictionary 型の制約によりエラーとなる場合があります。その場合は sort_by=\"frequency\" を使用してください。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>plot_category</span>"
    ]
  },
  {
    "objectID": "man/diagnose_category.html",
    "href": "man/diagnose_category.html",
    "title": "diagnose_category",
    "section": "",
    "text": "概要\nカテゴリー変数の要約\nデータフレームのカテゴリー変数を要約します。本関数は、カテゴリー情報を表す列（カテゴリ型・文字列型・ブール型）およびダミー変数（値が {0, 1} に制限された整数列）を対象として、欠損率、ユニーク値の数、最頻値、最頻値の頻度と割合、evenness などの指標を提供します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>diagnose_category</span>"
    ]
  },
  {
    "objectID": "man/diagnose_category.html#概要",
    "href": "man/diagnose_category.html#概要",
    "title": "diagnose_category",
    "section": "",
    "text": "diagnose_category(\n        data: IntoFrameT, \n        dropna: bool = True, \n        to_native: bool = True\n        )",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>diagnose_category</span>"
    ]
  },
  {
    "objectID": "man/diagnose_category.html#引数-argument",
    "href": "man/diagnose_category.html#引数-argument",
    "title": "diagnose_category",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\ndropna：bool 　欠測値（NaN, None など）を統計値の計算から除外するかどうかを表すブール値。初期設定は True です。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>diagnose_category</span>"
    ]
  },
  {
    "objectID": "man/diagnose_category.html#返り値-value",
    "href": "man/diagnose_category.html#返り値-value",
    "title": "diagnose_category",
    "section": "返り値 Value",
    "text": "返り値 Value\nfreq_table()関数は、次の値をもつ DataFrame を出力します。\n\nvariables: 変数（列）名\ncount: 非欠損値の個数\nmiss_pct: 欠損率(null_count / N * 100) (* ここで N は data の行数)\nunique: ユニーク値の個数\nunique_pct: ユニーク値の割合(unique / N * 100)\nmode: 最頻値\nmode_freq: 最頻値の度数\nmode_pct: 最頻値の割合（mode_freq / N * 100）\nevenness:　カテゴリー分布の均等度（[0, 1] の範囲）",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>diagnose_category</span>"
    ]
  },
  {
    "objectID": "man/diagnose_category.html#使用例-examples",
    "href": "man/diagnose_category.html#使用例-examples",
    "title": "diagnose_category",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport pandas as pd\nimport py4stats as py4st\nfrom palmerpenguins import load_penguins\n\npenguins = load_penguins().drop('year', axis = 1) # サンプルデータの読み込み\npenguins2 = penguins.copy()\ns = penguins2['body_mass_g']\npenguins2['heavy'] = np.where(s &gt;= s.quantile(0.75), True, False)\n\nprint(py4st.diagnose_category(penguins2).round(4))\n#&gt;   variables  count  miss_pct  unique  unique_pct    mode  mode_freq  mode_pct  evenness\n#&gt; 0   species    344    0.0000       3      0.8721  Adelie        152   44.1860    0.9550\n#&gt; 1    island    344    0.0000       3      0.8721  Biscoe        168   48.8372    0.9133\n#&gt; 2       sex    333    3.1977       2      0.5814    male        168   50.4505    0.9999\n#&gt; 3     heavy    344    0.0000       2      0.5814   False        254   73.8372    0.8292",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>diagnose_category</span>"
    ]
  },
  {
    "objectID": "man/diagnose_category.html#note",
    "href": "man/diagnose_category.html#note",
    "title": "diagnose_category",
    "section": "Note",
    "text": "Note\nevenness は、各列ごとに情報エントロピーを \\([0, 1]\\) の範囲に正規化した指標です。本実装では、対数の底をカテゴリの個数（unique）に設定することで正規化を行っており、これは底を2とした情報エントロピーを log2(unique) で割ることと同値です。この指標は正規化エントロピー（normalized entropy）としても知られています。\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>diagnose_category</span>"
    ]
  },
  {
    "objectID": "man/point_range.html",
    "href": "man/point_range.html",
    "title": "mean_qi median_qi mean_ci",
    "section": "",
    "text": "概要\n数値変数の点推定と区間推定\nR言語の ggdist::mean_qi() をオマージュした数値変数の点推定と区間推定を行う関数です。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>mean_qi median_qi mean_ci</span>"
    ]
  },
  {
    "objectID": "man/point_range.html#概要",
    "href": "man/point_range.html#概要",
    "title": "mean_qi median_qi mean_ci",
    "section": "",
    "text": "mean_qi(\n    data: Union[IntoFrameT, SeriesT],\n    width: float = 0.975,\n    interpolation: str = 'midpoint',\n    to_native: bool = True\n)\nmean_qi(\n    data: Union[IntoFrameT, SeriesT],\n    width: float = 0.975,\n    interpolation: str = 'midpoint',\n    to_native: bool = True\n)\n\nmedian_qi(\n    data: Union[IntoFrameT, IntoSeriesT],\n    width: float = 0.975,\n    interpolation: str = 'midpoint',\n    to_native: bool = True\n)\n\nmean_ci(\n    data: Union[IntoFrameT, IntoSeriesT],\n    width: float = 0.975,\n    to_native: bool = True\n)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>mean_qi median_qi mean_ci</span>"
    ]
  },
  {
    "objectID": "man/point_range.html#引数-argument",
    "href": "man/point_range.html#引数-argument",
    "title": "mean_qi median_qi mean_ci",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT or IntoSeriesT（必須） 入力データ。narwhals が受け入れ可能な DataFrame もしくは Series 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\nwidth：float 　分位点区間の幅、もしくは信頼区間の計算に用いる信頼係数。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>mean_qi median_qi mean_ci</span>"
    ]
  },
  {
    "objectID": "man/point_range.html#使用例-examples",
    "href": "man/point_range.html#使用例-examples",
    "title": "mean_qi median_qi mean_ci",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport py4stats as py4st\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込み\n\nprint(py4st.mean_qi(penguins['bill_length_mm']).round(2))\n#&gt;          variable   mean  lower  upper\n#&gt; 0  bill_length_mm  43.92   34.8   53.1\n\n\nprint(py4st.median_qi(penguins['bill_length_mm']).round(2))\n#&gt;          variable  median  lower  upper\n#&gt; 0  bill_length_mm   44.45   34.8   53.1\n\nprint(py4st.mean_ci(penguins['bill_length_mm']).round(2))\n#&gt;          variable   mean  lower  upper\n#&gt; 0  bill_length_mm  43.92  43.26  44.58\n\nprint(py4st.mean_ci(penguins[['bill_length_mm', 'bill_depth_mm']]).round(2))\n#&gt;          variable   mean  lower  upper\n#&gt; 0  bill_length_mm  43.92  43.26  44.58\n#&gt; 1   bill_depth_mm  17.15  16.91  17.39\n\nprint(penguins.groupby('species')[['bill_length_mm']].apply(py4st.median_qi).round(2))\n#&gt;                    variable  median  lower  upper\n#&gt; species                                          \n#&gt; Adelie    0  bill_length_mm   38.80  34.05  44.10\n#&gt; Chinstrap 0  bill_length_mm   49.55  42.45  55.00\n#&gt; Gentoo    0  bill_length_mm   47.30  42.65  53.85\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>mean_qi median_qi mean_ci</span>"
    ]
  },
  {
    "objectID": "man/remove_empty_constant.html",
    "href": "man/remove_empty_constant.html",
    "title": "remove_empty, remove_constant",
    "section": "",
    "text": "概要\nデータフレームの空白列および、定数列の削除\npy4stats.remove_empty()はR言語の janitor:remove_empty() をオマージュした関数で、全ての要素が NaN である列や行をデータフレームから除外します py4stats.remove_constant() はR言語の janitor:remove_constant() をオマージュした関数で、1種類だけの要素からなる列をデータフレームから除外します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>remove_empty, remove_constant</span>"
    ]
  },
  {
    "objectID": "man/remove_empty_constant.html#概要",
    "href": "man/remove_empty_constant.html#概要",
    "title": "remove_empty, remove_constant",
    "section": "",
    "text": "remove_empty(\n    data: IntoFrameT,\n    cols: bool = True,\n    rows: bool = True,\n    cutoff: float = 1.0,\n    quiet: bool = True,\n    to_native: bool = True,\n    **kwargs: Any\n) \n\nremove_constant(\n    data: IntoFrameT,\n    quiet: bool = True,\n    to_native: bool = True,\n    dropna = False,\n    **kwargs: Any\n)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>remove_empty, remove_constant</span>"
    ]
  },
  {
    "objectID": "man/remove_empty_constant.html#引数-argument",
    "href": "man/remove_empty_constant.html#引数-argument",
    "title": "remove_empty, remove_constant",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\ncols：bool 　空白列を削除するかどうかを表すブール値（remove_empty() のみ）。True（初期設定） なら空白列を削除し、Falseなら全ての要素が NaN の列があっても削除しません。\nrows：bool 　空白行を削除するかどうかを表すブール値（remove_empty() のみ）。True（初期設定） なら空白行を削除し、Falseなら全ての要素が NaN の行があっても削除しません。\ncutoff：float 　列（行）の削除を行うかどうかを判定する欠測率の閾値（remove_empty() のみ）。ある列（行）における NaN の割合が &gt;= cutoff のとき、その列（行）を削除します。初期設定は1で全ての要素が NaN の列（行）のみ削除しますが、例えば cutoff = 0.9 とすることで NaN の割合9が割以上の列（行）を削除できます。\nquiet：bool 　削除した列（行）を報告するかどうかを表すブール値。quiet = True（初期設定） であれば何も報告せずに削除だけ行い、quiet = False なら、削除した列（行）の数と列名（行名）を報告します。\ndropna：bool 　ユニーク値の数を計算する際に、NaN を除外するかどうかを表すブール値（remove_constant() のみ）。dropna = True だと NaN を除外し、dropna = False（初期設定）だと NaN を除外しません。データフレームに NaN と、 NaN ではない1種類の値からなる列がある場合、dropna = False だと削除されず、dropna = True だと削除されます。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>remove_empty, remove_constant</span>"
    ]
  },
  {
    "objectID": "man/remove_empty_constant.html#使用例-example",
    "href": "man/remove_empty_constant.html#使用例-example",
    "title": "remove_empty, remove_constant",
    "section": "使用例 Example",
    "text": "使用例 Example\npy4stats.remove_empty() の使用例。\nimport py4stats as py4st\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込み\n\npenguins2 = penguins.loc[:, ['species', 'body_mass_g']].copy()\n# 空白列を作成\npenguins2.loc[:, 'empty'] = np.nan\n# 空白行を作成\npenguins2.loc[344, :] = np.nan\n\nprint(penguins2.tail(3))\n#&gt;        species  body_mass_g  empty\n#&gt; 342  Chinstrap       4100.0    NaN\n#&gt; 343  Chinstrap       3775.0    NaN\n#&gt; 344        NaN          NaN    NaN\n# 完全に空白な行と列を削除。\nprint(py4st.remove_empty(penguins2, quiet = False).tail(3))\n#&gt; Removing 1 empty column(s) out of 3 columns(Removed: empty).\n#&gt; Removing 1 empty row(s) out of 345 rows(Removed: 344).\n#&gt;        species  body_mass_g\n#&gt; 341  Chinstrap       3775.0\n#&gt; 342  Chinstrap       4100.0\n#&gt; 343  Chinstrap       3775.0\n\n# 完全に空白な列のみ削除。\nprint(py4st.remove_empty(penguins2, rows = False, quiet = False).tail(3))\n#&gt; Removing 1 empty column(s) out of 3 columns(Removed: empty).\n#&gt;        species  body_mass_g\n#&gt; 342  Chinstrap       4100.0\n#&gt; 343  Chinstrap       3775.0\n#&gt; 344        NaN          NaN\n\n# 完全に空白な行のみ削除。\nprint(py4st.remove_empty(penguins2, cols = False, quiet = False).tail(3))\n#&gt; Removing 1 empty row(s) out of 345 rows(Removed: 344).\n#&gt;        species  body_mass_g  empty\n#&gt; 341  Chinstrap       3775.0    NaN\n#&gt; 342  Chinstrap       4100.0    NaN\n#&gt; 343  Chinstrap       3775.0    NaN\n# quiet = True の場合\nprint(py4st.remove_empty(penguins2).tail(3))\n#&gt;        species  body_mass_g\n#&gt; 341  Chinstrap       3775.0\n#&gt; 342  Chinstrap       4100.0\n#&gt; 343  Chinstrap       3775.0\npy4stats.remove_constant() の使用例。\npenguins2 = penguins.loc[:, ['species', 'body_mass_g']].copy()\npenguins2.loc[:, 'constant'] = 'c'\n\nprint(penguins2.head(3))\n#&gt;   species  body_mass_g constant\n#&gt; 0  Adelie       3750.0        c\n#&gt; 1  Adelie       3800.0        c\n#&gt; 2  Adelie       3250.0        c\n\nprint(py4st.remove_constant(penguins2, quiet = False).head(3))\n#&gt; Removing 1 constant column(s) out of 3 column(s)(Removed: constant).\n#&gt;   species  body_mass_g\n#&gt; 0  Adelie       3750.0\n#&gt; 1  Adelie       3800.0\n#&gt; 2  Adelie       3250.0\npenguins2.loc[:, 'almost_empty'] = pd.NA\npenguins2.loc[1, 'almost_empty'] = 'c'\n\n# dropna = False なら、almost_empty は削除されません。\nprint(py4st.remove_constant(penguins2).head(3))\n#&gt;   species  body_mass_g almost_empty\n#&gt; 0  Adelie       3750.0         &lt;NA&gt;\n#&gt; 1  Adelie       3800.0            c\n#&gt; 2  Adelie       3250.0         &lt;NA&gt;\n\nprint(py4st.remove_constant(penguins2, dropna = True).head(3))\n#&gt;   species  body_mass_g\n#&gt; 0  Adelie       3750.0\n#&gt; 1  Adelie       3800.0\n#&gt; 2  Adelie       3250.0\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>remove_empty, remove_constant</span>"
    ]
  },
  {
    "objectID": "man/filtering_out.html",
    "href": "man/filtering_out.html",
    "title": "filtering_out",
    "section": "",
    "text": "概要\nデータフレームの行と列の除外\npandas の DataFrame.filter() メソッドでは引数 like に文字列を指定することで、列名に特定の文字列を含む列を選択できます。py4st.filtering_out() では、反対に列名に特定の文字列を含む列を除外します。実装の一部はR言語の dplyr::select() を参考にしました。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>filtering_out</span>"
    ]
  },
  {
    "objectID": "man/filtering_out.html#概要",
    "href": "man/filtering_out.html#概要",
    "title": "filtering_out",
    "section": "",
    "text": "filtering_out(\n    data: IntoFrameT,\n    contains: Optional[str] = None,\n    starts_with: Optional[str] = None,\n    ends_with: Optional[str] = None,\n    axis: Union[int, str] = 'columns',\n    to_native: bool = True,\n)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>filtering_out</span>"
    ]
  },
  {
    "objectID": "man/filtering_out.html#引数-argument",
    "href": "man/filtering_out.html#引数-argument",
    "title": "filtering_out",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\n*args（str / list[str] / narwhals.Expr / narwhals.Selector） 移動したい列を指定します。指定方法は次のとおりです。\n\n列名（例：\"x\"）\n列名のリスト（例：[\"x\", \"y\"]）\nnarwhals の式（Expr）（例：nw.col(\"x\")） *axis = 'columns' の場合のみ\nnarwhals の Selector （例：ncs.numeric()）*axis = 'columns' の場合のみ\n\ncontains：str 　列名（行名）の検索に使用する文字列。内部で使用している pandas.Series.str.contains に渡され、指定された文字列を列名（行名）に含む列（行）を除外します。\nstarts_with：str 　列名（行名）の検索に使用する文字列。内部で使用している pandas.Series.str.startswith に渡され、指定された文字列で列名（行名）が始まる列（行）を除外します。\nends_with：str 　列名（行名）の検索に使用する文字列。内部で使用している pandas.Series.str.endswith に渡され、指定された文字列で列名（行名）が終わる列（行）を除外します。\naxis：{0 or 'index', 1 or 'columns'} axis = 1 または axis = 'columns' なら列の削除を行い、axis = 0 または axis = 'index' なら行の削除を行います。 このオプションは、data がインデックス属性 (例: pandas.DataFrame) をもつ場合のみ有効です。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>filtering_out</span>"
    ]
  },
  {
    "objectID": "man/filtering_out.html#使用例-example",
    "href": "man/filtering_out.html#使用例-example",
    "title": "filtering_out",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nimport narwhals.selectors as ncs\nfrom palmerpenguins import load_penguins\n\npenguins = load_penguins().head(3) # サンプルデータの読み込み\n\nprint(penguins)\n#&gt;   species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g     sex  year  female\n#&gt; 0  Adelie  Torgersen            39.1           18.7              181.0       3750.0    male  2007       0\n#&gt; 1  Adelie  Torgersen            39.5           17.4              186.0       3800.0  female  2007       1\n#&gt; 2  Adelie  Torgersen            40.3           18.0              195.0       3250.0  female  2007       1\n# *args で列名を直接指定\nprint(py4st.filtering_out(penguins, 'year', 'island', 'sex'))\n#&gt;   species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n#&gt; 0  Adelie            39.1           18.7              181.0       3750.0\n#&gt; 1  Adelie            39.5           17.4              186.0       3800.0\n#&gt; 2  Adelie            40.3           18.0              195.0       3250.0\n\n\n# narwhals.selector の使用例 文字列型の変数を除外\nprint(py4st.filtering_out(penguins, ncs.string()))\n#&gt;    bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  year\n#&gt; 0            39.1           18.7              181.0       3750.0  2007\n#&gt; 1            39.5           17.4              186.0       3800.0  2007\n#&gt; 2            40.3           18.0              195.0       3250.0  2007\n\n# 列名に 'length' を含む列を除外\nprint(py4st.filtering_out(penguins, contains = 'length'))\n#&gt;   species     island  bill_depth_mm  body_mass_g     sex  year  female\n#&gt; 0  Adelie  Torgersen           18.7       3750.0    male  2007       0\n#&gt; 1  Adelie  Torgersen           17.4       3800.0  female  2007       1\n#&gt; 2  Adelie  Torgersen           18.0       3250.0  female  2007       1\n\n# 列名が 'bill' から始まる列を除外\nprint(py4st.filtering_out(penguins, starts_with = 'bill'))\n#&gt;   species     island  flipper_length_mm  body_mass_g     sex  year  female\n#&gt; 0  Adelie  Torgersen              181.0       3750.0    male  2007       0\n#&gt; 1  Adelie  Torgersen              186.0       3800.0  female  2007       1\n#&gt; 2  Adelie  Torgersen              195.0       3250.0  female  2007       1\n\n# 列名が '_mm' で終わる列を除外\nprint(py4st.filtering_out(penguins, ends_with = '_mm'))\n#&gt;   species     island  body_mass_g     sex  year  female\n#&gt; 0  Adelie  Torgersen       3750.0    male  2007       0\n#&gt; 1  Adelie  Torgersen       3800.0  female  2007       1\n#&gt; 2  Adelie  Torgersen       3250.0  female  2007       1",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>filtering_out</span>"
    ]
  },
  {
    "objectID": "man/filtering_out.html#notes",
    "href": "man/filtering_out.html#notes",
    "title": "filtering_out",
    "section": "Notes",
    "text": "Notes\naxis='index' による行を対象とするフィルタリングは、インデックスの存在に依存します。したがって、pd.DataFrame 以外の行ラベルをもたない DataFrame バックエンドでは、このオプションは利用できません。\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>filtering_out</span>"
    ]
  },
  {
    "objectID": "man/relocate.html",
    "href": "man/relocate.html",
    "title": "relocate",
    "section": "",
    "text": "概要\nデータフレームの列を削除することなく並び替える関数\nrelocate() 関数は、データフレームに含まれる列を削除することなく並び替えるための関数です。指定した列（1 列または複数列）を、先頭・特定の列の前・特定の列の後に移動させることができます。本関数は、R の dplyr:relocate() に近い操作感を Python で提供することを目的としています。列の指定には、列名（文字列）だけでなく、narwhals の式（Expr）や Selector を利用でき、柔軟な列選択",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>relocate</span>"
    ]
  },
  {
    "objectID": "man/relocate.html#概要",
    "href": "man/relocate.html#概要",
    "title": "relocate",
    "section": "",
    "text": "relocate(\n      data: IntoFrameT, \n      *args: Union[str, List[str], narwhals.Expr, narwhals.selectors.Selector], \n      before: Optional[str] = None,\n      after: Optional[str] = None,\n      place: Optional[Literal[\"first\", \"last\"]] = None,\n      to_native: bool = True\n    ):",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>relocate</span>"
    ]
  },
  {
    "objectID": "man/relocate.html#引数-argument",
    "href": "man/relocate.html#引数-argument",
    "title": "relocate",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\n*args（str / list[str] / narwhals.Expr / narwhals.Selector） 移動したい列を指定します。指定方法は次のとおりです。\n\n列名（例：\"x\"）\n列名のリスト（例：[\"x\", \"y\"]）\nnarwhals の式（Expr）（例：nw.col(\"x\")）\nnarwhals の Selector （例：ncs.numeric()）\n\n指定した順序は、移動後の列順にもそのまま反映されます。\nbefore（str, optional） args で指定された列を、この列の直前に移動します。 after と同時に指定することはできません。デフォルトは None です。\nafter（str, optional） args で指定された列を、この列の直後に移動します。 before と同時に指定することはできません。デフォルトは None です。\nplace（str, optional） *args で指定された列の、配置場所を指定します。\n\n\"first\": 選択した列をデータフレームの先頭（最も左）に配置します。\n\"last\": 選択した列をデータフレームの末尾（最も右）に配置します。 place 引数は before または after と同時に指定することはできません。 未指定（None）の場合は \"first\" と同じ挙動になります。\n\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。\n\n\n返り値 Value\n\nIntoFrameT 入力データフレームと同じ列を保持したまま、指定されたルールに従って並び替えられたデータフレームを返します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>relocate</span>"
    ]
  },
  {
    "objectID": "man/relocate.html#使用例-example",
    "href": "man/relocate.html#使用例-example",
    "title": "relocate",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nimport narwhals.selectors as ncs\nfrom palmerpenguins import load_penguins\n\npenguins_mini = py4st.filtering_out(penguins, starts_with = 'bill').head(3)\nprint(penguins_mini)\n#&gt;   species     island  flipper_length_mm  body_mass_g     sex  year\n#&gt; 0  Adelie  Torgersen              181.0       3750.0    male  2007\n#&gt; 1  Adelie  Torgersen              186.0       3800.0  female  2007\n#&gt; 2  Adelie  Torgersen              195.0       3250.0  female  2007\n# *args に指定した列は最前列に移動します\nprint(py4st.relocate(penguins_mini, 'year', 'sex'))\n#&gt;    year     sex species     island  flipper_length_mm  body_mass_g\n#&gt; 0  2007    male  Adelie  Torgersen              181.0       3750.0\n#&gt; 1  2007  female  Adelie  Torgersen              186.0       3800.0\n#&gt; 2  2007  female  Adelie  Torgersen              195.0       3250.0\n\n# ncs.numeric() を使うことで、数値変数を指定できます\nprint(py4st.relocate(penguins_mini, ncs.numeric()))\n#&gt;    flipper_length_mm  body_mass_g  year species     island     sex\n#&gt; 0              181.0       3750.0  2007  Adelie  Torgersen    male\n#&gt; 1              186.0       3800.0  2007  Adelie  Torgersen  female\n#&gt; 2              195.0       3250.0  2007  Adelie  Torgersen  female\n\n# year 列を island 列の直前に移動\nprint(py4st.relocate(penguins_mini, 'year', before = 'island'))\n#&gt;   species  year     island  flipper_length_mm  body_mass_g     sex\n#&gt; 0  Adelie  2007  Torgersen              181.0       3750.0    male\n#&gt; 1  Adelie  2007  Torgersen              186.0       3800.0  female\n#&gt; 2  Adelie  2007  Torgersen              195.0       3250.0  female\n\n# year 列を island 列の直後に移動\nprint(py4st.relocate(penguins_mini, 'year', after = 'island'))\n#&gt;   species     island  year  flipper_length_mm  body_mass_g     sex\n#&gt; 0  Adelie  Torgersen  2007              181.0       3750.0    male\n#&gt; 1  Adelie  Torgersen  2007              186.0       3800.0  female\n#&gt; 2  Adelie  Torgersen  2007              195.0       3250.0  female\n\n#.  place = 'last' で最後列に移動\nprint(py4st.relocate(penguins_mini, 'year', place = 'last'))\n#&gt;   species     island  flipper_length_mm  body_mass_g     sex  year\n#&gt; 0  Adelie  Torgersen              181.0       3750.0    male  2007\n#&gt; 1  Adelie  Torgersen              186.0       3800.0  female  2007\n#&gt; 2  Adelie  Torgersen              195.0       3250.0  female  2007\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>relocate</span>"
    ]
  },
  {
    "objectID": "man/compare_df_cols.html",
    "href": "man/compare_df_cols.html",
    "title": "compare_df_cols, compare_df_stats",
    "section": "",
    "text": "概要\nデータ型と統計値によるデータフレームの比較\nR言語の janitor::compare_df_cols() をオマージュした関数で、compare_df_cols() は複数の pandas.DataFrame に含まれる同じ名前を持つ列同士のデータ型 dtype を比較し、compare_df_stats() は同じ名前を持つ列同士の記述統計量を比較します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>compare_df_cols, compare_df_stats</span>"
    ]
  },
  {
    "objectID": "man/compare_df_cols.html#概要",
    "href": "man/compare_df_cols.html#概要",
    "title": "compare_df_cols, compare_df_stats",
    "section": "",
    "text": "compare_df_cols(\n    df_list: Union[List[IntoFrameT], Mapping[str, IntoFrameT]],\n    df_name: Optional[List[str]] = None,\n    return_match: Literal[\"all\", \"match\", \"mismatch\"] = 'all',\n    dropna:bool = False,\n    to_native: bool = True\n)\n\ncompare_df_stats(\n    df_list: List[IntoFrameT],\n    df_name: Optional[List[str]] = None,\n    return_match: Literal[\"all\", \"match\", \"mismatch\"] = \"all\",\n    stats: Callable[..., Any] = np.mean,\n    rtol: float = 1e-05,\n    atol: float = 1e-08,\n    to_native: bool = True,\n    **kwargs: Any,\n)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>compare_df_cols, compare_df_stats</span>"
    ]
  },
  {
    "objectID": "man/compare_df_cols.html#引数-argument",
    "href": "man/compare_df_cols.html#引数-argument",
    "title": "compare_df_cols, compare_df_stats",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndf_list（必須） A list or dict of IntoFrameT  　列を比較するデータフレームのリストもしくは辞書オブジェクト。辞書が df_name が未指定の場合、辞書の keys を df_name として使用します。\ndf_name list of str  　表頭に表示するデータフレームの名前。['df1', 'df2'] のように文字列のリストを指定してください。初期設定では、自動的に df1, df2, df3 … と連番が割り当てられます。\nreturn_match str  　出力に反映する変数の範囲を表す文字列。次の値から選択できます。\n\n'all'（初期設定）： 全ての列を表示。\n'match'：全てのデータフレームで dtype が一致している列のみを表示。\n'mismatch'：少なくとも1つのデータフレームで dtype が一致していない列のみを表示。\n\ndropna bool (compare_df_cols() のみ) 　データ型 dtype の一致判定に当たり、NaN を無視するかどうか。初期設定 False の場合、すべてのデータフレームが同名かつ同じデータ型の列を持たない限り、ミスマッチが発生したと判定されます。\nstats str or function 　比較に用いる記述統計量を定義する関数。np.mean など values 列を1次元配列として受け取って単一の数値を返す任意の関数が使用できるほか、nw.mean など narwhals.functions モジュールで実装された関数を使用できます。初期設定は np.mean です。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>compare_df_cols, compare_df_stats</span>"
    ]
  },
  {
    "objectID": "man/compare_df_cols.html#使用例-examples",
    "href": "man/compare_df_cols.html#使用例-examples",
    "title": "compare_df_cols, compare_df_stats",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport pandas as pd\nimport py4stats as py4st\n\ndf1 = pd.DataFrame({'x':[1, 2, 3], 'y':[5,   4, 2], 'z':[True, False, True]})\ndf2 = pd.DataFrame({'x':[1, 2, 3], 'y':[5.0, 4, 2], 'z':['True', 'False', 'True']})\n\nprint(py4st.compare_df_cols([df1, df2]))\n#&gt;   term    df1      df2  match_dtype\n#&gt; 0    x  int64    int64         True\n#&gt; 1    y  int64  float64        False\n#&gt; 2    z   bool   object        False\nreturn_match = 'mismatch' を指定すると、データフレームの中で、dtype が一致していないものがある列を返します。\nprint(py4st.compare_df_cols(\n    [df1, df2], return_match = 'mismatch'\n    ))\n#&gt;   term    df1      df2  match_dtype\n#&gt; 1    y  int64  float64        False\n#&gt; 2    z   bool   object        False\n　py4st.compare_df_stats() は数値変数の記述統計量を比較するため、異なる経路で行われたデータ処理の結果が一致しているかを検証する場合に便利です。\nfrom palmerpenguins import load_penguins\npenguins = load_penguins()\npenguins2 = penguins.copy()\nvars = ['flipper_length_mm', 'body_mass_g']\npenguins2.loc[:, vars] = py4st.scale(penguins2.loc[:, vars])\n\nprint(\n    py4st.compare_df_stats([penguins, penguins2]).round(2)\n)\n#&gt;                 term      df1      df2  match_stats\n#&gt; 0      bill_depth_mm    17.15    17.15         True\n#&gt; 1     bill_length_mm    43.92    43.92         True\n#&gt; 2        body_mass_g  4201.75     0.00        False\n#&gt; 3  flipper_length_mm   200.92    -0.00        False\n#&gt; 4               year  2008.03  2008.03         True\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>compare_df_cols, compare_df_stats</span>"
    ]
  },
  {
    "objectID": "man/review_wrangling.html",
    "href": "man/review_wrangling.html",
    "title": "review_wrangling",
    "section": "",
    "text": "概要\nデータ前処理（wrangling）による変更点をレビュー形式で要約して、文字列として出力する関数です。\nこの関数は、前処理の前後（before / after）の DataFrame（相当）を比較し、変更点をユーザーが読みやすいレポート文字列として返します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>review_wrangling</span>"
    ]
  },
  {
    "objectID": "man/review_wrangling.html#概要",
    "href": "man/review_wrangling.html#概要",
    "title": "review_wrangling",
    "section": "",
    "text": "review_wrangling(\n        before: IntoFrameT, \n        after: IntoFrameT, \n        title: str = 'Review of wrangling',\n        abbreviate: bool = True,\n        max_columns: Optional[int] = None,\n        max_categories: Optional[int] = None,\n        max_width: int = 80\n        ) -&gt; str",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>review_wrangling</span>"
    ]
  },
  {
    "objectID": "man/review_wrangling.html#引数-argument",
    "href": "man/review_wrangling.html#引数-argument",
    "title": "review_wrangling",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nbefore:IntoFrameT（必須） 前処理（wrangling）を行う前のデータフレーム。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\nafter:IntoFrameT（必須） 前処理（wrangling）を行った後のデータフレーム。\ntitle:str 出力されるレビューテキストのタイトル。空でない文字列を指定した場合、タイトルとともにヘッダーとフッターが追加されます。\nabbreviate：bool 列名やカテゴリー水準の一覧を省略表示するかどうかを指定します。False を指定した場合、省略は行われず、すべての項目が表示されます。デフォルトは True です。\nmax_columns:int 列の追加・削除を報告する際に表示する列名の最大数。指定された場合、abbreviate = True のときに限り、文字数ではなく列数を基準として省略が行われます。None の場合は文字数（max_width）に基づいて省略されます。\nmax_categories:int カテゴリー変数の水準の変化を報告する際に、表示する水準の最大数。指定された場合、abbreviate=True のときに限り、文字数ではなく水準数を基準として省略が行われます。None の場合は文字数（max_width）に基づいて省略されます。\nmax_width:int abbreviate=True かつ対応する max_* 引数が None の場合に使用される、省略判定のための最大文字数。デフォルトは 80 です。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>review_wrangling</span>"
    ]
  },
  {
    "objectID": "man/review_wrangling.html#返り値-value",
    "href": "man/review_wrangling.html#返り値-value",
    "title": "review_wrangling",
    "section": "返り値 Value",
    "text": "返り値 Value\nbefore と after の差分を要約した、整形済みの複数行文字列。レビューに含まれる主な項目は次のとおりです。\n\nデータフレームの形状（行数・列数）の変化\n列の追加・削除\n既存列のデータ型（dtype）の変化\n欠測値の増加・減少\nカテゴリー変数における水準の増加・減少",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>review_wrangling</span>"
    ]
  },
  {
    "objectID": "man/review_wrangling.html#使用例-examples",
    "href": "man/review_wrangling.html#使用例-examples",
    "title": "review_wrangling",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport py4stats as py4st\nfrom palmerpenguins import load_penguins\n\nbefore = load_penguins() # サンプルデータの読み込\nafter = before.copy().dropna()\nreview_wrangling() 関数は前処理前後のデータフレームを比較し、上記の4項目に関する変化をレビューとして出力します。各項目の変化を報告しますが、変化がなかった場合にも変化がなかったことを報告するようにしています。\nprint(py4st.review_wrangling(before, after))\n#&gt; =================== Review of wrangling ====================\n#&gt; The shape of DataFrame:\n#&gt;    Rows: before 344 -&gt; after 333 (-11)\n#&gt;    Cols: before   8 -&gt; after   8 (No change)\n#&gt; \n#&gt; No columns were added or removed.\n#&gt; \n#&gt; No existing columns had their type changed.\n#&gt; \n#&gt; No existing columns increased the number of missing values.\n#&gt; \n#&gt; Decrease in missing values:\n#&gt;   bill_length_mm     before  2 (0.58%) -&gt; after 0 (0.00%)\n#&gt;   bill_depth_mm      before  2 (0.58%) -&gt; after 0 (0.00%)\n#&gt;   flipper_length_mm  before  2 (0.58%) -&gt; after 0 (0.00%)\n#&gt;   body_mass_g        before  2 (0.58%) -&gt; after 0 (0.00%)\n#&gt;   sex                before 11 (3.20%) -&gt; after 0 (0.00%)\n#&gt; \n#&gt; The following columns show changes in categories:\n#&gt;   sex:\n#&gt;     addition:  None\n#&gt;     removal:  'nan'\n#&gt; ============================================================\nafter = py4st.filtering_out(after, 'sex')\n\ns = after['body_mass_g']\nafter['heavy'] = np.where(s &gt;= s.quantile(0.75), True, False)\nafter['species'] = pd.Categorical(after['species'])\nafter['year'] = after['year'].astype(float)\nafter['const'] = 1\n\nafter['flipper_length_mm'] = py4st.set_miss(\n    after['flipper_length_mm'], prop = 0.1,\n    random_state = 1230\n    )\n\nafter = after.query('species != \"Adelie\"')\nreview_wrangling() では、カテゴリー変数についてユニーク値の変化を追っているため、データの抽出による暗黙的なカテゴリーの除外（e.g. species = 'Adelie' を除外したことで island = 'Torgersen' が除外された）も報告することができます。\nprint(py4st.review_wrangling(before, after))\n#&gt; ================== Review of wrangling ===================\n#&gt; The shape of DataFrame:\n#&gt;    Rows: before 344 -&gt; after 187 (-157)\n#&gt;    Cols: before   8 -&gt; after   9 (+1)\n#&gt; \n#&gt; Column additions and removals:\n#&gt;   added:   'heavy' and 'const'\n#&gt;   removed: 'sex'\n#&gt; \n#&gt; The following columns have changed their type:\n#&gt;   species object -&gt; category\n#&gt;   year    int64 -&gt; float64\n#&gt; \n#&gt; Increase in missing values:\n#&gt;   flipper_length_mm  before 2 (0.58%) -&gt; after 22 (11.76%)\n#&gt; \n#&gt; Decrease in missing values:\n#&gt;   bill_length_mm  before 2 (0.58%) -&gt; after 0 (0.00%)\n#&gt;   bill_depth_mm   before 2 (0.58%) -&gt; after 0 (0.00%)\n#&gt;   body_mass_g     before 2 (0.58%) -&gt; after 0 (0.00%)\n#&gt; \n#&gt; The following columns show changes in categories:\n#&gt;   species:\n#&gt;     addition:  None\n#&gt;     removal:  'Adelie'\n#&gt;   island:\n#&gt;     addition:  None\n#&gt;     removal:  'Torgersen'\n#&gt; ==========================================================\nデータセットから除外された列が多い場合、レビューテキストの視認性を維持するために列名の一部が省略表記されます。\nmroz = wooldridge.data('mroz')\n\nprint(py4st.review_wrangling(\n    mroz, mroz.loc[:, 'inlf':'wage']\n    ))\n#&gt; ================================ Review of wrangling =================================\n#&gt; The shape of DataFrame:\n#&gt;    Rows: before 753 -&gt; after 753 (No change)\n#&gt;    Cols: before  22 -&gt; after   7 (-15)\n#&gt; \n#&gt; Column additions and removals:\n#&gt;   No columns were added. \n#&gt;   removed: 'repwage', 'hushrs', 'husage', 'huseduc', 'huswage' and other 10 column(s)\n#&gt; \n#&gt; No existing columns had their type changed.\n#&gt; \n#&gt; No existing columns decreased the number of missing values.\n#&gt; \n#&gt; No columns had categories added or removed.\n#&gt; ======================================================================================",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>review_wrangling</span>"
    ]
  },
  {
    "objectID": "man/review_wrangling.html#notes",
    "href": "man/review_wrangling.html#notes",
    "title": "review_wrangling",
    "section": "Notes",
    "text": "Notes\n\n本関数では、before と after が同一の DataFrame バックエンド（例：どちらも pandas、またはどちらも polars）であることを前提としています。異なるバックエンドを混在させた場合、エラーが発生します。\nreview_wrangling() 関数は、行（レコード）単位の差分（値の変更・削除など）を追跡していません。これは、レコード単位の差分を追跡するためには index が必要になり、特定のバックエンド（e.g. Pandas）への依存が生じることと、前処理では行の並び替えや index の再設定によって before と after のレコード対応付けが曖昧になりやすいことが理由です。そのため、本関数は個々のレコードの変化ではなく、データセット全体に生じた構造的な変化をレビューする関数として設計しています。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>review_wrangling</span>"
    ]
  },
  {
    "objectID": "man/review_wrangling.html#参考-see-also",
    "href": "man/review_wrangling.html#参考-see-also",
    "title": "review_wrangling",
    "section": "参考 See also",
    "text": "参考 See also\n列のデータ型に基づいた比較については compare_df_cols() を、数値変数の統計値に基づいた比較については compare_df_stats() もご参照ください。\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>review_wrangling</span>"
    ]
  },
  {
    "objectID": "man/compare_group_stats.html",
    "href": "man/compare_group_stats.html",
    "title": "compare_group_means, _median plot_mean_diff, _median_diff",
    "section": "",
    "text": "概要\n統計量に基づく2グループの比較と差分の可視化\nこれら関数は、入力された2つのデータフレームについて、各数値変数の統計量に基づいた比較を提供します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>compare_group_means, _median<br> plot_mean_diff, _median_diff</span>"
    ]
  },
  {
    "objectID": "man/compare_group_stats.html#概要",
    "href": "man/compare_group_stats.html#概要",
    "title": "compare_group_means, _median plot_mean_diff, _median_diff",
    "section": "",
    "text": "compare_group_means(\n    group1: IntoFrameT,\n    group2: IntoFrameT,\n    group_names: Sequence[str] = ('group1', 'group2'),\n    columns: Literal['common', 'all'] = 'all',\n    to_native: bool = True\n    )\n\ncompare_group_median(\n    group1: IntoFrameT,\n    group2: IntoFrameT,\n    group_names: Sequence[str] = ('group1', 'group2'),\n    columns: Literal['common', 'all'] = 'all',\n    to_native: bool = True\n    )\n\nplot_mean_diff(\n    group1: IntoFrameT,\n    group2: IntoFrameT,\n    stats_diff: Literal[\"norm_diff\", \"abs_diff\", \"rel_diff\"] = \"norm_diff\",\n    ax: Optional[Axes] = None,\n    )\n\nplot_median_diff(\n    group1: IntoFrameT,\n    group2: IntoFrameT,\n    stats_diff: Literal[\"abs_diff\", \"rel_diff\"] = \"rel_diff\",\n    ax: Optional[Axes] = None,\n    )",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>compare_group_means, _median<br> plot_mean_diff, _median_diff</span>"
    ]
  },
  {
    "objectID": "man/compare_group_stats.html#引数-argument",
    "href": "man/compare_group_stats.html#引数-argument",
    "title": "compare_group_means, _median plot_mean_diff, _median_diff",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ngroup1（必須）a pandas.DataFrame  　数値変数を含む pandas.DataFrame で group2 との比較対象となるもの\ngroup2（必須）a pandas.DataFrame  　数値変数を含む pandas.DataFrame で group1 との比較対象となるもの\ngroup_names list of str  　表頭に表示するグループの名前。['group1', 'group2'] のように、2つの要素をもつ文字列のリストとして指定してください。\ncolumns str  2つのグループの結果を結合する際に含める変数を指定します。\n\n\"common\": 両方のグループに存在する変数のみが含まれます。\n\"all\": いずれかのグループに存在する全ての変数が含まれます。この場合、一方のグループにのみ存在する変数についての差分統計量は、欠損値（例：NaN または None）となります。\n\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。\nstats_diff: str （plot_mean_diff() および plot_median_diff() のみ） 　グラフの描画に使用する差分統計量。'norm_diff'（plot_mean_diff() のみ）、'abs_diff', 'rel_diff' のいずれかから選ぶことができます。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>compare_group_means, _median<br> plot_mean_diff, _median_diff</span>"
    ]
  },
  {
    "objectID": "man/compare_group_stats.html#返り値-value",
    "href": "man/compare_group_stats.html#返り値-value",
    "title": "compare_group_means, _median plot_mean_diff, _median_diff",
    "section": "返り値 Value",
    "text": "返り値 Value\n　compare_group_means()関数および, compare_group_median() 関数では、次の値をもつ pandas.DataFrame が出力されます。\n\ngroup1, group2（初期設定の場合） 　各グループにおける記述統計統計量の値\nnorm_diff（compare_group_means() のみ） 　標準化された平均値の差で、2つのグループの平均値を \\(\\bar{X}_1\\), \\(\\bar{X}_2\\)、分散を \\(s^2_1, s^2_2\\) とし、サンプルサイズを \\(n_1, n_2\\) とするとき、次式のように定義されます。\n\n\\[\n\\delta = \\frac{\\bar{X}_1  - \\bar{X}_2}{s},~~~~~ s^2 = \\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}\n\\]\n\nabs_diff 2つのグループの記述統計量の絶対差\nrel_diff 2つのグループの記述統計量の相対差。2つのグループの記述統計量を \\(\\bar{X}_1\\), \\(\\bar{X}_2\\) とするとき、次式のように定義されます。\n\n\\[\n\\delta = \\cfrac{\\bar{X}_1  - \\bar{X}_2}{\\cfrac{\\bar{X}_1  + \\bar{X}_2}{2}}\n= 2 \\cdot \\frac{\\bar{X}_1  - \\bar{X}_2}{\\bar{X}_1  + \\bar{X}_2}\n\\]\nplot_mean_diff() 関数および, plot_median_diff() 関数では、グループ別の記述統計両の差をグラフとして可視化します。詳細は使用例を参照して下さい。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>compare_group_means, _median<br> plot_mean_diff, _median_diff</span>"
    ]
  },
  {
    "objectID": "man/compare_group_stats.html#使用例-examples",
    "href": "man/compare_group_stats.html#使用例-examples",
    "title": "compare_group_means, _median plot_mean_diff, _median_diff",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport pandas as pd\nimport py4stats as py4st\nfrom palmerpenguins import load_penguins\n\npenguins = load_penguins().drop('year', axis = 1) # サンプルデータの読み込み\nres1 = py4st.compare_group_means(\n    penguins.query('species == \"Gentoo\"'),\n    penguins.query('species == \"Adelie\"')\n)\nprint(res1.round(3))\n#&gt;             variable    group1    group2  norm_diff  abs_diff  rel_diff\n#&gt; 0      bill_depth_mm    14.982    18.346     -3.012     3.364    -0.202\n#&gt; 1     bill_length_mm    47.505    38.791      3.048     8.713     0.202\n#&gt; 2        body_mass_g  5076.016  3700.662      2.868  1375.354     0.313\n#&gt; 3  flipper_length_mm   217.187   189.954      4.180    27.233     0.134\nres2 = py4st.compare_group_median(\n    penguins.query('species == \"Gentoo\"'),\n    penguins.query('species == \"Adelie\"'),\n    group_names = ['Gentoo', 'Adelie']\n)\nprint(res2.round(3))\n#&gt;             variable    Gentoo    Adelie  abs_diff  rel_diff\n#&gt; 0      bill_depth_mm    14.982    18.346     3.364    -0.202\n#&gt; 1     bill_length_mm    47.505    38.791     8.713     0.202\n#&gt; 2        body_mass_g  5076.016  3700.662  1375.354     0.313\n#&gt; 3  flipper_length_mm   217.187   189.954    27.233     0.134\npy4st.plot_mean_diff(\n    penguins.query('species == \"Gentoo\"'),\n    penguins.query('species == \"Adelie\"'),\n    stats_diff = 'norm_diff'\n)\n\n\n\nplot_mean_diff1\n\n\npy4st.plot_mean_diff(\n    penguins.query('species == \"Gentoo\"'),\n    penguins.query('species == \"Adelie\"'),\n    stats_diff = 'abs_diff'\n)\n\n\n\nplot_mean_diff2\n\n\npy4st.plot_median_diff(\n    penguins.query('species == \"Gentoo\"'),\n    penguins.query('species == \"Adelie\"'),\n    stats_diff = 'rel_diff'\n)\n\n\n\nplot_median_diff1\n\n\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>compare_group_means, _median<br> plot_mean_diff, _median_diff</span>"
    ]
  },
  {
    "objectID": "man/plot_miss_var.html",
    "href": "man/plot_miss_var.html",
    "title": "plot_miss_var",
    "section": "",
    "text": "概要\nR言語の naniar::gg_miss_var() をオマージュした関数で、データフレームの各変数について欠測値の量を横棒グラフとして可視化します。欠損値統計の計算には py4stats.diagnose() を使用しています。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>plot_miss_var</span>"
    ]
  },
  {
    "objectID": "man/plot_miss_var.html#概要",
    "href": "man/plot_miss_var.html#概要",
    "title": "plot_miss_var",
    "section": "",
    "text": "plot_miss_var(\n    data: IntoFrameT,\n    values: Literal['missing_percent', 'missing_count'] = 'missing_percent', \n    sort: bool = True, \n    miss_only: bool = False, \n    top_n: Optional[int] = None,\n    fontsize: int = 12,\n    ax: Optional[Axes] = None,\n    color: str = '#478FCE',\n    **kwargs: Any\n)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>plot_miss_var</span>"
    ]
  },
  {
    "objectID": "man/plot_miss_var.html#引数-argument",
    "href": "man/plot_miss_var.html#引数-argument",
    "title": "plot_miss_var",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\nnormalize：str 　グラフに表示する値の種類。\n\nmissing_percent 列毎の欠測率をパーセンテージで表示します。\ncolumns 列毎の欠測数を表示します。\n\nsort：bool プロット前に選択した指標で列をソートするかどうか。初期設定は True です。。\nmiss_only：bool 欠測値を含まない列を除外するかどうか。True だと欠測値を含まない列を除外し、False（初期設定）だと省略せずに全ての列を表示します。\ntop_n：int 棒グラフを表示するグラフの個数。top_n = None（初期設定）の場合、すべての棒グラフを表示し、整数値が指定された場合、欠測率（数）の上位 top_n 件が表示されます。\nax 　matplotlib の ax オブジェクト。複数のグラフを並べる場合などに使用します。\nfontsize：int 　軸ラベルなどのフォントサイズ。\npalette：list of str 　グラフの描画に使用する色コード。棒グラフの色に対応します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>plot_miss_var</span>"
    ]
  },
  {
    "objectID": "man/plot_miss_var.html#使用例-example",
    "href": "man/plot_miss_var.html#使用例-example",
    "title": "plot_miss_var",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込\n\npy4st.plot_miss_var(penguins)\n\n\n\nplot_miss_var1\n\n\npy4st.plot_miss_var(penguins, values = 'missing_count', miss_only = True)\n\n\n\nplot_miss_var2\n\n\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>plot_miss_var</span>"
    ]
  },
  {
    "objectID": "man/set_miss.html",
    "href": "man/set_miss.html",
    "title": "set_miss",
    "section": "",
    "text": "概要\nSeries オブジェクトに対する欠測値の挿入\nこの関数は、Series の非欠測要素のうち、指定された個数または割合を欠測値に置き換えます。narwhals を利用することで、複数の Series バックエンドに対応しています。主にテストデータの作成や、欠測データのシミュレーションを目的とした関数です。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>set_miss</span>"
    ]
  },
  {
    "objectID": "man/set_miss.html#概要",
    "href": "man/set_miss.html#概要",
    "title": "set_miss",
    "section": "",
    "text": "set_miss(\n    x: IntoSeriesT, \n    n: Optional[int] = None,\n    prop: Optional[float] = None, \n    method: Literal['random', 'first', 'last'] = 'random', \n    random_state: Optional[int] = None, \n    na_value: Any = None,\n    to_native: bool = True\n    )",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>set_miss</span>"
    ]
  },
  {
    "objectID": "man/set_miss.html#引数-argument",
    "href": "man/set_miss.html#引数-argument",
    "title": "set_miss",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 入力データ。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\nn：int  処理後の Series に含まれる欠測値の目標個数。すでに n 個以上の欠測値が含まれている場合は、新たな欠測値は追加されず、警告が発せられます。\nprop：float  処理後の Series に含まれる欠測値の目標割合。0 から 1 の間で指定してください。すでに欠測値の割合が prop 以上である場合は、新たな欠測値は追加されず、警告が発せられます。\nmethod: str: 欠測値に置き換える要素の選択方法。\n\n'random': 非欠測要素の中からランダムに選択します。\n'first': Series の先頭から選択します。\n'last': Series の末尾から選択します。 デフォルトは 'random' です。\n\nrandom_state (int, optional): method = 'random' の場合に使用する乱数シード。再現性のある結果を得るために指定できます。 method が 'random' 以外の場合、random_state は無視されます。\nna_value: (Any) 欠測値として使用する値。デフォルトは None です。\nto_native（bool, optional） True の場合、入力と同じ型の Series（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.Series を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>set_miss</span>"
    ]
  },
  {
    "objectID": "man/set_miss.html#使用例-example",
    "href": "man/set_miss.html#使用例-example",
    "title": "set_miss",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport pandas as pd\nfrom py4stats import set_miss\ns = pd.Series([1, 2, 3, 4, 5])\npy4st.set_miss(s, n = 2, method='first')\n#&gt; 0    NaN\n#&gt; 1    NaN\n#&gt; 2    3.0\n#&gt; 3    4.0\n#&gt; 4    5.0\n#&gt; dtype: float64\n\ns_miss = py4st.set_miss(s, prop=0.4, method='random', random_state=0)\n#&gt; 0    1.0\n#&gt; 1    NaN\n#&gt; 2    3.0\n#&gt; 3    NaN\n#&gt; 4    5.0\n#&gt; dtype: float64\nx に代入された Series オブジェクトに、既に指定された以上の欠測値が含まれていた場合、次のように欠測値を追加せず UserWarning を出します。\npy4st.set_miss(s_miss, n = 2)\n#&gt; UserWarning: Already contained 2(&gt;= n) missing value(s) in `x`, \n#&gt; no additional missing values were added.\n#&gt; 0    1.0\n#&gt; 1    NaN\n#&gt; 2    3.0\n#&gt; 3    NaN\n#&gt; 4    5.0\n#&gt; dtype: float64\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込\n\npenguins['island'] = py4st.set_miss(\n    penguins['island'], \n    n = 100, method='first'\n    )\npy4st.plot_miss_var(penguins, values = 'missing_count')\n\n\n\nset_miss",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>set_miss</span>"
    ]
  },
  {
    "objectID": "man/scale_wmean.html",
    "href": "man/scale_wmean.html",
    "title": "weighted_mean, scale, min_max",
    "section": "",
    "text": "概要\n加重平均と標準化・正規化ユーティリティ\n探索的データ解析（EDA）で頻繁に用いられる加重平均の計算および 数値データの正規化・標準化を行う関数群です。 内部では narwhals を利用することで、pandas・polars など複数のデータフレーム／シリーズ実装に対して共通の API を提供しています。\nweighted_mean(): 数値系列 x と対応する重み w を用いて、加重平均を計算します。欠損値の扱いを制御するためのオプションを備えています。\nscale(): 数値データを Z スコア標準化します。系列データを主な対象としますが、pandas.DataFrame に対しても専用実装により列単位での標準化をサポートしています。\nmin_max(): 数値データを Min-Max Normarization により \\([0, 1]\\) の範囲に変換します。scale() と同様に、Series を主対象としつつ pandas.DataFrame にも対応しています。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>weighted_mean, scale, min_max</span>"
    ]
  },
  {
    "objectID": "man/scale_wmean.html#概要",
    "href": "man/scale_wmean.html#概要",
    "title": "weighted_mean, scale, min_max",
    "section": "",
    "text": "weighted_mean(\n    x: IntoSeriesT, \n    w: IntoSeriesT, \n    dropna:bool = False\n    ) -&gt; float:\n\nscale(\n    x: Union[IntoSeriesT, pd.DataFrame], \n    ddof: int = 1, to_native: bool = True\n    ) -&gt; IntoSeriesT:\n\nmin_max(\n    x: Union[IntoSeriesT, pd.DataFrame], \n    to_native: bool = True\n    ) -&gt; IntoSeriesT:",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>weighted_mean, scale, min_max</span>"
    ]
  },
  {
    "objectID": "man/scale_wmean.html#引数-argument",
    "href": "man/scale_wmean.html#引数-argument",
    "title": "weighted_mean, scale, min_max",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nx：IntoSeriesT or pd.DataFrame（必須）\n\nnarwhals が受け入れ可能な Series 互換オブジェクト（例：pandas.Series、polars.Series）を指定できます。scale()関数と min_max()関数のみ pandas.DataFrame を指定することができ、この場合、各列ごとに変換が適用されます。\n\nw：IntoSeriesT（必須） x に対応する重みを表す数値系列。x と同じ長さである必要があります。narwhals が受け入れ可能な Series 互換オブジェクト（例：pandas.Series、polars.Series）を指定できます。\nddof（int, optional）scale(), min_max() のみ  標準偏差の計算に用いる自由度調整量（delta degrees of freedom）。デフォルトは 1 です。\ndropna（bool, optional）scale(), min_max() のみ  True の場合、x または w のいずれかが欠損値（NaN）である観測を計算前に除外します。デフォルトは False です。\nto_native（bool, optional）scale(), min_max() のみ  True の場合、入力と同じ型の Series（e.g. pandas / polars / pyarrow）を返します。 False の場合、nw.Series を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>weighted_mean, scale, min_max</span>"
    ]
  },
  {
    "objectID": "man/scale_wmean.html#返り値-value",
    "href": "man/scale_wmean.html#返り値-value",
    "title": "weighted_mean, scale, min_max",
    "section": "返り値 Value",
    "text": "返り値 Value\n\nweighted_mean\n\nfloat\n加重平均\n\nscale\n\nIntoSeriesT\n平均 0、標準偏差 1 に標準化された値を返します。\n\nmin_max\n\nIntoSeriesT\n最小値が 0、最大値が 1 となるよう正規化された値を返します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>weighted_mean, scale, min_max</span>"
    ]
  },
  {
    "objectID": "man/scale_wmean.html#使用例-example",
    "href": "man/scale_wmean.html#使用例-example",
    "title": "weighted_mean, scale, min_max",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込\n\nx1 = penguins.groupby('species')['bill_length_mm'].mean()\nw = penguins.groupby('species')['bill_length_mm'].count()\n\nprint(\n    f\"{py4st.weighted_mean(x1, w) :.2f}, \"\n    f\"{penguins['bill_length_mm'].mean() :.2f}\"\n)\n#&gt; 43.92, 43.92\n\nx2 = penguins['bill_length_mm']\nz1 = py4st.scale(x2)\nprint(f\"{z1.mean():.2f}, {z1.std():.2f}\")\n#&gt; 0.00, 1.00\n\nz2 = py4st.min_max(x2)\nprint(f\"{z2.min():.2f}, {z2.max():.2f}\")\n#&gt; 0.00, 1.00",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>weighted_mean, scale, min_max</span>"
    ]
  },
  {
    "objectID": "man/predicate_str.html",
    "href": "man/predicate_str.html",
    "title": "is_number, is_ymd, is_ymd_like",
    "section": "",
    "text": "概要\n文字列のフォーマットに判定する論理関数\nSeries の要素が、特定のフォーマットにそった文字列かどうかを判定する関数です。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>is_number, is_ymd,  is_ymd_like</span>"
    ]
  },
  {
    "objectID": "man/predicate_str.html#概要",
    "href": "man/predicate_str.html#概要",
    "title": "is_number, is_ymd, is_ymd_like",
    "section": "",
    "text": "is_number(\n  data:IntoSeriesT, \n  na_default:bool = True, \n  to_native: bool = True\n  )\n\nis_ymd(\n  data:IntoSeriesT, \n  na_default:bool = True, \n  to_native: bool = True\n  )\n\nis_ymd_like(\n  data:IntoSeriesT, \n  na_default:bool = True, \n  to_native: bool = True\n  )\n\npy4stats.is_number()：与えられた文字列が数字かどうかを判定します。\npy4stats.is_ymd()：与えられた文字列が yyyy-mm-dd フォーマットにそった値かどうかを判定します。\npy4stats.is_ymd_like()：与えられた文字列が’2024年3月3日’ のような yyyy-mm-dd に近いフォーマットの値かどうかを判定します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>is_number, is_ymd,  is_ymd_like</span>"
    ]
  },
  {
    "objectID": "man/predicate_str.html#引数-argument",
    "href": "man/predicate_str.html#引数-argument",
    "title": "is_number, is_ymd, is_ymd_like",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoSeriesT（必須）\n入力データ。narwhals が受け入れ可能な Series 互換オブジェクト （例：pandas.Series、polars.DataFrame、pyarrow.Table）を指定できます。\nna_default：bool 　NA値に対して関数が返す値。na_default = True （初期設定）であれば None や NaN には True を返し、na_default = False であれば False が返します。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>is_number, is_ymd,  is_ymd_like</span>"
    ]
  },
  {
    "objectID": "man/predicate_str.html#使用例-example",
    "href": "man/predicate_str.html#使用例-example",
    "title": "is_number, is_ymd, is_ymd_like",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport pandas as pd\nimport numpy as np\n\ns = pd.Series([\n    '123', \"0.12\", \"1e+07\", '-31', '2個', '1A',\n    \"2024-03-03\", \"2024年3月3日\", \"24年3月3日\", '令和6年3月3日',\n    '0120-123-456', \"apple\", \"不明\", None, np.nan\n    ])\n\nprint(s[py4st.is_number(s)])\n#&gt; 0       123\n#&gt; 1      0.12\n#&gt; 2     1e+07\n#&gt; 3       -31\n#&gt; 13     None\n#&gt; 14      NaN\n#&gt; dtype: object\n\nprint(s[py4st.is_ymd(s)])\n#&gt; 6     2024-03-03\n#&gt; 13          None\n#&gt; 14           NaN\n#&gt; dtype: object\n\nprint(s[py4st.is_ymd_like(s)])\n#&gt; 6     2024-03-03\n#&gt; 7      2024年3月3日\n#&gt; 8        24年3月3日\n#&gt; 9       令和6年3月3日\n#&gt; 13          None\n#&gt; 14           NaN\n#&gt; dtype: object\n　実践的な使用例として「厚生労働省 ４．食中毒統計資料」のうち、2020年の食中毒事件一覧を考えます。東京都のデータを取り出て'摂食者数'の列を見ると、数字が並んでいるものの dtype は object となっており、数字ではない値が含まれていることが疑われます。\n# 厚生労働省：食中毒統計資料より\ndata = pd.read_excel('https://www.mhlw.go.jp/content/R2itiran.xlsx', header = 1)\\\n  .query('都道府県名等.str.contains(\"東京\")')\n\nprint(data['摂食者数'])\n#&gt; 280    41\n#&gt; 281    86\n#&gt; 282     3\n#&gt; 283    10\n#&gt; 284     3\n#&gt;        ..\n#&gt; 381     2\n#&gt; 382     2\n#&gt; 383     4\n#&gt; 384     6\n#&gt; 385     4\n#&gt; Name: 摂食者数, Length: 106, dtype: object\neda.is_number() を使うと数字以外にどのような値が含まれているかを確認できるため、これをもとに「不明」となっている部分は NaN に置き換えるなどの対処法が考えられます。\nprint(data.loc[~py4st.is_number(data['摂食者数']), '摂食者数'])\n#&gt; 285    不明\n#&gt; 315    不明\n#&gt; 374    不明\n#&gt; 375    不明\n#&gt; 377    不明\n#&gt; 378    不明\n#&gt; 379    不明\n#&gt; 380    不明\n#&gt; Name: 摂食者数, dtype: object\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>is_number, is_ymd,  is_ymd_like</span>"
    ]
  },
  {
    "objectID": "man/is_dummy.html",
    "href": "man/is_dummy.html",
    "title": "is_dummy",
    "section": "",
    "text": "概要\nダミー変数を判定する論理関数\nリストや Series の要素が、指定されたダミーコードのみで構成されたダミー変数かどうかを判定します。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>is_dummy</span>"
    ]
  },
  {
    "objectID": "man/is_dummy.html#概要",
    "href": "man/is_dummy.html#概要",
    "title": "is_dummy",
    "section": "",
    "text": "is_dummy(\n    data: Union[IntoFrameT, IntoSeriesT],\n    cording: Sequence[Any] = (0, 1),\n    dropna: bool = True,\n    to_pd_series: bool = False,\n    **kwargs\n    )",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>is_dummy</span>"
    ]
  },
  {
    "objectID": "man/is_dummy.html#引数-argument",
    "href": "man/is_dummy.html#引数-argument",
    "title": "is_dummy",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata: list, IntoFrameT or IntoSeriesT  入力データ。list あるいは、narwhals が受け入れ可能な DataFrame もしくは Series 互換オブジェクト\ncording: list  ダミーコードとして許容される値の集合。入力データに含まれる値の集合が、この集合と完全に一致する場合にダミー変数であると判定されます。デフォルトは (0, 1) です。\ndropna：bool 　欠測値（NaN）をコーディングの判定から除外するかどうかを表すブール値。初期設定は True です。\nto_pd_series: bool  data が DataFrame 場合の戻り値の形式を制御します。\n\nTrue の場合：列名をインデックスにもつ pandas.Series を返します\nFalse の場合：to_native の値に応じた値を出力します。\n\nto_native（bool, optional） data がデータ DataFrame 互換オブジェクトの場合の出力を制御します。 True の場合、data 同じバックエンドの Series（e.g. pandas / polars / pyarrow）を返します。 False の場合、nw.Series を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。\n**kwargs: 将来の拡張のために予約されたキーワード引数です。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>is_dummy</span>"
    ]
  },
  {
    "objectID": "man/is_dummy.html#返り値-value",
    "href": "man/is_dummy.html#返り値-value",
    "title": "is_dummy",
    "section": "返り値 Value",
    "text": "返り値 Value\n\ndata が Series-like の場合\n\n-指定されたダミーコードのみで構成されていれば True、それ以外の場合は False\n\ndata が DataFrame-like の場合 \n\nto_pd_Series = False のとき：各列ごとの判定結果を要素とする list[bool]\nto_pd_Series = True のとき：列名をインデックスにもつ pd.Series",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>is_dummy</span>"
    ]
  },
  {
    "objectID": "man/is_dummy.html#使用例-examples",
    "href": "man/is_dummy.html#使用例-examples",
    "title": "is_dummy",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport py4stats as py4st\nimport pandas as pd\nfrom palmerpenguins import load_penguins\n\npenguins = load_penguins() # サンプルデータの読み込み\n\n# ダミー変数の作成\npenguins2 = pd.get_dummies(\n    penguins.loc[:, 'species':'bill_length_mm'], \n    columns = ['species']\n    )\npenguins2['Intercept'] = 1 # 定数列の作成\npenguins2['female'] = penguins['sex'] == 'female' # bool 型の変数を作成\n\nprint(py4st.is_dummy(penguins2['species_Adelie']))\n#&gt; True\nなお、初期設定では bool 型の変数についても True が出力されます。\nprint(py4st.is_dummy(penguins2))\n#&gt; island               False\n#&gt; bill_length_mm       False\n#&gt; species_Adelie        True\n#&gt; species_Chinstrap     True\n#&gt; species_Gentoo        True\n#&gt; Intercept            False\n#&gt; female                True\n#&gt; Name: 0, dtype: bool\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>is_dummy</span>"
    ]
  },
  {
    "objectID": "man/varidate.html",
    "href": "man/varidate.html",
    "title": "check_that check_viorate",
    "section": "",
    "text": "概要\n簡易なルールベースのデータ検証ツール\nR言語の varidateパッケージの check_that() 関数などをオマージュした、ごく簡易なデータ検証関数です。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>check_that check_viorate</span>"
    ]
  },
  {
    "objectID": "man/varidate.html#概要",
    "href": "man/varidate.html#概要",
    "title": "check_that check_viorate",
    "section": "",
    "text": "check_that(\n    data: IntoFrameT,\n    rule_dict: Union[Mapping[str, str], pd.Series],\n    **kwargs: Any,\n)\n\ncheck_viorate(\n    data: IntoFrameT,\n    rule_dict: Union[Mapping[str, str], pd.Series],\n    **kwargs: Any,\n)",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>check_that check_viorate</span>"
    ]
  },
  {
    "objectID": "man/varidate.html#引数-argument",
    "href": "man/varidate.html#引数-argument",
    "title": "check_that check_viorate",
    "section": "引数 Argument",
    "text": "引数 Argument\n\ndata：IntoFrameT（必須） 　ルールに基づくデータ検証を行うデータセット。narwhals が受け入れ可能な DataFrame 互換オブジェクト （例：pandas.DataFrame、polars.DataFrame、pyarrow.Table）を指定できます。\nrule_dictdict or pd.Series of str（必須） 　pandas.eval() メソッドで実行した結果が論理値となるような expression の文字列を値とする辞書オブジェクト。詳細は使用例も参照してください。\nto_native（bool, optional） True の場合、入力と同じ型のデータフレーム（e.g. pandas / polars / pyarrow）を返します。 False の場合、narwhals.DataFrame を返します。デフォルトは True で、to_native = False は、主にライブラリ内部での利用や、バックエンドに依存しない後続処理を行う場合を想定したオプションです。\n**kwargs 　pandas.eval() に渡す追加の引数。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>check_that check_viorate</span>"
    ]
  },
  {
    "objectID": "man/varidate.html#返り値-value",
    "href": "man/varidate.html#返り値-value",
    "title": "check_that check_viorate",
    "section": "返り値 Value",
    "text": "返り値 Value\n\ncheck_that(): データセット単位の検証結果の集計\n次の列を含む、引数 data に代入されたデータフレームと同じ型の DataFrame が出力されます。\n\nrule: 検証ルールの名前\nitem: ルールが検証対象とした項目の数。レコード（行）を検証単位とするルールの場合、item は data の行数（rows）になります。一方、データセット全体を検証単位とするルール（例：集計量に基づく条件）の場合、item は 1 になります。\npasses: 検証の結果、ルールを満たすと判定されたレコードの数。\nfails: 検証の結果、ルールを満たさないと判定されたレコードの数。\ncountna: 欠測値によって、ルールの検証が行えなかったレコードの数。行（レコード）を検証単位とするルールでは、ルールの評価に使用された変数のいずれかに欠測値が含まれる場合、そのレコードは検証不能として NA 扱いされます。countna は、このように検証を正しく実施できなかったレコードの件数を表します。\nexpression: 検証ルールを表す文字列（expression）。\n\n\n\ncheck_viorate(): レコード単位の検証結果\nルール名を列名として、レコード毎の違反を示す論理変数をもつ DataFrame が出力されます。\n各列の要素の True は検証のルールへの違反、もしくは欠測値によって評価に失敗したことを表します。rule_dict で設定された各ルールに対応する列の他に、次の列が追加で出力されます。\n\nany: 行内のいずれかのルールが違反または評価に失敗した場合に True となるブール値。\nall: 行内の全ルールが違反または評価に失敗した場合に True となるブール値。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>check_that check_viorate</span>"
    ]
  },
  {
    "objectID": "man/varidate.html#使用例-examples",
    "href": "man/varidate.html#使用例-examples",
    "title": "check_that check_viorate",
    "section": "使用例 Examples",
    "text": "使用例 Examples\n　ここでは py4st.check_that() 関数を使って Loo, Jonge(2022, p. 136)の結果を再現します。まずはR言語の validate パッケージに付属する retailers データを利用します。retailers は60件の小売業者の経営状況についてのデータで、従業員数、売上高とその他の収入、人件費、総費用、および利益がユーロ導入前の通貨単位である1000ギルダー単位で収録されています。\nimport py4stats as py4st\nimport pandas as pd\n\nURL = 'https://raw.githubusercontent.com/data-cleaning/validate/master/pkg/data/retailers.csv'\nretailers = pd.read_csv(URL, sep = ';')\nretailers.columns = retailers.columns.to_series().str.replace('.', '_', regex = False)\n　py4st.check_that() 関数は、第1引数にデータセットを、第2引数に検証ルールの辞書オブジェクトを代入して使用します。\n　まずは、検証ルールの辞書オブジェクトを定義します。辞書オブジェクトの値には pandas.eval() メソッドで実行可能な expression の文字列を指定し、key に検証ルールの名前を指定します。検証ルールの名前は任意の値で構いませんが、 expression は結果が論理値となるものでなければなりません。\nrule_dict =  {\n    'to':'turnover &gt; 0',                                     # 売上高は厳密に正である\n    'sc':'staff_costs / staff &lt; 50',                         # 従業員1人当たりの人件費は50,000ギルダー未満である\n    'cd1':'staff_costs &gt; 0 | ~(staff &gt; 0)',                    # 従業員がいる場合、人件費は厳密に正である\n    'cd2':py4st.implies_exper('staff &gt; 0', 'staff_costs &gt; 0'), # cd1 の別表現\n    'bs':'turnover + other_rev == total_rev',                # 売上高とその他の収入の合計は総収入に等しい\n    'mn':'profit.mean() &gt; 0'                                 # セクター全体の平均的な利益はゼロよりも大きい\n    }\npd.Series(rule_dict)\n#&gt; to                          turnover &gt; 0\n#&gt; sc              staff_costs / staff &lt; 50\n#&gt; cd1       staff_costs &gt; 0 | ~(staff &gt; 0)\n#&gt; cd2       staff_costs &gt; 0 | ~(staff &gt; 0)\n#&gt; bs     turnover + other_rev == total_rev\n#&gt; mn                     profit.mean() &gt; 0\n#&gt; dtype: object\nretailers と rule_dict を py4st.check_that() に代入すると、rule_dict に指定したルールに基づいた検証が実行されます。item 列はその検証ルールで生成された論理値の個数（通常はデータセットの列数と一致します）を表し、passes 列は検証結果が True となったレコードの数を、fails は False となったレコードの数を表します。また、coutna はルールの検証に使用した変数（データセットの列）のいずれかが欠測値であったレコードの数です。\nprint(py4st.check_that(retailers, rule_dict))\n#&gt;   rule  item  passes  fails  coutna                         expression\n#&gt; 0   to    60      56      0       4                       turnover &gt; 0\n#&gt; 1   sc    60      39      5      16           staff_costs / staff &lt; 50\n#&gt; 2  cd1    60      44      0      16     staff_costs &gt; 0 | ~(staff &gt; 0)\n#&gt; 3  cd2    60      44      0      16     staff_costs &gt; 0 | ~(staff &gt; 0)\n#&gt; 4   bs    60      19      4      37  turnover + other_rev == total_rev\n#&gt; 5   mn     1       1      0       0                  profit.mean() &gt; 0\n前述の通り、py4st.check_that() 関数ではルール検証を pandas.eval() メソッドで実行しているため、検証ルールに自作関数や外部のモジュールからインポート関数を使うには、関数名の前に @ をつけて @func(…) と記述し、また **kwargs 引数に local_dict = locals() と指定してください。\n　次のコードで定義している is_complete() 関数は、代入された pd.Series が全て欠測値ではなく、指定された変数に関して完全ケースであることを判定する関数です。turnover.notna() & total_rev.notna() & other_rev.notna() と記述しても同じ結果が得られますが、自作関数を使うことで若干簡潔に記述できます。\nfrom pandas.api.types import is_numeric_dtype\ndef is_complete(*arg): return pd.concat(arg, axis = 'columns').notna().all(axis = 'columns')\n\npd.set_option('display.expand_frame_repr', False)\n\nrule_dict2 =  {\n    'to_num':'@is_numeric_dtype(turnover)',                      # 売上高は数値変数である\n    'rev_complete':'@is_complete(turnover, total_rev, other_rev)', # 売上高と収入が全て観測されている\n    }\n\nprint(py4st.check_that(\n    retailers, rule_dict2, local_dict = locals()\n    ))\n#&gt;            rule  item  passes  fails  coutna                                    expression\n#&gt; 0        to_num     1       1      0       0                   @is_numeric_dtype(turnover)\n#&gt; 1  rev_complete    60      23      0      37  @is_complete(turnover, total_rev, other_rev)\npy4st.check_viorate() の使い方も py4st.check_that() と同様ですが、py4st.check_that() がデータセット全体での検証結果を出力するのに対し、py4st.check_viorate() ではレコード別の検証結果を表示します。py4st.check_viorate() から出力されるデータフレームでは、各列が検証ルールに、各行が元データの観測値に対応し、当該ルールが満たされていない場合、True と表示されます。また、any 列は複数あるルールのいずれか1つでも満たされていないことを、all 列は全てのルールが満たされていないことを示します。\nrule_dict3 =  {\n    'to':'turnover &gt; 0',                                     # 売上高は厳密に正である\n    'sc':'staff_costs / staff &lt; 50',                         # 従業員1人当たりの人件費は50,000ギルダー未満である\n    'rev_complete':'@is_complete(turnover, total_rev, other_rev)',# 売上高と収入が全て観測されている\n    }\n  \ndf_viorate = py4st.check_viorate(retailers, rule_dict3)\nprint(df_viorate.head())\n#&gt;       to     sc rev_complete   any    all\n#&gt; 0   True   True         True  True   True\n#&gt; 1  False  False         True  True  False\n#&gt; 2  False   True        False  True  False\n#&gt; 3  False   True        False  True  False\n#&gt; 4   True   True         True  True   True\ndf_viorate データフレームの各列は論理値であるため、次のように検証ルールを満たさない観測値を抽出することができます。\nprint(retailers.loc[df_viorate['to'], 'size':'turnover'])\n#&gt;   size  incl_prob  staff  turnover\n#&gt; 0  sc0       0.02   75.0       NaN\n#&gt; 4  sc3       0.14    NaN       NaN\n#&gt; 6  sc3       0.14    5.0       NaN",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>check_that check_viorate</span>"
    ]
  },
  {
    "objectID": "man/varidate.html#notes",
    "href": "man/varidate.html#notes",
    "title": "check_that check_viorate",
    "section": "Notes",
    "text": "Notes\n本関数の内部実装は、 pd.DataFrame.eval() メソッドに依存しているため、実行時間の面で必ずしも最適化されていません。",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>check_that check_viorate</span>"
    ]
  },
  {
    "objectID": "man/varidate.html#参考文献",
    "href": "man/varidate.html#参考文献",
    "title": "check_that check_viorate",
    "section": "参考文献",
    "text": "参考文献\n\nLoo, Mark van der, and Edwin de Jonge. (2022). 『統計的データクリーニングの理論と実践: Rによるデータ編集/欠測補完システム』. 共立出版. 地道 正行, 髙橋 雅夫, 藤野 友和, 安川 武彦〔訳〕\n\n\nReturn to Function reference.",
    "crumbs": [
      "**EDA**",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>check_that check_viorate</span>"
    ]
  },
  {
    "objectID": "man/compare_ols.html",
    "href": "man/compare_ols.html",
    "title": "compare_ols",
    "section": "",
    "text": "概要\n回帰係数の比較\nsm.ols() や smf.glm() で作成された回帰分析の結果から、推定結果を縦方向に並べて比較する表を作成します。表のフォーマットについてはR言語の texreg::screenreg()やmodelsummary::modelsummary()を参考にしています。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>compare_ols</span>"
    ]
  },
  {
    "objectID": "man/compare_ols.html#概要",
    "href": "man/compare_ols.html#概要",
    "title": "compare_ols",
    "section": "",
    "text": "compare_ols(\n    list_models: Sequence[RegressionResultsWrapper],\n    model_name: Optional[Sequence[str]] = None,\n    subset: Optional[Sequence[str]] = None,\n    stats: Literal[\"std_err\", \"statistics\", \"p_value\", \"conf_int\"] = \"std_err\",\n    add_stars: bool = True,\n    stars: Optional[Mapping[str, float]] = None,\n    stats_glance: Optional[Sequence[str]] = (\"rsquared_adj\", \"nobs\", \"df\"),\n    digits: int = 4,\n    table_style: Literal[\"two_line\", \"one_line\"] = \"two_line\",\n    line_break: str = \"\\n\",\n    **kwargs: Any\n)",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>compare_ols</span>"
    ]
  },
  {
    "objectID": "man/compare_ols.html#引数-argument",
    "href": "man/compare_ols.html#引数-argument",
    "title": "compare_ols",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nlist_models：Sequence[RegressionResultsWrapper] 推定結果を表示する分析結果のリスト（必須）。sm.ols() や smf.ols() で作成された回帰分析の結果を list_models = [fit1, fit2] のようにリストとして指定してください。\nmodel_name：list of str 表頭に表示するモデルの名前。['モデル1', 'モデル2'] のように文字列のリストを指定してください。初期設定では、自動的に model 1, model 2, model 3 … と連番が割り当てられます。\nsubset：list of str 表示する回帰係数のリスト。指定しない場合（初期設定）、モデルに含まれる全ての回帰係数が表示されます。内部ではpandas.DataFrame.locメソッドを用いて処理を行っているため、['変数1', '変数2', ...] のような文字列のリスト、[True, False, True, ...] のようなブール値のリストに対応しています。文字列のリストが指定された場合、リストの並び順に合わせて回帰係数が表示されます。\nstats：str 表中の丸括弧 ( ) 内に表示する統計値の設定。次の値が指定できます。\n\n'std_err' 標準誤差（初期設定）\n'p_value' p-値\n'statistics' t統計量\n\nadd_stars：bool 回帰係数の統計的有意性を表すアスタリスク * を表示するかどうかを表すブール値。add_stars = True（初期-設定）なら表示、add_stars = Falseなら非表示となります。table_style に 'two_line' を指定した場合はアスタリスクは回帰係数の直後に表示され、'one_line' を指定した場合は stats で指定した統計値の後に表示されます。アスタリスクはp-値の値に応じて次のように表示されます。\nstars：dict（p_stars() のみ） 　有意性を示す記号を key に、表示を切り替える閾値を値(value)にもつ辞書オブジェクト。初期設定の stars = None の場合、下記の方式で表示されます。\n\np ≤ 0.1 *\np ≤ 0.05 **\np ≤ 0.01 ***\np &gt; 0.1 表示なし 詳細はbuilding_block.style_pvalue() を参照してください。\n\nstats_glance:list of str\n表の下部に追加する当てはまりの尺度の種類を表す文字列のリスト。リストの値には次の値を指定できます。なお、None もしくは空のリスト [ ] が指定された場合には非表示となります。\n\n'rsquared'：決定係数\n'rsquared_adj'：自由度調整済み決定係数\n'nobs'：サインプルサイズ\n'df'：モデルの自由度（説明変数の数）\n'sigma'：回帰式の標準誤差\n'F_values'：全ての回帰係数がゼロであることを帰無仮説とするF検定の統計量\n'p_values'：F検定のP-値\n'AIC'：赤池情報量基準\n'BIC'：ベイズ情報量基準\n\ndigits: int 回帰係数と統計値について表示する小数点以下の桁数。初期設定は4です。\ntable_style: str 表の書式を表す文字列。次の値から選択できます（部分一致可）。\n\n'two_line'回帰係数と統計値を2行に分ける（初期設定）\n'one_line'回帰係数と統計値を1行で表示する\n\nline_break: str table_style = 'two_line' とした場合に使用される改行記号。table_style = 'one_line' とした場合、この引数は無視されます。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>compare_ols</span>"
    ]
  },
  {
    "objectID": "man/compare_ols.html#使用例-examples",
    "href": "man/compare_ols.html#使用例-examples",
    "title": "compare_ols",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport py4stats as py4st\nimport statsmodels.formula.api as smf\n\nimport pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込み\n\n# 回帰分析の実行\nfit1 = smf.ols('body_mass_g ~ bill_length_mm + species', data = penguins).fit()\nfit2 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species', data = penguins).fit()\nfit3 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex', data = penguins).fit()\n\ncompare_tab1 = py4st.compare_ols(list_models = [fit1, fit2, fit3]) # 表の作成\ncompare_tab1\n\n\n\n\n\n\n\n\n\nterm\nmodel 1\nmodel 2\nmodel 3\n\n\n\n\nIntercept\n153.7397\n-1,742.7202 ***\n843.9812 **\n\n\n\n(268.9012)\n(313.7697)\n(403.5956)\n\n\nspecies[T.Chinstrap]\n-885.8121 ***\n-539.6864 ***\n-245.1516 ***\n\n\n\n(88.2502)\n(86.9425)\n(84.5952)\n\n\nspecies[T.Gentoo]\n578.6292 ***\n1,492.8283 ***\n1,443.3525 ***\n\n\n\n(75.3623)\n(118.4442)\n(107.7844)\n\n\nbill_length_mm\n91.4358 ***\n55.6461 ***\n26.5366 ***\n\n\n\n(6.8871)\n(7.2326)\n(7.2436)\n\n\nbill_depth_mm\n\n179.0434 ***\n87.9328 ***\n\n\n\n\n(19.0997)\n(20.2192)\n\n\nsex[T.male]\n\n\n437.2007 ***\n\n\n\n\n\n(49.1098)\n\n\nrsquared_adj\n0.7810\n0.8258\n0.8613\n\n\nnobs\n342\n342\n333\n\n\ndf\n3\n4\n5\n\n\n\npy4st.compare_ols() の実行結果は Pandas の DataFrame として出力されるため、.xlsx. ファイルなどに変換することができます。また、用途に応じて表の体裁を調整できるようにしています。\ncompare_tab2 = py4st.compare_ols(\n    list_models = [fit1, fit2, fit3],\n    model_name = ['基本モデル', '嘴の高さ追加', '性別追加'], # モデル名を変更\n    stats = 'p_value',        # () 内の値をP-値に変更する\n    add_stars = False,        # 有意性のアスタリスクなし\n    table_style = 'one_line', # 表スタイルを1行表示に設定 'one' でも可能\n    digits = 3                # 小数点以下の桁数を3に設定\n    )\ncompare_tab2\n\n\n\n\n\n\n\n\n\nterm\n基本モデル\n嘴の高さ追加\n性別追加\n\n\n\n\nIntercept\n153.740(0.568)\n-1,742.720(0.000)\n843.981(0.037)\n\n\nspecies[T.Chinstrap]\n-885.812(0.000)\n-539.686(0.000)\n-245.152(0.004)\n\n\nspecies[T.Gentoo]\n578.629(0.000)\n1,492.828(0.000)\n1,443.353(0.000)\n\n\nbill_length_mm\n91.436(0.000)\n55.646(0.000)\n26.537(0.000)\n\n\nbill_depth_mm\n\n179.043(0.000)\n87.933(0.000)\n\n\nsex[T.male]\n\n\n437.201(0.000)\n\n\nrsquared_adj\n0.781\n0.826\n0.861\n\n\nnobs\n342\n342\n333\n\n\ndf\n3\n4\n5\n\n\n\ntable_style = 'two_line' のときに使用される改行記号は line_break で指定できます。great_tables モジュールの GT() 関数と併用する場合など、html 形式で出力する場合には line_break = '&lt;br&gt;' を指定します。\nfrom great_tables import GT, md, html\n\ncompare_tab3 = py4st.compare_ols(\n    list_models = [fit1, fit2, fit3],\n    model_name = ['基本モデル', '嘴の高さ追加', '性別追加'], # モデル名を変更\n    line_break = '&lt;br&gt;'                              # 改行文字の変更\n    )\n\nGT(compare_tab3.reset_index())\\\n  .tab_header(title = 'Palmer penguin データを使った回帰分析の結果')\\\n  .tab_source_note(\n      source_note= \"Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’\"\n      )\\\n  .tab_source_note(source_note = '( ) の値は標準誤差')\n\n\n有意性の表示規則の変更\npy4stats の v0.2.0 以降は、stars 引数で有意性の表示規則を変更できるようになりました。\nstars_dict = {'★★★':0.001, '★★':0.01, '★': 0.05, '.':0.1}\n\nreg.compare_ols(\n    list_models = [fit3],\n    model_name = ['model 3'],\n    stars = stars_dict\n    )\n\n\n\nterm\nmodel 3\n\n\n\n\nIntercept\n843.9812 ★\n\n\n\n(403.5956)\n\n\nspecies[T.Chinstrap]\n-245.1516 ★★\n\n\n\n(84.5952)\n\n\nspecies[T.Gentoo]\n1,443.3525 ★★★\n\n\n\n(107.7844)\n\n\nsex[T.male]\n437.2007 ★★★\n\n\n\n(49.1098)\n\n\nbill_length_mm\n26.5366 ★★★\n\n\n\n(7.2436)\n\n\nbill_depth_mm\n87.9328 ★★★\n\n\n\n(20.2192)\n\n\nrsquared_adj\n0.8613\n\n\nnobs\n333\n\n\ndf\n5\n\n\n\n\n\n回帰係数の sbusetting\n引数 subset を使って表示したい回帰係数を指定することで、一部の回帰係数を省略して表記することもできます。\n# 説明変数に island を追加したモデルを推定\nfit4 = smf.ols(\n    'body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex + island',\n    data = penguins).fit()\n\nvar_list = [\n    'species[T.Chinstrap]', 'species[T.Gentoo]',\n    'bill_length_mm', 'bill_depth_mm', 'sex[T.male]'\n    ]\n\n# 全ての回帰係数を表示すると表が長すぎるので、一部を省略します\ncompare_tab4 = py4st.compare_ols(\n    list_models = [fit2, fit3, fit4],\n    subset = var_list\n    )\n\ncompare_tab4.loc['島ダミー', :] = ['No', 'No', 'Yes']\n\ncompare_tab4\n\n\n\n\n\n\n\n\n\nterm\nmodel 1\nmodel 2\nmodel 3\n\n\n\n\nspecies[T.Chinstrap]\n-539.6864 ***\n-245.1516 ***\n-255.2732 ***\n\n\n\n(86.9425)\n(84.5952)\n(92.4796)\n\n\nspecies[T.Gentoo]\n1,492.8283 ***\n1,443.3525 ***\n1,446.1574 ***\n\n\n\n(118.4442)\n(107.7844)\n(114.1676)\n\n\nbill_length_mm\n55.6461 ***\n26.5366 ***\n26.6643 ***\n\n\n\n(7.2326)\n(7.2436)\n(7.2792)\n\n\nbill_depth_mm\n179.0434 ***\n87.9328 ***\n88.3284 ***\n\n\n\n(19.0997)\n(20.2192)\n(20.3267)\n\n\nsex[T.male]\n\n437.2007 ***\n436.0334 ***\n\n\n\n\n(49.1098)\n(49.4227)\n\n\nrsquared_adj\n0.8258\n0.8613\n0.8605\n\n\nnobs\n342\n333\n333\n\n\ndf\n4\n5\n7\n\n\n島ダミー\nNo\nNo\nYes\n\n\n\npandas の pandas.DataFrame.query メソッドを使って、次のように説明変数を除外することもできます。\ncompare_tab4 = py4st.compare_ols(\n    list_models = [fit2, fit3, fit4]\n    )\n\ncompare_tab4 = compare_tab4\\\n  .query('~term.str.contains(\"Intercept|island\")').copy()\n\ncompare_tab4.loc['島ダミー', :] = ['No', 'No', 'Yes']\n\ncompare_tab4 # 上記のコードと同じ結果",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>compare_ols</span>"
    ]
  },
  {
    "objectID": "man/compare_ols.html#補足",
    "href": "man/compare_ols.html#補足",
    "title": "compare_ols",
    "section": "補足",
    "text": "補足\ntable_style = 'two_line' としたとき、初期設定ではの回帰係数とp-値の間に改行記号 '\\n'が挿入されます。そのため、print() 関数や display() 関数を使った出力では、改行記号 '\\n' がそのまま表示されます。この場合でも、pd.DataFrame.to_excel() や pd.DataFrame.to_markdown() を使って Excel ファイルや markdown の表に変換していただくと、改行として反映されます。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>compare_ols</span>"
    ]
  },
  {
    "objectID": "man/compare_ols.html#参考-see-also",
    "href": "man/compare_ols.html#参考-see-also",
    "title": "compare_ols",
    "section": "参考 see also",
    "text": "参考 see also\n一般化線形モデルの限界効果を比較する場合は py4stats.compare_mfx()をご利用ください。\n\nReturn to Function reference.",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>compare_ols</span>"
    ]
  },
  {
    "objectID": "man/compare_mfx.html",
    "href": "man/compare_mfx.html",
    "title": "compare_mfx",
    "section": "",
    "text": "概要\n限界効果の比較\nsm.glm()の推定結果を計量経済学の実証論文でよく用いられる、回帰分析の結果を縦方向に並べて比較する表を作成します。表のフォーマットについてはR言語の texreg::screenreg()やmodelsummary::modelsummary()を参考にしています。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>compare_mfx</span>"
    ]
  },
  {
    "objectID": "man/compare_mfx.html#概要",
    "href": "man/compare_mfx.html#概要",
    "title": "compare_mfx",
    "section": "",
    "text": "compare_mfx(\n    list_models, \n    model_name = None,\n    subset = None,\n    stats = 'std_err',\n    add_stars = True,\n    stats_glance = ['prsquared', 'nobs', 'df'],\n    at = 'overall',\n    method = 'dydx',\n    dummy = False,\n    digits = 4, \n    table_style = 'two_line',\n    line_break = '\\n',\n    **kwargs\n)",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>compare_mfx</span>"
    ]
  },
  {
    "objectID": "man/compare_mfx.html#引数-argument",
    "href": "man/compare_mfx.html#引数-argument",
    "title": "compare_mfx",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nlist_models： 推定結果を表示する分析結果のリスト（必須）。sm.glm()で作成された一般化線形モデルの結果を list_models = [fit1, fit2] のようにリストとして指定してください。\nmodel_name：list of str 表頭に表示するモデルの名前。['モデル1', 'モデル2'] のように文字列のリストを指定してください。初期設定では、自動的に model 1, model 2, model 3 … と連番が割り当てられます。\nsubset：list of str 表示する回帰係数のリスト。指定しない場合（初期設定）、モデルに含まれる全ての回帰係数が表示されます。内部ではpandas.DataFrame.locメソッドを用いて処理を行っているため、['変数1', '変数2', ...] のような文字列のリスト、[True, False, True, ...] のようなブール値のリストに対応しています。文字列のリストが指定された場合、リストの並び順に合わせて回帰係数が表示されます。\nstats：str 表中の丸括弧 ( ) 内に表示する統計値の設定。次の値が指定できます。\n\n'std_err' 標準誤差（初期設定）\n'p_value' p-値\n'statistics' t統計量\n\nadd_stars：bool 回帰係数の統計的有意性を表すアスタリスク * を表示するかどうかを表すブール値。add_stars = True（初期-設定）なら表示、add_stars = Falseなら非表示となります。table_style に 'two_line' を指定した場合はアスタリスクは回帰係数の直後に表示され、'one_line' を指定した場合は stats で指定した統計値の後に表示されます。アスタリスクはp-値の値に応じて次のように表示されます。\nstars：dict（p_stars() のみ） 　有意性を示す記号を key に、表示を切り替える閾値を値(value)にもつ辞書オブジェクト。初期設定の stars = None の場合、下記の方式で表示されます。\n\np ≤ 0.1 *\np ≤ 0.05 **\np ≤ 0.01 ***\np &gt; 0.1 表示なし 詳細はbuilding_block.style_pvalue() を参照してください。\n\nstats_glance:list of str\n表の下部に追加する当てはまりの尺度の種類を表す文字列のリスト。リストの値には次の値を指定できます。なお、None もしくは空のリスト [ ] が指定された場合には非表示となります。\n\n'rsquared'：決定係数\n'rsquared_adj'：自由度調整済み決定係数\n'nobs'：サインプルサイズ\n'df'：モデルの自由度（説明変数の数）\n'sigma'：回帰式の標準誤差\n'F_values'：全ての回帰係数がゼロであることを帰無仮説とするF検定の統計量\n'p_values'：F検定のP-値\n'AIC'：赤池情報量基準\n'BIC'：ベイズ情報量基準\n\ndigits: int 回帰係数と統計値について表示する小数点以下の桁数。初期設定は4です。\ntable_style: str 表の書式を表す文字列。次の値から選択できます（部分一致可）。\n\n'two_line'回帰係数と統計値を2行に分ける（初期設定）\n'one_line'回帰係数と統計値を1行で表示する\n\nline_break: str table_style = 'two_line' とした場合に使用される改行記号。table_style = 'one_line' とした場合、この引数は無視されます。\nat: str 限界効果の集計方法。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 at として渡されます。method = 'coef' を指定した場合、この引数は無視されます。\n\n'overall'：各観測値の限界効果の平均値を表示（初期設定）\n'mean'：各説明変数の平均値における限界効果を表示\n'median'：各説明変数の中央値における限界効果を表示\n'zero'：各説明変数の値がゼロであるときの限界効果を表示\n\nmethod: str 推定する限界効果の種類。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 method として渡されます。ただし、method = 'coef' を指定した場合には限界効果を推定せずに回帰係数をそのまま表示します。\n\n'coef'：回帰係数の推定値を表示\n'dydx'：限界効果の値を変換なしでそのまま表。（初期設定）\n'eyex'：弾力性 d(lny)/d(lnx) の推定値を表示\n'dyex'：準弾力性 dy /d(lnx) の推定値を表示\n'eydx'：準弾力性 d(lny)/dx の推定値を表示\n\ndummy: bool ダミー変数の限界効果の推定方法を制御するブール値。もし False （初期設定）であれば、ダミー変数を連続な数値変数として扱います。もし、True であればダミー変数が0から1へと変化したときの予測値の変化を推定します。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 dummy として渡されます。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>compare_mfx</span>"
    ]
  },
  {
    "objectID": "man/compare_mfx.html#使用例-example",
    "href": "man/compare_mfx.html#使用例-example",
    "title": "compare_mfx",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport statsmodels.formula.api as smf\n\nimport pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込み\n　py4st.compare_mfx() は py4st.compare_ols() の一般化線型モデルバージョンで、初期設定では statsmodels ライブラリの.get_margeff() メソッドから得られた限界効果の推定値を表示します。\npenguins['female'] = np.where(penguins['sex'] == 'female', 1, 0)\n\n# ロジスティック回帰の実行\nfit_logit1 = smf.logit('female ~ body_mass_g + bill_length_mm + bill_depth_mm', data = penguins).fit()\nfit_logit2 = smf.logit('female ~ body_mass_g + bill_length_mm + bill_depth_mm + species', data = penguins).fit()\n\npy4st.compare_mfx([fit_logit1, fit_logit2])\n\n\n\nterm\nmodel 1\nmodel 2\n\n\n\n\nbody_mass_g\n-0.0004 ***\n-0.0003 ***\n\n\n\n(0.0000)\n(0.0000)\n\n\nbill_length_mm\n-0.0053\n-0.0357 ***\n\n\n\n(0.0036)\n(0.0070)\n\n\nbill_depth_mm\n-0.1490 ***\n-0.1098 ***\n\n\n\n(0.0051)\n(0.0175)\n\n\nspecies[T.Chinstrap]\n\n0.4172 ***\n\n\n\n\n(0.0848)\n\n\nspecies[T.Gentoo]\n\n0.3527 ***\n\n\n\n\n(0.1308)\n\n\nprsquared\n0.5647\n0.6187\n\n\nnobs\n342\n342\n\n\ndf\n3\n5\n\n\n\nfrom great_tables import GT, md, html\ncompare_tab = py4st.compare_mfx(\n    [fit_logit1, fit_logit2],\n    model_name = ['ベースモデル', 'species 追加'], # モデル名を変更\n    line_break = '&lt;br&gt;'                         # 改行文字の変更\n)\n\nGT(compare_tab.reset_index())\\\n  .tab_header(title = 'ロジットモデルの限界効果')\\\n  .tab_source_note(\n      source_note= \"Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’\"\n      )\\\n  .tab_source_note(source_note = '丸括弧 ( ) の値は標準誤差')",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>compare_mfx</span>"
    ]
  },
  {
    "objectID": "man/compare_mfx.html#補足",
    "href": "man/compare_mfx.html#補足",
    "title": "compare_mfx",
    "section": "補足",
    "text": "補足\n　　table_style = 'two_line' としたとき、初期設定ではの回帰係数とp-値の間に改行記号 '\\n'が挿入されます。そのため、print() 関数や display() 関数を使った出力では、改行記号 '\\n' がそのまま表示されます。この場合でも、pd.DataFrame.to_excel() や pd.DataFrame.to_markdown() を使って Excel ファイルや markdown の表に変換していただくと、改行として反映されます。\n\nReturn to Function reference.",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>compare_mfx</span>"
    ]
  },
  {
    "objectID": "man/coefplot.html",
    "href": "man/coefplot.html",
    "title": "coefplot, mfxplot",
    "section": "",
    "text": "概要\n回帰分析による推定値の視覚化\nグラフ上の縦軸が説明変数、横軸回帰係数の値です。点が回帰係数の推定値を、エラーバー（横棒）が信頼区間を表します。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>coefplot, mfxplot</span>"
    ]
  },
  {
    "objectID": "man/coefplot.html#概要",
    "href": "man/coefplot.html#概要",
    "title": "coefplot, mfxplot",
    "section": "",
    "text": "coefplot(\n    mod, \n    subset = None, \n    conf_level = [0.95, 0.99], \n    palette = ['#1b69af', '#629CE7'], \n    show_Intercept = False,\n    show_vline = True,\n    ax = None,\n    **kwargs\n)\n\nmfxplot(\n    mod, \n    subset = None, \n    conf_level = [0.95, 0.99], \n    at = 'overall',\n    method = 'dydx',\n    dummy = False,\n    palette = ['#1b69af', '#629CE7'], \n    show_Intercept = False,\n    show_vline = True,\n    ax = None,\n    **kwargs\n)",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>coefplot, mfxplot</span>"
    ]
  },
  {
    "objectID": "man/coefplot.html#引数-argument",
    "href": "man/coefplot.html#引数-argument",
    "title": "coefplot, mfxplot",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nmod：statsmodels で作成した回帰分析の結果（必須）。\nsubset：グラフに回帰係数を表示する説明変数のリスト。指定しなければモデルに含まれる全ての説明変数を使用します。また subset に指定された順番に合わせてグラフ内での回帰係数の並び順が変更されます。\nconf.level：信頼区間の計算に用いる信頼係数。1つ目の要素が太い方のエラーバーの幅に、2つ目の要素が細い方のエラーバーの幅に対応します。初期設定は [0.95, 0.99] です。\npalette：グラフの描画に使用する色コード。1つ目の要素が太い方のエラーバーの色に、2つ目の要素が細い方のエラーバーの色に対応します。\nshow_Intercept：切片の係数を表示するかどうか。True だと切片の係数を表示し、False（初期設定）だと表示しません。\nshow_vline：回帰係数 = 0 の垂直線を表示するかどうか。True （初期設定）を指定すると垂直線を表示し、False を指定すると表示されません。\nax：matplotlib の ax オブジェクト。複数のグラフを並べる場合などに使用します。\nat：限界効果の集計方法（mfxplot() のみ）。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 at として渡されます。method = 'coef' を指定した場合、この引数は無視されます。\n\n'overall'：各観測値の限界効果の平均値を表示（初期設定）\n'mean'：各説明変数の平均値における限界効果を表示\n'median'：各説明変数の中央値における限界効果を表示\n'zero'：各説明変数の値がゼロであるときの限界効果を表示\n\nmethod：推定する限界効果の種類（mfxplot() のみ）。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 method として渡されます。ただし、method = 'coef' を指定した場合には限界効果を推定せずに回帰係数をそのまま表示します。\n\n'coef'：回帰係数の推定値を表示\n'dydx'：限界効果の値を変換なしでそのまま表。（初期設定）\n'eyex'：弾力性 d(lny)/d(lnx) の推定値を表示\n'dyex'：準弾力性 dy /d(lnx) の推定値を表示\n'eydx'：準弾力性 d(lny)/dx の推定値を表示\n\ndummy：ダミー変数の限界効果の推定方法（mfxplot() のみ）。もし False （初期設定）であれば、ダミー変数を連続な数値変数として扱います。もし、True であればダミー変数が0から1へと変化したときの予測値の変化を推定します。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 dummy として渡されます。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>coefplot, mfxplot</span>"
    ]
  },
  {
    "objectID": "man/coefplot.html#使用例-example",
    "href": "man/coefplot.html#使用例-example",
    "title": "coefplot, mfxplot",
    "section": "使用例 Example",
    "text": "使用例 Example\nimport py4stats as py4st\nimport statsmodels.formula.api as smf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込み\n\n\n# 回帰分析の実行\nfit2 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species', data = penguins).fit()\nfit3 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex', data = penguins).fit()\n\npy4st.coefplot(fit3)\n\n\n\ncoefplot1\n\n\nplt.rcParams[\"figure.autolayout\"] = True\n\nfig, ax = plt.subplots(1, 2, figsize = (2.2 * 5, 5), dpi = 100)\n\npy4st.coefplot(fit2, ax = ax[0])\nax[0].set_xlim(-900, 1800)\n\npy4st.coefplot(fit3, ax = ax[1], palette = ['#FF6F91', '#F2E5EB'])\nax[1].set_xlim(-900, 1800);\n\n\n\ncoefplot2\n\n\npenguins['female'] = np.where(penguins['sex'] == 'female', 1, 0)\n\n# ロジスティック回帰の実行\nfit_logit1 = smf.logit('female ~ body_mass_g + bill_length_mm + bill_depth_mm', data = penguins).fit()\nfit_logit2 = smf.logit('female ~ body_mass_g + bill_length_mm + bill_depth_mm + species', data = penguins).fit()\nplt.rcParams[\"figure.autolayout\"] = True\n\nfig, ax = plt.subplots(1, 2, figsize = (2.2 * 5, 5), dpi = 100)\n\npy4st.mfxplot(fit_logit1, ax = ax[0])\nax[0].set_xlim(-0.2, 0.85)\n\npy4st.mfxplot(fit_logit2, ax = ax[1], palette = ['#FF6F91', '#F2E5EB'])\nax[1].set_xlim(-0.2, 0.85);\n *** Return to Function reference.",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>coefplot, mfxplot</span>"
    ]
  },
  {
    "objectID": "man/tidy.html",
    "href": "man/tidy.html",
    "title": "tidy, tidy_mfx",
    "section": "",
    "text": "概要\n線形モデルの推定結果を DataFrame に集約\ntidy() はR言語の broom::tidy() をオマージュした関数で、sm.ols() や smf.logit() などの推定結果を pands.DataFrame に変換します。py4stats.tidy() は回帰係数と関連する検定結果を表示し、 py4stats.tidy_mfx() は限界効果と関連する検定結果を表示します。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>tidy, tidy_mfx</span>"
    ]
  },
  {
    "objectID": "man/tidy.html#概要",
    "href": "man/tidy.html#概要",
    "title": "tidy, tidy_mfx",
    "section": "",
    "text": "tidy(\n  x, \n  name_of_term = None,\n  conf_level = 0.95,\n  **kwargs\n  )\n\ntidy_mfx(\n  x, \n  at = 'overall', \n  method = 'dydx', \n  dummy = False, \n  conf_level = 0.95, \n  **kwargs\n  )",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>tidy, tidy_mfx</span>"
    ]
  },
  {
    "objectID": "man/tidy.html#引数-argument",
    "href": "man/tidy.html#引数-argument",
    "title": "tidy, tidy_mfx",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nx（必須） 　sm.ols()もしくは smf.logit() などで作成された分析結果のオブジェクト。\nname_of_term：list of str 　term 列（index） として表示する説明変数の名前のリスト。指定しない場合（初期設定）、モデルの推定に使用された説明変数の名前がそのまま表示されます。\nconf_level：float 　信頼区間の計算に用いる信頼係数。\nat：限界効果の集計方法（tidy_mfx() のみ）。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 at として渡されます。method = 'coef' を指定した場合、この引数は無視されます。\n\n'overall'：各観測値の限界効果の平均値を表示（初期設定）\n'mean'：各説明変数の平均値における限界効果を表示\n'median'：各説明変数の中央値における限界効果を表示\n'zero'：各説明変数の値がゼロであるときの限界効果を表示\n\nmethod：推定する限界効果の種類（tidy_mfx() のみ）。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 method として渡されます。ただし、method = 'coef' を指定した場合には限界効果を推定せずに回帰係数をそのまま表示します。\n\n'coef'：回帰係数の推定値を表示\n'dydx'：限界効果の値を変換なしでそのまま表。（初期設定）\n'eyex'：弾力性 d(lny)/d(lnx) の推定値を表示\n'dyex'：準弾力性 dy /d(lnx) の推定値を表示\n'eydx'：準弾力性 d(lny)/dx の推定値を表示\n\ndummy：ダミー変数の限界効果の推定方法（tidy_mfx() のみ）。もし False （初期設定）であれば、ダミー変数を連続な数値変数として扱います。もし、True であればダミー変数が0から1へと変化したときの予測値の変化を推定します。内部で使用しているstatsmodels.discrete.discrete_model.DiscreteResults.get_margeff() メソッドに引数 dummy として渡されます。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>tidy, tidy_mfx</span>"
    ]
  },
  {
    "objectID": "man/tidy.html#返り値-value",
    "href": "man/tidy.html#返り値-value",
    "title": "tidy, tidy_mfx",
    "section": "返り値 Value",
    "text": "返り値 Value\n　次の列を含む pands.DataFrame が出力されます。\n\nterm（index） 　説明変数の名称\nestimate 　回帰係数(tidy()の場合)、もしくは限界効果(tidy_mfx()の場合)の推定値\nstd_err 推定値 estimate の標準誤差\nstatistics estimate = 0 を帰無仮説とする仮説検定の標本検定統計量。x に代入されたモデルが sm.ols() によって作成されたものであれば \\(t\\) 統計量が表示され、sm.glm() によって作成されたものであれば \\(z\\) 統計量が表示されます。\np_value estimate = 0 を帰無仮説とする両側検定の標本p-値\nconf_lower 　信頼区間の下側信頼限界\nconf_higher 　信頼区間の上側信頼限界",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>tidy, tidy_mfx</span>"
    ]
  },
  {
    "objectID": "man/tidy.html#使用例-examples",
    "href": "man/tidy.html#使用例-examples",
    "title": "tidy, tidy_mfx",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\nimport statsmodels.formula.api as smf\n\nimport py4stats as py4st\npenguins = load_penguins() # サンプルデータの読み込み\n# 回帰分析の実行\nfit1 = smf.ols('body_mass_g ~ bill_length_mm + species', data = penguins).fit()\n\nprint(py4st.tidy(fit1).round(4))\n#&gt;                       estimate   std_err  statistics  p_value  conf_lower  conf_higher\n#&gt; term                                                                                  \n#&gt; Intercept             153.7397  268.9012      0.5717   0.5679   -375.1910     682.6704\n#&gt; species[T.Chinstrap] -885.8121   88.2502    -10.0375   0.0000  -1059.4008    -712.2234\n#&gt; species[T.Gentoo]     578.6292   75.3623      7.6780   0.0000    430.3909     726.8674\n#&gt; bill_length_mm         91.4358    6.8871     13.2764   0.0000     77.8888     104.9828\npenguins['female'] = np.where(penguins['sex'] == 'female', 1, 0)\n\n# ロジスティック回帰の実行\nfit_logit1 = smf.logit('female ~ body_mass_g + bill_length_mm + bill_depth_mm', data = penguins).fit()\n\nprint(py4st.tidy_mfx(fit_logit1).round(4))\n#&gt;                 estimate  std_err  statistics  p_value  conf_lower  conf_higher\n#&gt; body_mass_g      -0.0004   0.0000    -17.6561   0.0000     -0.0004      -0.0003\n#&gt; bill_length_mm   -0.0053   0.0036     -1.4628   0.1435     -0.0123       0.0018\n#&gt; bill_depth_mm    -0.1490   0.0051    -29.1681   0.0000     -0.1591      -0.1390",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>tidy, tidy_mfx</span>"
    ]
  },
  {
    "objectID": "man/tidy.html#注意点",
    "href": "man/tidy.html#注意点",
    "title": "tidy, tidy_mfx",
    "section": "注意点",
    "text": "注意点\n参考にしたR言語の broom::tidy() は様々な種類のモデルに対応したジェネリック関数として定義されていますが、py4stats.tidy() と py4stats.tidy_mfx() では対応しているモデルが限定的であることにご注意ください。py4st.tidy() のメソッドが定義されているオブジェクトのクラスを確認するには次のコードを実行して下さい。\nimport py4stats as py4st\nlist(py4st.tidy.registry.keys())\npy4stats.tidy() は functools.singledispatch を用いたジェネリック関数として実装しています。 Py4Etrics モジュールの py4etrics.heckit.Heckit() で作成された HeckitResults クラスのオブジェクト用のメソッドについては heckit_helper.tidy_heckit() を参照してください。\n\nReturn to Function reference.",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>tidy, tidy_mfx</span>"
    ]
  },
  {
    "objectID": "man/tidy_test.html",
    "href": "man/tidy_test.html",
    "title": "tidy_test",
    "section": "",
    "text": "概要\n\\(t\\) 検定、\\(F\\) 検定に対応した tidy メソッド\nR言語の broom::tidy() をオマージュした py4stats.tidy() 関数のうち、statsmodels ライブラリのメソッド RegressionResults.t_test() もしくは RegressionResults.f_test() で作成された statsmodels.stats.contrast.ContrastResults クラスのオブジェクト専用のメソッドです。py4stats.tidy()はジェネリック関数として実装されているため、py4st.tidy(x) としてご利用いただけます。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>tidy_test</span>"
    ]
  },
  {
    "objectID": "man/tidy_test.html#概要",
    "href": "man/tidy_test.html#概要",
    "title": "tidy_test",
    "section": "",
    "text": "tidy_test(x, conf_level = 0.95, **kwargs)",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>tidy_test</span>"
    ]
  },
  {
    "objectID": "man/tidy_test.html#引数-argument",
    "href": "man/tidy_test.html#引数-argument",
    "title": "tidy_test",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nx（必須） 　statsmodels ライブラリのメソッド RegressionResults.t_test() もしくはRegressionResults.f_test() で作成された statsmodels.stats.contrast.ContrastResults クラスのオブジェクト。\nconf_level：float 　信頼区間の計算に用いる信頼係数。ただし、x に代入されたオブジェクトが f_test() の結果である場合は、この引数は無視されます。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>tidy_test</span>"
    ]
  },
  {
    "objectID": "man/tidy_test.html#返り値-value",
    "href": "man/tidy_test.html#返り値-value",
    "title": "tidy_test",
    "section": "返り値 Value",
    "text": "返り値 Value\n　引数 x に代入されたオブジェクトが t_test() の結果である場合、次の列を含む pands.DataFrame が出力されます。\n\nestimate 　帰無仮説のもとでの回帰係数（の線型結合）の推定値\nstd_err 推定値 estimate の標準誤差\nstatistics 　仮説検定の標本検定統計量。\np_value 両側検定の標本p-値\nconf_lower 　信頼区間の下側信頼限界\nconf_higher 　信頼区間の上側信頼限界\n\n　一方で引数 x に代入されたオブジェクトが f_test() の結果である場合、次の列を含む pands.DataFrame が出力されます。\n\nstatistics 　仮説検定の標本検定統計量。\np_value 　F検定の標本p-値\ndf_denom 　モデルの残差自由度\ndf_denom 　帰無仮説のもとでの制約数",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>tidy_test</span>"
    ]
  },
  {
    "objectID": "man/tidy_test.html#使用例-examples",
    "href": "man/tidy_test.html#使用例-examples",
    "title": "tidy_test",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport py4stats as py4st\n\nimport pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\nimport statsmodels.formula.api as smf\n\npenguins = load_penguins() # サンプルデータの読み込み\n\nfit3 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex', data = penguins).fit()\nhypotheses = 'bill_length_mm = 20'\nprint(py4st.tidy(fit3.t_test(hypotheses)).round(4))\n#&gt;       estimate  std_err  statistics  p_value  conf_lower  conf_higher\n#&gt; term                                                                 \n#&gt; c0     26.5366   7.2436      0.9024   0.3675     12.2867      40.7866\nhypotheses = 'species[T.Chinstrap] = 0, species[T.Gentoo] = 0'\nprint(py4st.tidy(fit3.f_test(hypotheses)).round(4))\n#&gt;           statistics  p_value  df_denom  df_num\n#&gt; term                                           \n#&gt; contrast    210.9432      0.0       327       2\n\nReturn to Function reference.",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>tidy_test</span>"
    ]
  },
  {
    "objectID": "man/glance.html",
    "href": "man/glance.html",
    "title": "glance",
    "section": "",
    "text": "概要\n線形モデルの当てはまりの尺度\nR言語の bloom::glance() をオマージュした関数で、sm.ols() や smf.logit() などで推定されたモデルを pands.DataFrame に変換します。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>glance</span>"
    ]
  },
  {
    "objectID": "man/glance.html#概要",
    "href": "man/glance.html#概要",
    "title": "glance",
    "section": "",
    "text": "glance(x)",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>glance</span>"
    ]
  },
  {
    "objectID": "man/glance.html#引数-argument",
    "href": "man/glance.html#引数-argument",
    "title": "glance",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nx（必須） 　sm.ols() もしくは smf.logit() などで作成された分析結果のオブジェクト。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>glance</span>"
    ]
  },
  {
    "objectID": "man/glance.html#返り値-value",
    "href": "man/glance.html#返り値-value",
    "title": "glance",
    "section": "返り値 Value",
    "text": "返り値 Value\n　モデルの当てはまり（goodness of fit）の尺度を各列に持つ pands.DataFrame が出力されます。表示される指標はモデルの種類によって異なります。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>glance</span>"
    ]
  },
  {
    "objectID": "man/glance.html#使用例-examples",
    "href": "man/glance.html#使用例-examples",
    "title": "glance",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport pandas as pd\nimport numpy as np\nfrom palmerpenguins import load_penguins\nimport statsmodels.formula.api as smf\n\nimport py4stats as py4st\npenguins = load_penguins() # サンプルデータの読み込み\n# 線形回帰の場合\nfit_lm1 = smf.ols('body_mass_g ~ bill_length_mm + species', data = penguins).fit()\n\npd.set_option('display.expand_frame_repr', False)\nprint(py4st.glance(fit_lm1).round(4))\n#&gt;    rsquared  rsquared_adj  nobs  df     sigma  F_values  p_values        AIC        BIC\n#&gt; 0    0.7829         0.781   342   3  375.3251  406.2735       0.0  5029.1406  5044.4798\n# ロジスティック回帰の場合\npenguins['female'] = np.where(penguins['sex'] == 'female', 1, 0)\nfit_logit1 = smf.logit('female ~ body_mass_g + bill_length_mm + bill_depth_mm', data = penguins).fit()\n\nprint(py4st.glance(fit_logit1).round(4))\n#&gt;    prsquared   LL-Null  df_null    logLik       AIC      BIC  deviance  df_resid  df_model  nobs\n#&gt; 0     0.5647 -236.8458      341 -103.1079  214.2157  229.555  206.2157       338         3   342",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>glance</span>"
    ]
  },
  {
    "objectID": "man/glance.html#注意点",
    "href": "man/glance.html#注意点",
    "title": "glance",
    "section": "注意点",
    "text": "注意点\n参考にしたR言語の bloom::glance() は様々な種類のモデルに対応したジェネリック関数として定義されていますが、py4st.glance() は現段階では限られたモデルにしか対応していません。py4st.glance() のメソッドが定義されているオブジェクトのクラスを確認するには次のコードを実行して下さい。\nimport py4stats as py4st\nlist(py4st.glance.registry.keys())\n\nReturn to Function reference.",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>glance</span>"
    ]
  },
  {
    "objectID": "man/Blinder_Oaxaca.html",
    "href": "man/Blinder_Oaxaca.html",
    "title": "Blinder_Oaxaca, plot_Blinder_Oaxaca",
    "section": "",
    "text": "概要\n2つのサブサンプルを用いた回帰分析の推定結果に対して、Blinder-Oaxaca分解を行います。\nいま、ある変数 \\(s\\) を用いて \\(s = m\\) と \\(s = f\\) の2つのサブグループからなるデータセットがあるとし、次のような回帰式を仮定します。\n\\[\n\\begin{aligned}\nY_{i}^s = \\boldsymbol{X}_i^s\\boldsymbol{\\beta}^s + \\epsilon_i^s, &&\ns = m, f\n\\end{aligned}\n\\tag{1}\n\\]\nここで、\\(\\boldsymbol{X}_i^s\\) サブグループ \\(s\\) に属する個人 \\(i\\) についての説明変数からなる行列で、\\(\\boldsymbol{\\beta}^s\\) はサブグループ \\(s\\) のについての回帰係数、\\(\\epsilon_i^s\\) は誤差項です。 　さらに、サブグループ \\(s\\) の被説明変数の平均値を \\(\\bar{Y}^s\\) とし、説明変数の平均値を \\(\\bar{\\boldsymbol{X}}^s\\) とするとき、Blinder-Oaxaca分解は2つのグループにおける被説明変数の平均値の差 \\(\\bar{Y}^m - \\bar{Y}^f\\) を次のように分解します。\n\\[\n\\begin{aligned}\n\\bar{Y}^m - \\bar{Y}^f = (\\bar{\\boldsymbol{X}}^m - \\bar{\\boldsymbol{X}}^f)\\boldsymbol{\\beta}^m + \\bar{\\boldsymbol{X}}^f(\\boldsymbol{\\beta}^m - \\boldsymbol{\\beta}^f)\n\\end{aligned}\n\\tag{2}\n\\]\nこのとき、式(2)右辺の各項は、それぞれ次のような意味を持ちます。\n式(1)および式(2)については朝井(2014, p.9)を参照しました。",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Blinder_Oaxaca, plot_Blinder_Oaxaca</span>"
    ]
  },
  {
    "objectID": "man/Blinder_Oaxaca.html#概要",
    "href": "man/Blinder_Oaxaca.html#概要",
    "title": "Blinder_Oaxaca, plot_Blinder_Oaxaca",
    "section": "",
    "text": "Blinder_Oaxaca(model1, model2)\n\nplot_Blinder_Oaxaca(\n    model1, model2,\n    diff_type = ['observed_diff', 'unobserved_diff'],\n    ax = None, \n)\n\n\n\n\n\n\n\\((\\bar{\\boldsymbol{X}}^m - \\bar{\\boldsymbol{X}}^f)\\boldsymbol{\\beta}^m\\)：2つのグループの観測可能な属性の差に起因する被説明変数の差 observed_diff\n\\(\\bar{\\boldsymbol{X}}^f(\\boldsymbol{\\beta}^m - \\boldsymbol{\\beta}^f)\\)：2つのグループの観測できない要因の違いに起因する被説明変数の差 unobserved_diff",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Blinder_Oaxaca, plot_Blinder_Oaxaca</span>"
    ]
  },
  {
    "objectID": "man/Blinder_Oaxaca.html#引数-argument",
    "href": "man/Blinder_Oaxaca.html#引数-argument",
    "title": "Blinder_Oaxaca, plot_Blinder_Oaxaca",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nmodel1：statsmodels で作成した回帰分析の結果（必須）。\nmodel2：statsmodels で作成した回帰分析の結果（必須）。\ndiff_type （plot_Blinder_Oaxaca()のみ）list of str or str  　グラフの描画に使用する要約統計量の種類。初期設定では observed_diff と unobserved_diff の両方を表示します。\nax：matplotlib の ax オブジェクト。複数のグラフを並べる場合などに使用します。 　 ## 使用例 Examples\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\nimport py4stats as py4st\n\nwage1 = wooldridge.data('wage1')\n\nfit_female = smf.ols(\n    'lwage ~ educ + exper + expersq + tenure + tenursq + married', \n    data = wage1.query('female == 1')\n    ).fit()\n\nfit_male = smf.ols(\n    'lwage ~ educ + exper + expersq + tenure + tenursq + married', \n    data = wage1.query('female == 0')\n    ).fit()\npy4st.compare_ols(\n    list_models = [fit_female, fit_male],\n    model_name = ['female', 'male']\n    )\n\n\n\nterm\nfemale\nmale\n\n\n\n\nIntercept\n0.3159 **(0.1401)\n0.2255 *(0.1302)\n\n\neduc\n0.0737 ***(0.0104)\n0.0830 ***(0.0089)\n\n\nexper\n0.0200 ***(0.0072)\n0.0329 ***(0.0076)\n\n\nexpersq\n-0.0004 ***(0.0002)\n-0.0006 ***(0.0002)\n\n\ntenure\n0.0391 ***(0.0117)\n0.0301 ***(0.0089)\n\n\ntenursq\n-0.0014 ***(0.0005)\n-0.0005 *(0.0003)\n\n\nmarried\n-0.0548 (0.0539)\n0.1718 ***(0.0595)\n\n\nrsquared_adj\n0.2446\n0.4509\n\n\nnobs\n252\n274\n\n\ndf\n6\n6\n\n\n\nwage_decomp = py4st.Blinder_Oaxaca(\n    model1 = fit_female,\n    model2 = fit_male\n)\nwage_decomp\n\n\n\nterms\nobserved_diff\nunobserved_diff\n\n\n\n\nIntercept\n0\n-0.0903337\n\n\neduc\n0.0390661\n0.114713\n\n\nexper\n0.0371577\n0.211177\n\n\nexpersq\n-0.0216026\n-0.0962631\n\n\ntenure\n0.0859831\n-0.0327949\n\n\ntenursq\n-0.0342727\n0.0378497\n\n\nmarried\n0.0278806\n0.118657\n\n\n\npy4st.plot_Blinder_Oaxaca(\n    model1 = fit_female,\n    model2 = fit_male\n)\n\n\n\nplot_Blinder_Oaxaca1\n\n\ndiff_type を指定することで、一方の統計量だけを表示することもできます。\npy4st.plot_Blinder_Oaxaca(\n    model1 = fit_female,\n    model2 = fit_male,\n    diff_type = 'unobserved_diff'\n)\n\n\n\nplot_Blinder_Oaxaca2\n\n\nグラフのサイズや解像度を指定するには、次のように行います。\nfig, ax = plt.subplots(1, 2, figsize = (1.1 * 2 * 4, 4), sharey = True, dpi = 200)\n\npy4st.plot_Blinder_Oaxaca(\n    model1 = fit_female,\n    model2 = fit_male,\n    ax = ax\n)\nfig.tight_layout()",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Blinder_Oaxaca, plot_Blinder_Oaxaca</span>"
    ]
  },
  {
    "objectID": "man/Blinder_Oaxaca.html#参考文献",
    "href": "man/Blinder_Oaxaca.html#参考文献",
    "title": "Blinder_Oaxaca, plot_Blinder_Oaxaca",
    "section": "参考文献",
    "text": "参考文献\n\n朝井 友紀子 (2014) 「労働市場における男女差の30年― 就業のサンプルセレクションと男女間賃金格差」『日本労働研究雑誌』, No.648, pp.6–16\n\n\nReturn to Function reference.",
    "crumbs": [
      "**Regression**",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Blinder_Oaxaca, plot_Blinder_Oaxaca</span>"
    ]
  },
  {
    "objectID": "man/tidy_heckit.html",
    "href": "man/tidy_heckit.html",
    "title": "heckit_helper.tidy_heckit",
    "section": "",
    "text": "概要\nR言語の broom::tidy() をオマージュした regression_tools.tidy() 関数の、py4etrics.heckit.HeckitResults クラス専用のメソッドです。regression_tools.tidy()はジェネリック関数として実装されているため、py4st.tidy(x) としてご利用いただけます。",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>heckit_helper.tidy_heckit</span>"
    ]
  },
  {
    "objectID": "man/tidy_heckit.html#概要",
    "href": "man/tidy_heckit.html#概要",
    "title": "heckit_helper.tidy_heckit",
    "section": "",
    "text": "tidy_heckit(\n    model, \n    name_selection = None, \n    name_outcome = None, \n    conf_level = 0.95\n  )",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>heckit_helper.tidy_heckit</span>"
    ]
  },
  {
    "objectID": "man/tidy_heckit.html#引数-argument",
    "href": "man/tidy_heckit.html#引数-argument",
    "title": "heckit_helper.tidy_heckit",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nx（必須） 　 Py4Etrics モジュールの py4etrics.heckit.Heckit() で作成された HeckitResults クラスのオブジェクト\nname_selection：list of str 　term 列（index） のうち、第1段階の説明変数の名称として表示する文字列のリスト。指定しない場合（初期設定）、モデルの推定に使用された説明変数の名前がそのまま表示されます。\nname_outcome：list of str 　term 列（index） のうち、第2段階の説明変数の名称として表示する文字列のリスト。指定しない場合（初期設定）、モデルの推定に使用された説明変数の名前がそのまま表示されます。\nconf_level：float 　信頼区間の計算に用いる信頼係数。",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>heckit_helper.tidy_heckit</span>"
    ]
  },
  {
    "objectID": "man/tidy_heckit.html#返り値-value",
    "href": "man/tidy_heckit.html#返り値-value",
    "title": "heckit_helper.tidy_heckit",
    "section": "返り値 Value",
    "text": "返り値 Value\n　次の列を含む pands.DataFrame が出力されます。\n\nterm（index） 　説明変数の名称\nestimate） 　回帰係数の推定値\nstd_err 推定値 estimate の標準誤差\nstatistics estimate = 0 を帰無仮説とする仮説検定の標本検定統計量。x に代入されたモデルが sm.ols() によって作成されたものであれば \\(t\\) 統計量が表示され、sm.glm() によって作成されたものであれば \\(z\\) 統計量が表示されます。\np_value estimate = 0 を帰無仮説とする両側検定の標本p-値\nconf_lower 　信頼区間の下側信頼限界\nconf_higher 　信頼区間の上側信頼限界",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>heckit_helper.tidy_heckit</span>"
    ]
  },
  {
    "objectID": "man/tidy_heckit.html#使用例-examples",
    "href": "man/tidy_heckit.html#使用例-examples",
    "title": "heckit_helper.tidy_heckit",
    "section": "使用例 Examples",
    "text": "使用例 Examples\n　heckit_helper モジュールはヘックマンの2段階推定（Heckit）を実行を Py4Etrics モジュールの py4etrics.heckit.Heckit() に依存しているため、事前のインストールをお願いします。\npip install git+https://github.com/Py4Etrics/py4etrics.git\nここでは wooldridge モジュールの mroz データを使い、春山(2023, Chap.24)のモデルを再現します。\nimport pandas as pd\nimport wooldridge\nimport py4stats as py4st\nfrom py4stats import heckit_helper\n\nmroz = wooldridge.data('mroz') # サンプルデータの読み込み\n\nmod_heckit, exog_outcome, exog_select = heckit_helper.Heckit_from_formula(\n    selection = 'lwage ~ educ + exper + expersq + nwifeinc + age + kidslt6 + kidsge6',\n    outcome = 'lwage ~ educ + exper + expersq',\n    data = mroz\n)\n\nres_heckit = mod_heckit.fit(cov_type_2 = 'HC1')\n内部で functools.singledispatch を使用して定義しているため、heckit_helper モジュールの読み込み後は、py4st.tidy() 関数を呼び出すことで tidy_heckit() を実行することができます。\n# 初期設定で使用した場合\nprint(py4st.tidy(res_heckit).round(4))\n#&gt;               estimate  std_err  statistics  p_value  conf_lower  conf_higher\n#&gt; term                                                                         \n#&gt; O: Intercept   -0.5781   0.3050     -1.8954   0.0580     -1.1759       0.0197\n#&gt; O: educ         0.1091   0.0155      7.0261   0.0000      0.0786       0.1395\n#&gt; O: exper        0.0439   0.0163      2.6989   0.0070      0.0120       0.0758\n#&gt; O: expersq     -0.0009   0.0004     -1.9574   0.0503     -0.0017       0.0000\n#&gt; S: const        0.2701   0.5086      0.5310   0.5954     -0.7267       1.2669\n#&gt; S: x1           0.1309   0.0253      5.1835   0.0000      0.0814       0.1804\n#&gt; S: x2           0.1233   0.0187      6.5903   0.0000      0.0867       0.1600\n#&gt; S: x3          -0.0019   0.0006     -3.1452   0.0017     -0.0031      -0.0007\n#&gt; S: x4          -0.0120   0.0048     -2.4843   0.0130     -0.0215      -0.0025\n#&gt; S: x5          -0.0529   0.0085     -6.2347   0.0000     -0.0695      -0.0362\n#&gt; S: x6          -0.8683   0.1185     -7.3263   0.0000     -1.1006      -0.6360\n#&gt; S: x7           0.0360   0.0435      0.8281   0.4076     -0.0492       0.1212\n　注意：内部で使用している statsmodels.iolib.summary.summary_params_frame() の仕様上、初期設定では第1段階の説明変数の名前が反映されません。説明変数の名前を反映するには name_selection 引数で指定してください。\nprint(py4st.tidy(res_heckit, name_selection = exog_select.columns).round(4))\n#&gt;               estimate  std_err  statistics  p_value  conf_lower  conf_higher\n#&gt; term                                                                         \n#&gt; O: Intercept   -0.5781   0.3050     -1.8954   0.0580     -1.1759       0.0197\n#&gt; O: educ         0.1091   0.0155      7.0261   0.0000      0.0786       0.1395\n#&gt; O: exper        0.0439   0.0163      2.6989   0.0070      0.0120       0.0758\n#&gt; O: expersq     -0.0009   0.0004     -1.9574   0.0503     -0.0017       0.0000\n#&gt; S: Intercept    0.2701   0.5086      0.5310   0.5954     -0.7267       1.2669\n#&gt; S: educ         0.1309   0.0253      5.1835   0.0000      0.0814       0.1804\n#&gt; S: exper        0.1233   0.0187      6.5903   0.0000      0.0867       0.1600\n#&gt; S: expersq     -0.0019   0.0006     -3.1452   0.0017     -0.0031      -0.0007\n#&gt; S: nwifeinc    -0.0120   0.0048     -2.4843   0.0130     -0.0215      -0.0025\n#&gt; S: age         -0.0529   0.0085     -6.2347   0.0000     -0.0695      -0.0362\n#&gt; S: kidslt6     -0.8683   0.1185     -7.3263   0.0000     -1.1006      -0.6360\n#&gt; S: kidsge6      0.0360   0.0435      0.8281   0.4076     -0.0492       0.1212\n\nReturn to Function reference.",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>heckit_helper.tidy_heckit</span>"
    ]
  },
  {
    "objectID": "man/Heckit_from_formula.html",
    "href": "man/Heckit_from_formula.html",
    "title": "heckit_helper.Heckit_from_formula",
    "section": "",
    "text": "概要",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>heckit_helper.Heckit_from_formula</span>"
    ]
  },
  {
    "objectID": "man/Heckit_from_formula.html#概要",
    "href": "man/Heckit_from_formula.html#概要",
    "title": "heckit_helper.Heckit_from_formula",
    "section": "",
    "text": "Heckit_from_formula(\n  selection, \n  outcome, \n  data, \n  **kwargs\n  )",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>heckit_helper.Heckit_from_formula</span>"
    ]
  },
  {
    "objectID": "man/Heckit_from_formula.html#引数-argument",
    "href": "man/Heckit_from_formula.html#引数-argument",
    "title": "heckit_helper.Heckit_from_formula",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nselectionstr（必須） 　Type2トービットモデルのうち第1段階の selection equation(選択関数, 就業決定関数)の回帰式\noutcomestr（必須） 　Type2トービットモデルのうち第2段階の regression equation(賃金関数)の回帰式\ndata：pandas.DataFrame（必須）\n**kwargs  py4etrics.heckit.Heckit() に渡すその他の引数",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>heckit_helper.Heckit_from_formula</span>"
    ]
  },
  {
    "objectID": "man/Heckit_from_formula.html#返り値-value",
    "href": "man/Heckit_from_formula.html#返り値-value",
    "title": "heckit_helper.Heckit_from_formula",
    "section": "返り値 Value",
    "text": "返り値 Value\n　3つの要素を持つ tuple。左から順に次の3つのオブジェクトが出力されます。\n\npy4etrics.heckit.Heckit() から出力されたモデルの推定結果\n第2段階の regression equation(賃金関数)の説明変数からなる pd.DataFrame\n第1段階のselection equation(選択関数, 就業決定関数)の説明変数からなる pd.DataFrame",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>heckit_helper.Heckit_from_formula</span>"
    ]
  },
  {
    "objectID": "man/Heckit_from_formula.html#使用例-examples",
    "href": "man/Heckit_from_formula.html#使用例-examples",
    "title": "heckit_helper.Heckit_from_formula",
    "section": "使用例 Examples",
    "text": "使用例 Examples\n　heckit_helper モジュールはヘックマンの2段階推定（Heckit）を実行を Py4Etrics モジュールの py4etrics.heckit.Heckit() に依存しているため、事前のインストールをお願いします。\npip install git+https://github.com/Py4Etrics/py4etrics.git\nここでは春山(2023, Chap.24)のモデルを再現するため、wooldridge モジュールから mroz データを読み込みます。\nimport pandas as pd\nimport wooldridge\nfrom py4stats import heckit_helper\n\nmroz = wooldridge.data('mroz') # サンプルデータの読み込み\nHeckit_from_formula() 関数を使い、モデルを推定します。なお、Type2トービットモデルを推定する場合、第2段階の回帰式 outcome で使用される説明変数は全て第1段階の回帰式 selection に含まれ、なおかつ selection に含まれるものの、outcome には含まれない説明変数が少なくとも1つは必要であることに注意してください(末石, 2015, p.117)。\nmod_heckit, exog_outcome, exog_select = \\\n heckit_helper.Heckit_from_formula(\n    selection = 'lwage ~ educ + exper + expersq + nwifeinc + age + kidslt6 + kidsge6',\n    outcome = 'lwage ~ educ + exper + expersq',\n    data = mroz\n)\n\nres_heckit = mod_heckit.fit(cov_type_2 = 'HC1')\n\nprint(res_heckit.summary())\n#&gt;                            Heckit Regression Results                            \n#&gt; ================================================================================\n#&gt; Dep. Variable:                    lwage   R-squared:                       0.156\n#&gt; Model:                           Heckit   Adj. R-squared:                  0.150\n#&gt; Method:                Heckman Two-Step   F-statistics:                   26.148\n#&gt; Date:                  Mon, 11 Mar 2024   Prob (F-statistic):              0.000\n#&gt; Time:                          08:40:39   Cov in 1st Stage:            nonrobust\n#&gt; No. Total Obs.:                     753   Cov in 2nd Stage:                  HC1\n#&gt; No. Censored Obs.:                  325                                         \n#&gt; No. Uncensored Obs.:                428                                         \n#&gt; ==============================================================================\n#&gt;                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n#&gt; ------------------------------------------------------------------------------\n#&gt; Intercept     -0.5781      0.305     -1.895      0.058      -1.176       0.020\n#&gt; educ           0.1091      0.016      7.026      0.000       0.079       0.139\n#&gt; exper          0.0439      0.016      2.699      0.007       0.012       0.076\n#&gt; expersq       -0.0009      0.000     -1.957      0.050      -0.002    1.15e-06\n#&gt; ==============================================================================\n#&gt;                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n#&gt; ------------------------------------------------------------------------------\n#&gt; Intercept      0.2701      0.509      0.531      0.595      -0.727       1.267\n#&gt; educ           0.1309      0.025      5.183      0.000       0.081       0.180\n#&gt; exper          0.1233      0.019      6.590      0.000       0.087       0.160\n#&gt; expersq       -0.0019      0.001     -3.145      0.002      -0.003      -0.001\n#&gt; nwifeinc      -0.0120      0.005     -2.484      0.013      -0.022      -0.003\n#&gt; age           -0.0529      0.008     -6.235      0.000      -0.069      -0.036\n#&gt; kidslt6       -0.8683      0.119     -7.326      0.000      -1.101      -0.636\n#&gt; kidsge6        0.0360      0.043      0.828      0.408      -0.049       0.121\n#&gt; ================================================================================\n#&gt;                    coef    std err          z      P&gt;|z|      [0.025      0.975]\n#&gt; --------------------------------------------------------------------------------\n#&gt; IMR (Lambda)     0.0323      0.134      0.241      0.809      -0.230       0.294\n#&gt; =====================================\n#&gt; rho:                            0.049\n#&gt; sigma:                          0.664\n#&gt; =====================================\n#&gt; \n#&gt; First table are the estimates for the regression (response) equation.\n#&gt; Second table are the estimates for the selection equation.\n#&gt; Third table is the estimate for the coef of the inverse Mills ratio (Heckman's Lambda).",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>heckit_helper.Heckit_from_formula</span>"
    ]
  },
  {
    "objectID": "man/Heckit_from_formula.html#参考文献",
    "href": "man/Heckit_from_formula.html#参考文献",
    "title": "heckit_helper.Heckit_from_formula",
    "section": "参考文献",
    "text": "参考文献\n\n末石直也(2015)『計量経済学：ミクロデータ分析へのいざない』 日本評論社.\n春山鉄源(2023) 『Pythonで学ぶ入門計量経済学』 https://py4etrics.github.io/index.html\n\n\nReturn to Function reference.",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>heckit_helper.Heckit_from_formula</span>"
    ]
  },
  {
    "objectID": "man/heckitmfx_compute.html",
    "href": "man/heckitmfx_compute.html",
    "title": "heckit_helper.heckitmfx_compute",
    "section": "",
    "text": "概要\nType2トービットモデルの限界効果を推定します。推定方法についてはダハナ, 勝又(2023, p.136)および Hoffmann, Kassouf(2005)を参照し、関数の実装についてはR言語の heckitmfx::heckitmfx_log() 関数を参考にしています。",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>heckit_helper.heckitmfx_compute</span>"
    ]
  },
  {
    "objectID": "man/heckitmfx_compute.html#概要",
    "href": "man/heckitmfx_compute.html#概要",
    "title": "heckit_helper.heckitmfx_compute",
    "section": "",
    "text": "heckitmfx_compute(\n    model, \n    exog_select, \n    exog_outcome, \n    exponentiate = False\n)",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>heckit_helper.heckitmfx_compute</span>"
    ]
  },
  {
    "objectID": "man/heckitmfx_compute.html#引数-argument",
    "href": "man/heckitmfx_compute.html#引数-argument",
    "title": "heckit_helper.heckitmfx_compute",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nmodel（必須） 　 Py4Etrics モジュールの py4etrics.heckit.Heckit() で作成された HeckitResults クラスのオブジェクト\nexog_selectpd.DataFrame（必須） 　Type2トービットモデルのうち第1段階の selection equation(選択関数, 就業決定関数)の説明変数からなる pd.DataFrame\nexog_outcomepd.DataFrame（必須） 　Type2トービットモデルのうち第2段階の regression equation(賃金関数)の説明変数からなる pd.DataFrame\n\nこれらの引数は heckit_helper.Heckit_from_formula() の出力を使用することを想定しています（使用例を参照）。\n\nexponentiatebool 　推定結果に指数関数を用いた変換を行うかどうかを表す論理値。もし False （初期設定）であれば限界効果と回帰係数の推定値をそのまま出力し、もし True であれば出力されるデータフレームのうち unconditional、conditional、selection、beta の列について指数関数 \\(100[\\exp(x - 1)]\\) を用いた変換を行います。例えば被説明変数は対数賃金であれば、変換後の限界効果はパーセンテージで表された賃金の変化率として解釈できます。",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>heckit_helper.heckitmfx_compute</span>"
    ]
  },
  {
    "objectID": "man/heckitmfx_compute.html#返り値-value",
    "href": "man/heckitmfx_compute.html#返り値-value",
    "title": "heckit_helper.heckitmfx_compute",
    "section": "返り値 Value",
    "text": "返り値 Value\n　次の列を含む pands.DataFrame が出力されます。\n\nterm（index） 　説明変数の名称\nunconditional 　Hoffmann, Kassouf(2005, p.6)の(14)式および(15)式に基づく条件付なしの平均限界効果（unconditional marginal effect）\nconditional 　Hoffmann, Kassouf(2005, pp.4-5)の(8)式および(9)式に基づく条件付平均限界効果（conditional marginal effect）\nselection 　Hoffmann, Kassouf(2005, p.6)の(14)式および(15)式の第3項に当たる間接効果\nbeta 　第2段階の regression equation の回帰係数\ngamma 　第1段階の selection equation の回帰係数",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>heckit_helper.heckitmfx_compute</span>"
    ]
  },
  {
    "objectID": "man/heckitmfx_compute.html#使用例-examples",
    "href": "man/heckitmfx_compute.html#使用例-examples",
    "title": "heckit_helper.heckitmfx_compute",
    "section": "使用例 Examples",
    "text": "使用例 Examples\n　heckit_helper モジュールはヘックマンの2段階推定（Heckit）を実行を Py4Etrics モジュールの py4etrics.heckit.Heckit() に依存しているため、事前のインストールをお願いします。\npip install git+https://github.com/Py4Etrics/py4etrics.git\nここでは wooldridge モジュールの mroz データを使い、春山(2023, Chap.24)のモデルを再現します。\nimport pandas as pd\nimport wooldridge\nfrom py4stats import heckit_helper\n\nmroz = wooldridge.data('mroz') # サンプルデータの読み込み\n\nmod_heckit, exog_outcome, exog_select = \\\n heckit_helper.Heckit_from_formula(\n    selection = 'lwage ~ educ + exper + expersq + nwifeinc + age + kidslt6 + kidsge6',\n    outcome = 'lwage ~ educ + exper + expersq',\n    data = mroz\n)\n\nres_heckit = mod_heckit.fit(cov_type_2 = 'HC1')\nprint(heckit_helper.heckitmfx_compute(\n    res_heckit,\n    exog_select = exog_select,\n    exog_outcome = exog_outcome\n    ).round(4))\n#&gt;           unconditional  conditional  selection    beta   gamma\n#&gt; term                                                           \n#&gt; age             -0.0385       0.0010    -0.0395  0.0000 -0.0529\n#&gt; educ             0.2045       0.1067     0.0978  0.1091  0.1309\n#&gt; exper            0.1338       0.0417     0.0922  0.0439  0.1233\n#&gt; expersq         -0.0022      -0.0008    -0.0014 -0.0009 -0.0019\n#&gt; kidsge6          0.0263      -0.0006     0.0269  0.0000  0.0360\n#&gt; kidslt6         -0.6332       0.0157    -0.6489  0.0000 -0.8683\n#&gt; nwifeinc        -0.0088       0.0002    -0.0090  0.0000 -0.0120\n被説明変数の lwage は対数賃金であるため、exponentiate = True として指数関数 \\(100[\\exp(x - 1)]\\) を使った変換を行うことで、限界効果を賃金の変化率として解釈できるようになります。\nprint(heckit_helper.heckitmfx_compute(\n    res_heckit,\n    exog_select = exog_select,\n    exog_outcome = exog_outcome,\n    exponentiate = True\n    ).round(4))\n#&gt;           unconditional  conditional  selection     beta   gamma\n#&gt; term                                                            \n#&gt; age             -3.7809       0.0954    -3.8725   0.0000 -0.0529\n#&gt; educ            22.6943      11.2606    10.2765  11.5235  0.1309\n#&gt; exper           14.3206       4.2543     9.6555   4.4865  0.1233\n#&gt; expersq         -0.2233      -0.0825    -0.1409  -0.0859 -0.0019\n#&gt; kidsge6          2.6604      -0.0649     2.7271   0.0000  0.0360\n#&gt; kidslt6        -46.9117       1.5782   -47.7365   0.0000 -0.8683\n#&gt; nwifeinc        -0.8730       0.0217    -0.8945   0.0000 -0.0120",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>heckit_helper.heckitmfx_compute</span>"
    ]
  },
  {
    "objectID": "man/heckitmfx_compute.html#注意",
    "href": "man/heckitmfx_compute.html#注意",
    "title": "heckit_helper.heckitmfx_compute",
    "section": "注意",
    "text": "注意\n　heckitmfx_compute() の実装は実験的なものであり、 Stata における margins コマンドなどの既存の手法とは計算結果が一致しない可能性があります。",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>heckit_helper.heckitmfx_compute</span>"
    ]
  },
  {
    "objectID": "man/heckitmfx_compute.html#参考文献",
    "href": "man/heckitmfx_compute.html#参考文献",
    "title": "heckit_helper.heckitmfx_compute",
    "section": "参考文献",
    "text": "参考文献\n\nダハナ・ウィラワン ドニ, 勝又壮太郎(2023) 『Rによるマーケティング・データ分析: 基礎から応用まで (ライブラリ データ分析への招待 4)』新世社.\n春山鉄源 (2023) 『Pythonで学ぶ入門計量経済学』. https://py4etrics.github.io/index.html\nHoffmann, Rodolfo, and Ana Lucia Kassouf. (2005). Deriving conditional and unconditional marginal effects in log earnings equations estimated by heckman’s procedure. Applied Economics, 37(11), 1303–1311. *** Return to Function reference.",
    "crumbs": [
      "**heckit_helper**",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>heckit_helper.heckitmfx_compute</span>"
    ]
  },
  {
    "objectID": "man/arg_match.html",
    "href": "man/arg_match.html",
    "title": "building_block.arg_match",
    "section": "",
    "text": "概要\n引数のアサーション\nR言語の rlang::arg_match() をオマージュした関数で、文字列で与えられた引数のアサーションを行います。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>building_block.arg_match</span>"
    ]
  },
  {
    "objectID": "man/arg_match.html#概要",
    "href": "man/arg_match.html#概要",
    "title": "building_block.arg_match",
    "section": "",
    "text": "arg_match(\n    arg: Union[str, Sequence[str], pd.Series, np.ndarray],\n    values: Sequence[str],\n    arg_name: Optional[str] = None,\n    multiple: bool = False,\n    any_missing: bool = False,\n    all_missing: bool = False,\n    nullable: bool = False\n    )",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>building_block.arg_match</span>"
    ]
  },
  {
    "objectID": "man/arg_match.html#引数-argument",
    "href": "man/arg_match.html#引数-argument",
    "title": "building_block.arg_match",
    "section": "引数 Argument",
    "text": "引数 Argument\n\narg（必須）str or list of str 　適正かどうかを判断したい引数の値\nvalues（必須）：list of str 　引数 arg の適正な値のリスト\narg_name：str 　エラーメッセージに表示する引数の名前。指定されなかった場合（初期設定）、引数 arg に代入されたオブジェクトの名称を表示します。なお、この機能は varname.argname()関数を使って実装されています。\nmultiple：bool 　引数の値として複数の値を許容するかどうかを示すブール値。arg にリストが代入された場合、multiple = False（初期設定）であれば最初の値のみを出力し、multiple = True であればリストの値を全て出力します。\nany_missing:bool True の場合、欠測値（例：None、NaN、pd.NA など）が引数 arg の一部に含まれていても許容されます。\nall_missing: bool True の場合、すべての要素が欠測値であることを許容します。\nnullable: bool True の場合、引数そのものが None であることを許容します。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>building_block.arg_match</span>"
    ]
  },
  {
    "objectID": "man/arg_match.html#返り値-value",
    "href": "man/arg_match.html#返り値-value",
    "title": "building_block.arg_match",
    "section": "返り値 Value",
    "text": "返り値 Value\n　引数 arg に代入された値が、values に代入されたリストに含まれていればその値を返し、そうでなければエラーメッセージを出力します。エラーメッセージでは values に代入されたリストの値を arg の適正な値の候補として提示します。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>building_block.arg_match</span>"
    ]
  },
  {
    "objectID": "man/arg_match.html#使用例-examples",
    "href": "man/arg_match.html#使用例-examples",
    "title": "building_block.arg_match",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nfrom py4stats import building_block as build\n\ndef my_faivarit(fruits):\n  fruits = build.arg_match(\n      fruits, arg_name = 'fruits',\n      values = ['apple', 'orange', 'grape'], \n      multiple = False\n      )\n  return fruits\n\nmy_faivarit('apple')\n#&gt; 'apple'\n\nmy_faivarit('orang')\n#&gt; ValueError: `fruits` must be one of 'apple', 'orange' or 'grape', not 'orang'.\n#&gt;              Did you mean 'orange'?\n\nmy_faivarit('ap')\n#&gt; ValueError: `fruits` must be one of 'apple', 'orange' or 'grape', not 'ap'.\n#&gt;              Did you mean 'apple' or 'grape'?\n# arg に list を指定した場合\n# 初期設定では1つ目の要素だけ使用されます。\nmy_faivarit(['apple', 'orange'])\n#&gt; 'apple'\n\n# multiple = True として再度関数を定義\ndef my_faivarit2(fruits):\n  fruits = build.arg_match(\n      fruits, arg_name = 'fruits',\n      values = ['apple', 'orange', 'grape'], \n      multiple = True\n      )\n  return fruits\n\nmy_faivarit2(['apple', 'orange'])\n#&gt; ['apple', 'orange']\n\nmy_faivarit2(['apple', 'orang'])\n#&gt; ValueError: `fruits` must be one of 'apple', 'orange' or 'grape', not 'orang'.\n#&gt;              Did you mean 'orange'?\n　Py4Stats では eda_tools.tabyl()や regression_tools.compare_ols() など、文字列で指定する引数をもつ関数で、引数のアサーションに build.arg_match() を使用しています。\nimport py4stats as py4st\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins() # サンプルデータの読み込\n\npy4st.tabyl(penguins, 'island', 'species', normalize = 'ind')\n#&gt; ValueError: `normalize` must be one of 'index', 'columns' or 'all', not 'ind'.\n#&gt;              Did you mean 'index'?\n\nReturn to Function reference.",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>building_block.arg_match</span>"
    ]
  },
  {
    "objectID": "man/assert_dtype.html",
    "href": "man/assert_dtype.html",
    "title": "building_block.assert_dtypes",
    "section": "",
    "text": "概要\nデータ型による引数のアサーション\nR言語の checkmate パッケージの関数群をオマージュした、引数に代入された値が想定されたデータ型ではないときにエラーを出力する関数です。\nそれぞれの関数は第一引数 arg に代入された array-like オブジェクトの要素が、次の型ではない場合にエラーを出力します。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>building_block.assert_dtypes</span>"
    ]
  },
  {
    "objectID": "man/assert_dtype.html#概要",
    "href": "man/assert_dtype.html#概要",
    "title": "building_block.assert_dtypes",
    "section": "",
    "text": "assert_character(\n    arg: Any, \n    arg_name: Optional[str] = None,\n    len_arg: Optional[int] = None,\n    len_min: int = 1,\n    len_max: Optional[int] = None,\n    any_missing: bool = False,\n    all_missing: bool = False,\n    nullable: bool = False,\n    scalar_only: bool = False\n    )\n\nassert_logical(\n    arg: Any, \n    arg_name: Optional[str] = None,\n    len_arg: Optional[int] = None,\n    len_min: int = 1,\n    len_max: Optional[int] = None,\n    any_missing: bool = False,\n    all_missing: bool = False,\n    nullable: bool = False,\n    scalar_only: bool = False\n    )\n\nassert_numeric(\n    arg: Any,\n    arg_name: Optional[str] = None,\n    lower = -float('inf'), \n    upper = float('inf'), \n    inclusive: Literal[\"both\", \"neither\", \"left\", \"right\"] = \"both\",\n    len_arg: Optional[int] = None,\n    len_min: int = 1,\n    len_max: Optional[int] = None,\n    any_missing: bool = False,\n    all_missing: bool = False,\n    nullable: bool = False,\n    scalar_only: bool = False\n    )\n\nassert_integer(\n    arg: Any,\n    arg_name: Optional[str] = None,\n    lower = -float('inf'), \n    upper = float('inf'), \n    inclusive: Literal[\"both\", \"neither\", \"left\", \"right\"] = \"both\",\n    len_arg: Optional[int] = None,\n    len_min: int = 1,\n    len_max: Optional[int] = None,\n    any_missing: bool = False,\n    all_missing: bool = False,\n    nullable: bool = False,\n    scalar_only: bool = False\n    )\n\nassert_count(\n    arg: Any,\n    arg_name: Optional[str] = None,\n    lower = 0, \n    upper = float('inf'), \n    inclusive: Literal[\"both\", \"neither\", \"left\", \"right\"] = \"both\",\n    len_arg: Optional[int] = None,\n    len_min: int = 1,\n    len_max: Optional[int] = None,\n    any_missing: bool = False,\n    all_missing: bool = False,\n    nullable: bool = False,\n    scalar_only: bool = False\n    )\n\nassert_float(\n    arg: Any,\n    arg_name: Optional[str] = None,\n    lower = -float('inf'), \n    upper = float('inf'), \n    inclusive: Literal[\"both\", \"neither\", \"left\", \"right\"] = \"both\",\n    len_arg: Optional[int] = None,\n    len_min: int = 1,\n    len_max: Optional[int] = None,\n    any_missing: bool = False,\n    all_missing: bool = False,\n    nullable: bool = False,\n    scalar_only: bool = False\n    )\n\n\nassert_character()：str\nassert_numeric()：int or float\nassert_integer()：int\nassert_count()：int\nassert_float()：float",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>building_block.assert_dtypes</span>"
    ]
  },
  {
    "objectID": "man/assert_dtype.html#引数-argument",
    "href": "man/assert_dtype.html#引数-argument",
    "title": "building_block.assert_dtypes",
    "section": "引数 Argument",
    "text": "引数 Argument\n\narg（必須）array-like 　適正かどうかを判断したい引数。検証対象となる引数。スカラー値、または array-like オブジェクト（例：list、NumPy 配列、pandas Series）を指定できます。\narg_name：str 　エラーメッセージに表示する引数の名前。None の場合、可能であれば arg に渡された変数名が自動的に推定されます。なお、この機能は varname.argname()関数を使って実装されています。\nlower, upper：int or float 　arg に代入されたオブジェクトの要素が取るべき値の最大値と最小値。\ninclusive：str 　値の範囲チェックにおいて、境界値を含めるかどうかを表す文字列。 'both', 'neither', 'left', 'right' から選択できます。\n\n'both'：lower &lt;= x &lt;= upper\n'neither'：lower &lt; x &lt; upper\n'left'：lower &lt;= x &lt; upper\n'right'：lower &lt; x &lt;= upper\n\nlen_arg: int 引数の要素数を表す自然数：要素数をこの値と正確に一致させたい場合に指定します。len_arg を指定した場合、引数はちょうどこの個数の要素をもつ必要があります。 　引数の長さは、None や np.nan などの欠測値を含む要素数をもとに判定されます。例えば引数の要素が arg = [1, None, 3] のとき、len_arg = 3なら正常として判定され、len_arg = 2 ならエラーが出されます。\nlen_min, len_max:: int 許容される最小の要素数と最大の要素数。len_max = None の場合、上限は設けられません。\nany_missing:bool True の場合、欠測値（例：None、NaN、pd.NA など）が引数 arg の一部に含まれていても許容されます。\nall_missing: bool True の場合、すべての要素が欠測値であることを許容します。\nnullable: bool True の場合、引数そのものが None であることを許容します。\nscalar_only: bool True の場合、スカラー値のみを許容します。この場合、1要素であっても、list や配列などの array-like オブジェクトは受け付けません。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>building_block.assert_dtypes</span>"
    ]
  },
  {
    "objectID": "man/assert_dtype.html#返り値-value",
    "href": "man/assert_dtype.html#返り値-value",
    "title": "building_block.assert_dtypes",
    "section": "返り値 Value",
    "text": "返り値 Value\n引数 arg に代入されたオブジェクトの全ての要素が、アサーションの条件を満たしていれば何も返さず、そうでなければエラーメッセージを出力します。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>building_block.assert_dtypes</span>"
    ]
  },
  {
    "objectID": "man/assert_dtype.html#使用例-examples",
    "href": "man/assert_dtype.html#使用例-examples",
    "title": "building_block.assert_dtypes",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nfrom py4stats import building_block as build\nx = [1, 2, 3]\ny = ['A', 'B', 'C']\n\nbuild.assert_character(x, arg_name = 'x')\n#&gt; TypeError: Argument `x` must be of type 'str'.\n\nbuild.assert_character(y, arg_name = 'y')\nbuild.assert_numeric(x, arg_name = 'x')\n\nbuild.assert_numeric(y, arg_name = 'y')\n#&gt; TypeError: Argument `y` must be of type 'int' or 'float' with value(s) -inf &lt;= x &lt;= inf.\n\nz = [0.1, 0.3, 0.6]\nbuild.assert_numeric(z, arg_name = 'z', lower = 0, upper = 1)\n\nz.extend([2, 3])\nbuild.assert_numeric(z, arg_name = 'z', lower = 0, upper = 1)\n#&gt; ValueError: Argument `z` must have value 0 &lt;= x &lt;= 1\n#&gt; element '3' and '4' of 'z' not sutisfy the condtion.\n\nz = 1\nbuild.assert_numeric(\n    z, arg_name = 'z', \n    lower = 0, upper = 1, \n    inclusive = 'left'\n    )\n#&gt; ValueError: Argument `z` must have value 0 &lt;= x &lt; 1.",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>building_block.assert_dtypes</span>"
    ]
  },
  {
    "objectID": "man/assert_dtype.html#参照",
    "href": "man/assert_dtype.html#参照",
    "title": "building_block.assert_dtypes",
    "section": "参照",
    "text": "参照\n　データ型の判定にはこちらの関数を使用しています。\n\nReturn to Function reference.",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>building_block.assert_dtypes</span>"
    ]
  },
  {
    "objectID": "man/is_dtype.html",
    "href": "man/is_dtype.html",
    "title": "building_block.is_dtypes",
    "section": "",
    "text": "概要\nデータ型を判定する論理関数\n代入された値、あるいはリストの要素が特定のデータ型であるかどうかを判定する関数です。基本的には pandas.api.types.is_*() 関数のラッパー関数で、命名規則はR言語の同種の関数に基づいています。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>building_block.is_dtypes</span>"
    ]
  },
  {
    "objectID": "man/is_dtype.html#概要",
    "href": "man/is_dtype.html#概要",
    "title": "building_block.is_dtypes",
    "section": "",
    "text": "is_character(x)\n\nis_logical(x)\n\nis_numeric(x)\n\nis_integer(x)\n\nis_float(x)",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>building_block.is_dtypes</span>"
    ]
  },
  {
    "objectID": "man/is_dtype.html#引数-argument",
    "href": "man/is_dtype.html#引数-argument",
    "title": "building_block.is_dtypes",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nx（必須）array, list, or pd.Series",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>building_block.is_dtypes</span>"
    ]
  },
  {
    "objectID": "man/is_dtype.html#返り値-value",
    "href": "man/is_dtype.html#返り値-value",
    "title": "building_block.is_dtypes",
    "section": "返り値 Value",
    "text": "返り値 Value\n引数 x が次の型であるときに、True を返します。\n\nis_character()：str\nis_logical()：bool\nis_numeric()：int, float or bool\nis_integer()：int or bool\nis_float()：float",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>building_block.is_dtypes</span>"
    ]
  },
  {
    "objectID": "man/is_dtype.html#使用例-examples",
    "href": "man/is_dtype.html#使用例-examples",
    "title": "building_block.is_dtypes",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nfrom py4stats import building_block as build\nx_str = ['A', 'B']\nx_bool = [True, False, True]\nx_int = [1, 2, 3]\nx_float = [0, 1, 2.1, 0.5]\nx_list = [x_str, x_bool, x_int, x_float]\n\nprint([build.is_character(x) for x in x_list])\n#&gt; [True, False, False, False]\n\nprint([build.is_logical(x) for x in x_list])\n#&gt; [False, True, False, False]\n\nprint([build.is_numeric(x) for x in x_list])\n#&gt; [False, True, True, True]\n\nprint([build.is_integer(x) for x in x_list])\n#&gt; [False, False, True, False]\n\nprint([build.is_float(x) for x in x_list])\n#&gt; [False, False, False, True]\n\nReturn to Function reference.",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>building_block.is_dtypes</span>"
    ]
  },
  {
    "objectID": "man/miscellaneous.html",
    "href": "man/miscellaneous.html",
    "title": "building_block.style_number, _currency, _percent",
    "section": "",
    "text": "概要\n数字のフォーマットを変更する関数",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>building_block.style_number, _currency, _percent</span>"
    ]
  },
  {
    "objectID": "man/miscellaneous.html#概要",
    "href": "man/miscellaneous.html#概要",
    "title": "building_block.style_number, _currency, _percent",
    "section": "",
    "text": "style_number(x, digits = 2, big_mark = ',')\n\nstyle_currency(x, symbol = '$', digits = 0, big_mark = ',')\n\nstyle_percent(x, digits = 2, unit = 100, symbol = '%')",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>building_block.style_number, _currency, _percent</span>"
    ]
  },
  {
    "objectID": "man/miscellaneous.html#引数-argument",
    "href": "man/miscellaneous.html#引数-argument",
    "title": "building_block.style_number, _currency, _percent",
    "section": "引数 Argument",
    "text": "引数 Argument\n\nx：scalar or array-like of int or float\np_value：scalar or array-like of int or float\ndigits：int 小数点以下の桁数\nbig_mark：int 3桁毎の桁区切りに使用する記号。カンマ ',', アンダーバー '_', もしくは 非表示 '' から選ぶことができます。\nsymbol：str 　貨幣記号を表す文字列",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>building_block.style_number, _currency, _percent</span>"
    ]
  },
  {
    "objectID": "man/miscellaneous.html#返り値-value",
    "href": "man/miscellaneous.html#返り値-value",
    "title": "building_block.style_number, _currency, _percent",
    "section": "返り値 Value",
    "text": "返り値 Value\n　以下の値をもつ pd.Series を返します。\n\nbuilding_block.style_number()： 任意の数値に対して、小数点以下を桁数 digits に丸め、3桁区切り記号を通過した値を文字列として返します。f-string によるフォーマット f'{x:{big_mark}.{digits}f}' を用いて実装されています。\nbuilding_block.style_currency()： build.style_number() と同じく任意の数値に対して、小数点以下を桁数 digits に丸め、3桁区切り記号を通過した値を文字列として返しますが、さらに貨幣記号を追加します。f-string によるフォーマット f'{symbol}{x:{big_mark}.{digits}f}' を用いて実装されています。\nbuilding_block.style_percent()： 任意の数値をパーセンテージ表示に変換した値を文字列として返します。f-string によるフォーマット f'{x:,.{digits}%}' を用いて実装されています。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>building_block.style_number, _currency, _percent</span>"
    ]
  },
  {
    "objectID": "man/miscellaneous.html#使用例-examples",
    "href": "man/miscellaneous.html#使用例-examples",
    "title": "building_block.style_number, _currency, _percent",
    "section": "使用例 Examples",
    "text": "使用例 Examples\nimport numpy as np\nfrom py4stats import building_block as build\n\nx = [2000, 1000, 0.5, 0.11, 0.123]\n\nprint(build.style_number(x).to_list())\n#&gt; ['2,000.00', '1,000.00', '0.50', '0.11', '0.12']\n\nprint(build.style_number(x, big_mark = '').to_list())\n#&gt; ['2000.00', '1000.00', '0.50', '0.11', '0.12']\n\nprint(build.style_currency(x).to_list())\n#&gt; ['$2,000', '$1,000', '$0', '$0', '$0']\npct = [0.11, 0.06, 0.05, 0.01, 0.00234]\n\nprint(build.style_percent(pct).to_list())\n#&gt; ['11.00%', '6.00%', '5.00%', '1.00%', '0.23%']\n\nprint(build.style_percent(pct, unit = 1).to_list())\n#&gt; ['0.11%', '0.06%', '0.05%', '0.01%', '0.00%']\n\nprint(build.style_percent(pct, unit = 1000, symbol = '‰').to_list())\n#&gt; ['110.00‰', '60.00‰', '50.00‰', '10.00‰', '2.34‰']\n\nReturn to Function reference.",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>building_block.style_number, _currency, _percent</span>"
    ]
  },
  {
    "objectID": "man/style_pvalue.html",
    "href": "man/style_pvalue.html",
    "title": "building_block.style_pvalue, p_stars",
    "section": "",
    "text": "概要\np-値のフォーマットを変更する関数\nR言語の style_pvalue() と gtools::stars.pval() をオマージュした関数でp-値を見やすい形のフォーマットに変換します。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>building_block.style_pvalue, p_stars</span>"
    ]
  },
  {
    "objectID": "man/style_pvalue.html#概要",
    "href": "man/style_pvalue.html#概要",
    "title": "building_block.style_pvalue, p_stars",
    "section": "",
    "text": "style_pvalue(\n    p_value: ArrayLike,\n    digits: int = 3,\n    prepend_p: bool = False,\n    p_min: float = 0.001,\n    p_max: float = 0.9\n    )\n\np_stars(\n    p_value, \n    stars = {'***':0.01, '**':0.05, '*':0.1}\n    )",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>building_block.style_pvalue, p_stars</span>"
    ]
  },
  {
    "objectID": "man/style_pvalue.html#引数-argument",
    "href": "man/style_pvalue.html#引数-argument",
    "title": "building_block.style_pvalue, p_stars",
    "section": "引数 Argument",
    "text": "引数 Argument\n\np_value：scalar or array-like of int or float\ndigits：int（style_pvalue() のみ） 　小数点以下の桁数\nprepend_p：bool（style_pvalue() のみ） 　出区力に接頭辞 ’p’ を追加するかどうかを表す論理値。False であれば追加されず、True であれば追加されます。\np_min：int（style_pvalue() のみ） 　p-値を実数値で表示する最小値。p_value がこの値を下回る場合、’&lt;p_min’ もしくは ’p&lt;p_min’ の形で表示されます。\np_max：int（style_pvalue() のみ） 　p-値を実数値で表示する最大値。p_value がこの値を下回る場合、’&gt;p_max’ もしくは ’p&gt;p_max’ の形で表示されます。\nstars：dict（p_stars() のみ） 　有意性を示す記号を key に、表示を切り替える閾値を値(value)にもつ辞書オブジェクト。初期設定の stars = None の場合、{'***': 0.01, '**': 0.05, '*': 0.1} が使用されます。詳細は下記を参照して下さい。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>building_block.style_pvalue, p_stars</span>"
    ]
  },
  {
    "objectID": "man/style_pvalue.html#返り値-value",
    "href": "man/style_pvalue.html#返り値-value",
    "title": "building_block.style_pvalue, p_stars",
    "section": "返り値 Value",
    "text": "返り値 Value\n　フォーマットされたp-値を表す pd.Series を出力します。building_block.style_pvalue() では引数 p_value に与えられた数値を指定された桁数に丸めた値を表示し、指定された範囲を外れる値については ’&lt;p_min’ や ’&gt;p_max’の書式にへんかんします。   　building_block.p_stars()では仮説検定の有意性を示すアスタリスク*` に変換します。初期設定ではアスタリスクはp-値の値に応じて次のように表示されます。\n\np ≤ 0.1 *\np ≤ 0.05 **\np ≤ 0.01 ***\np &gt; 0.1 表示なし",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>building_block.style_pvalue, p_stars</span>"
    ]
  },
  {
    "objectID": "man/style_pvalue.html#使用例-examples",
    "href": "man/style_pvalue.html#使用例-examples",
    "title": "building_block.style_pvalue, p_stars",
    "section": "使用例 Examples",
    "text": "使用例 Examples\n\nfrom py4stats import building_block as build\np_value = [\n    0.999, 0.5028, 0.2514, 0.197, 0.10, \n    0.0999, 0.06, 0.03, 0.002, 0.0002\n    ]\n\nprint(build.style_pvalue(p_value).to_list())\n#&gt; ['&gt;0.9', '0.503', '0.251', '0.197', '0.1', '0.1', '0.06', '0.03', '0.002', '&lt;0.001']\n\nprint(build.style_pvalue(p_value, prepend_p = True).to_list())\n#&gt; ['p&gt;0.9', 'p=0.503', 'p=0.251', 'p=0.197', 'p=0.1', 'p=0.1', 'p=0.06', 'p=0.03', 'p=0.002', 'p&lt;0.001']\n\nprint(build.p_stars(p_value).to_list())\n#&gt; ['', '', '', '', '*', '*', '*', '**', '***', '***']\n\n# R言語の stats::summary.lm() や gtools::stars.pval() を再現する場合。\nstars_dict = {'***':0.001, '**':0.01, '*': 0.05, '.':0.1}\nprint(build.p_stars(p_value, stars = stars_dict).to_list())\n#&gt; ['', '', '', '', '.', '.', '.', '*', '**', '***']\n\nReturn to Function reference.",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>building_block.style_pvalue, p_stars</span>"
    ]
  },
  {
    "objectID": "man/oxford_comma.html",
    "href": "man/oxford_comma.html",
    "title": "building_block.oxford_comma",
    "section": "",
    "text": "概要\n文字列のリストから並列文を作成する関数\n文字列のリストを与えると、リストの要素を英文における並列文の形に変換する関数です。表記法については Wikipedia Serial comma を参照し、コードについては stack overflow:Grammatical List Join in Python [duplicate] を参照しました。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>building_block.oxford_comma</span>"
    ]
  },
  {
    "objectID": "man/oxford_comma.html#概要",
    "href": "man/oxford_comma.html#概要",
    "title": "building_block.oxford_comma",
    "section": "",
    "text": "oxford_comma(\n    x: Union[str, List[str]], \n    sep_last: str = \"and\", \n    quotation: bool = True\n    )\n\noxford_comma_and(\n    x: Union[str, List[str]], \n    quotation: bool = True\n    )\n\noxford_comma_or(\n    x: Union[str, List[str]], \n    quotation: bool = True\n    )\n\noxford_comma_shorten(\n    x: List[str], \n    sep_last: str = 'and', \n    quotation: bool = True, \n    suffix: str = 'items', \n    max_items: Optional[int] = None,\n    max_width: int = 80,\n    abbreviate: bool = True\n)",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>building_block.oxford_comma</span>"
    ]
  },
  {
    "objectID": "man/oxford_comma.html#引数",
    "href": "man/oxford_comma.html#引数",
    "title": "building_block.oxford_comma",
    "section": "引数",
    "text": "引数\n\nx：str or list of str\nsep_last: str oxford_comma() のみ 　リストの最後の要素の直前に付加する単語を表す文字列。\nquotation: bool 　リストの各要素にクオーテーションマーク ’’ を追加するかどうかを表す論理値。True（初期設定）であればクオーテーションマークを追加し、False であれば追加しません。\nsuffix：str oxford_comma_shorten() のみ 省略された要素を表すための補足語。\"other N items\" の items の部分に使用されます。\nmax_items：int oxford_comma_shorten() のみ abbreviate=True の時に表示する要素の最大個数。max_items が指定され、かつ x 数より少ない場合、出力には最初の max_items 個のアイテムが表示され、その後 \"and other N {suffix}\" の表記が追加されます。None の場合、テキスト幅に基づいて省略処理が行われます。\nmax_width：int oxford_comma_shorten() のみ 出力される文字列の最大幅。返り値の文字列がこの幅を超える場合、省略処理が行われます。デフォルトは80です。\nabbreviate: bool oxford_comma_shorten() のみ 省略処理を許可するかどうか。False を指定した場合、x の要素数や文字幅に関わらず常に全文を返します。デフォルトは True です。abbreviate = False が指定された場合、oxford_comma_shorten() の動作は oxford_comma() と同等になります。\n\nなお、oxford_comma_and(x) は oxford_comma(x, 'and') と、oxford_comma_or(x) は oxford_comma(x, 'or') と同等です。oxford_comma_shorten() は、生成されたテキストが指定された文字幅を超える場合に、自動的に省略表示を行います。省略が発生した場合は、\"and other N items\" のように、省略された要素の数が分かる表現を付加します。",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>building_block.oxford_comma</span>"
    ]
  },
  {
    "objectID": "man/oxford_comma.html#使用例-example",
    "href": "man/oxford_comma.html#使用例-example",
    "title": "building_block.oxford_comma",
    "section": "使用例 Example",
    "text": "使用例 Example\nfrom py4stats import building_block as build\nx = ['A', 'B', 'C']\n\nprint(build.oxford_comma_and(x))\n#&gt; 'A', 'B' and 'C'\n\nprint(build.oxford_comma_and(x, quotation = False))\n#&gt; A, B and C\n\nprint(build.oxford_comma_or(x))\n#&gt; 'A', 'B' or 'C'\nリストの要素が1つの場合、あるいは x に文字列が指定された場合はカンマなどを追加せずにそのまま出力します。\nprint(build.oxford_comma_or(['A']))\n#&gt; 'A'\n\nprint(build.oxford_comma_or('A'))\n#&gt; 'A'\nリストの要素が1つの場合、あるいは x に文字列が指定された場合はカンマなどを追加せずにそのまま出力します。\nimport string\nalpha = list(string.ascii_lowercase)\n        \nprint(build.oxford_comma_shorten(alpha))\n#&gt; \"'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l' and other 14 items\"\n        \nprint(build.oxford_comma_shorten(alpha, max_width = 40))\n#&gt; \"'a', 'b', 'c', 'd' and other 22 items\"\n\n# リストが十分に短い場合は、省略されません\nprint(build.oxford_comma_shorten(alpha[:10]))\n#&gt; \"'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i' and 'j'\"\n\nReturn to Function reference.",
    "crumbs": [
      "**building_block**",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>building_block.oxford_comma</span>"
    ]
  },
  {
    "objectID": "articles/release_notes.html",
    "href": "articles/release_notes.html",
    "title": "Release Notes",
    "section": "",
    "text": "Py4Stats v0.4.0 2026-01-27",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Release Notes</span>"
    ]
  },
  {
    "objectID": "articles/release_notes.html#py4stats-v0.4.0-2026-01-27",
    "href": "articles/release_notes.html#py4stats-v0.4.0-2026-01-27",
    "title": "Release Notes",
    "section": "",
    "text": "概要（Summary）\nこのリリースでは review_wrangling() 関数を追加し、既存関数のリファクタリングとバグ修正を行いました。\n\n\n✨ 主な新機能 （New Features）\n\nreview_wrangling() 関数の追加\n\nデータ前処理（wrangling）による変更点をレビュー形式で要約して、文字列として出力する関数です。\n\n\n\n\n🛠 修正と改善（Fixes /Improvements）\n\nrelocate(): *args 引数が未指定であった場合のエラーメッセージを改善しました。\nis_dummy(): data 引数に list を代入した場合でも dropna = True が正しく機能するように修正しました。\nmean_qi(), median_qi(), mean_ci(), scale(), min_max()\n\n関数のリファクタリングを実施し、メソッドが未実装のオブジェクトを代入したときのエラーメッセージを改善しました。\n\nset_miss(): pd.DataFram に使用した場合、欠測率が prop で指定した値より高くなる現象を修正しました。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Release Notes</span>"
    ]
  },
  {
    "objectID": "articles/release_notes.html#py4stats-v0.3.0-2026-01-23",
    "href": "articles/release_notes.html#py4stats-v0.3.0-2026-01-23",
    "title": "Release Notes",
    "section": "Py4Stats v0.3.0 2026-01-23",
    "text": "Py4Stats v0.3.0 2026-01-23\n\n概要（Summary）\nこのリリースでは Pyt4Stats に幾つかの関数の追加を行いました。 関数のリファクタリングとバグ修正を行いました。今回のリリースでは機能の追加や変更はありません。\n\n\n✨ 主な新機能 （New Features）\n\ndiagnose_category() 関数の追加\n\nデータフレームのカテゴリー変数の要約を提供する関数です。\n\nset_miss() 関数の追加\n\nSeries の非欠測要素のうち、指定された個数または割合を欠測値に置き換えます。\n\n\n\n\n🛠 修正と改善（Fixes /Improvements）\n\ncompare_group_means(), compare_group_median(), compare_df_cols(), compare_df_stats(): コードをリファクタリングし、引数と同じクラスのデータフレームを出力できるようにしました。この変更により、返り値が pd.DataFrame である場合でも、index が自動では設定されなくなりました。\ndiagnose(): dtype 列が、polars や pyarrow における列のクラスの表記に対してより忠実になるように修正しました。\nrelocate() 関数に、指定した列を最後列に配置する機能を追加し、エラーメッセージを改善しました。\nassert_character() および assert_numeric() 系関数のエラーメッセージを改善しました。\nその他、いくつかの関数のエラーメッセージを改善しました。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Release Notes</span>"
    ]
  },
  {
    "objectID": "articles/release_notes.html#py4stats-v0.2.2-2026-01-19",
    "href": "articles/release_notes.html#py4stats-v0.2.2-2026-01-19",
    "title": "Release Notes",
    "section": "Py4Stats v0.2.2 2026-01-19",
    "text": "Py4Stats v0.2.2 2026-01-19\n\n概要（Summary）\n型ヒントに関する若干の修正と、バグ修正を行いました。今回のリリースでは機能の追加や変更はありません。\n\n\n🛠 修正と改善（Fixes /Improvements）\n\nbuilding_block.assert_numeric 系関数のリファクタリングを行いました。この変更でメインモジュールの関数の動作に変更はありません。\ncompare_group_means(), compare_group_median() のテストコードを実装しました。\ntabyl(): 第一引数 data と同じオブジェクト型をもつ DataFrame を出力できるように実装を修正しました。\ncheck_that(), check_viorate() : 第一引数 data と同じオブジェクト型をもつ DataFrame を出力できるように実装を修正しました。引き続きロジックのコア部分には pd.DataFrame.eval() を使用しており、使用方法に大きな変更はありません。\nis_number() 関数を修正し、pyarrow.lib.ChunkedArray オブジェクトを代入すると生じるエラーを解消しました。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Release Notes</span>"
    ]
  },
  {
    "objectID": "articles/release_notes.html#py4stats-v0.2.1-2026-01-16",
    "href": "articles/release_notes.html#py4stats-v0.2.1-2026-01-16",
    "title": "Release Notes",
    "section": "Py4Stats v0.2.1 2026-01-16",
    "text": "Py4Stats v0.2.1 2026-01-16\n\n概要（Summary）\nこのリリースでは Pyt4Stats の各モジュールに幾つかの関数の追加を行いました。\n\n\n✨ 主な新機能 （New Features）\n\nplot_category() 関数の追加\n\nカテゴリ変数の回答分布を 100% 積み上げ横棒グラフとして描画する関数です。\n\nplot_miss_var() 関数の追加\n\nデータフレームの各変数について欠測値の量を横棒グラフとして可視化します。\n\nrelocate() 関数の追加\n\nデータフレームの列を、削除することなく並べ替えます。\n\nweighted_mean(), scale(), min_max() 関数の追加\n\nそれぞれ Series オブジェクトの加重平均の計算と、標準化を行う関数です。\n\n\n\n\n🛠 修正と改善（Fixes /Improvements）\n\neda_tools の Pandas ベース実装 eda_tools/_pands.py に、FutureWarning を実装しました。\nユーザビリティ向上のため、freq_table() 関数に sort_by 引数を導入しました。\n\nsort_by = 'frequency' なら度数分布表を頻度に応じてソートし（従来の sort = True に相当）、sort_by = 'values' なら subset で指定した列の値に応じてソートします（従来の sort = False に相当）。\nこの変更に合わせて、sort 引数は非推奨扱いに変更されています。\n\nPareto_plot() の aggfunc 引数に、np.mean など values 列を1次元配列として受け取って単一の数値を返す任意の関数を使用できるように改良を行いました。\nその他、py4stats ライブラリ全体のエラーメッセージ改善\nbuilding_block.assert_* 系関数の改良を行い、与えられた引数の要素数に関するアサーションと、None やリストを拒否する機能を追加しました。\ncmpare_ols() および cmpare_mfx() に stars 引数を追加し、有意性のアスタリスクの表示形式を変更できる機能を追加しました。また、その他エラーメッセージの改善を行なっています。\n\n\n\n⚠️ 既知の制限・注意点（Notes）\n\npyarrow.Table を使用する場合、plot_category() 関数の一部機能が制限されます。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Release Notes</span>"
    ]
  },
  {
    "objectID": "articles/release_notes.html#py4stats-v0.1.0-2026-01-11",
    "href": "articles/release_notes.html#py4stats-v0.1.0-2026-01-11",
    "title": "Release Notes",
    "section": "Py4Stats v0.1.0 2026-01-11",
    "text": "Py4Stats v0.1.0 2026-01-11\n\n概要（Summary）\nこのリリースでは EDA モジュールの narwhals ベース実装を統合し、パフォーマンスと互換性を大幅に改善しました。いくつかの既知の挙動も修正されています。\n\n\n✨ 主な新機能 （New Features）\n\npy4stats.eda_tools が Pandas ベースの実装から narwhals ベース実装へ移行しました。\n\nこの変更により、複数バックエンド（pandas / polars / pyarrow）をサポートしました。\n\nPandas ベースの実装は、当面 py4stats ライブラリのサブモジュール eda_tools._pandas として維持されますが、将来的に廃止される予定です。\n\n\n\n🛠 修正と改善（Fixes /Improvements）\n\nbilding_block モジュールの名称を building_block に修正\nPy4Stats.building_block モジュールの assert_* 系関数の出力を AssertionError から ValueError に変更しました。\nPy4Stats.eda_tools モジュールの関数の bool 値の引数を中心に、型の不一致があった場合のエラーメッセージを改善しました。\n\n\n\n⚠️ 既知の制限・注意点（Notes）\n\nバックエンドの変更に伴い、py4st.freq_table()、py4st.diagnose()、py4st.tabyl() など、従来はインデックス（Index）付きの pandas.DataFrame データフレームが出力されていた関数で、インデックスのない pandas.DataFrame が出力されるように変更されました。\npolars / pyarrow のサポートは experimental であり、一部のエッジケースで動作に違いが出る可能性があります。詳細は Technical Notes および eda_tools開発状況 を参照してください。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Release Notes</span>"
    ]
  },
  {
    "objectID": "articles/scaling_up_regression.html",
    "href": "articles/scaling_up_regression.html",
    "title": "scaling up regression",
    "section": "",
    "text": "複数の回帰式を比較する\nここでは実証分析の場面で便利な回帰分析の実装例を紹介します。\n異なる説明変数の組合せを比較したい場合、リスと内包表記を使って実装するとコードが簡潔で扱いやすくなります。まずは smf.ols() をもとに回帰式を受け取って回帰分析の結果を返す関数 fit_ols と、回帰式のリストlist_fml を定義します。\n回帰分析の実行部分は次のように記述します。\nこのとき list_fitted1 は回帰分析の推定結果を要素に持つリストであるため、py4st.compare_ols() にそのまま代入することができます。\nこの方法であれば、試したい回帰式のパターンが増えた場合でも、list_fml の要素を追加するだけで済むため、実行部分を変更する必要がありません。\n　また、回帰係数を視覚的に比較するには次のようなコードを使うと良いでしょう。\n## グループ別の回帰分析\n次に、データセットのグループ別に回帰分析を行う場合を考えます。この場合、データを受け取ると回帰分析の結果を返す関数 group_ols を定義し、回帰式は固定しておきます。\n次に pd.DataFrame の .groupby() メソッドを使ってグループ分けを行い、続いて .apply() メソッドを使ってグループ別に回帰分析を実行します。ここでは、実行結果が回帰分析の結果を要素にもつ pd.Series になるので、.to_list() メソッドでリストに変換しています。\nここまでの準備ができれば、後は py4st.compare_ols() で分析結果を比較できます。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>scaling up regression</span>"
    ]
  },
  {
    "objectID": "articles/scaling_up_regression.html#複数の回帰式を比較する",
    "href": "articles/scaling_up_regression.html#複数の回帰式を比較する",
    "title": "scaling up regression",
    "section": "",
    "text": "# 回帰分析の推定\ndef fit_ols(fml, data):\n  res = smf.ols(fml, data = data).fit()\n  return res\n\nlist_fml = [\n    'body_mass_g ~ bill_length_mm + species',\n    'body_mass_g ~ bill_length_mm + bill_depth_mm + species',\n    'body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex'\n]\n\n# 回帰分析の実行\nlist_fitted1 = [fit_ols(fml, penguins) for fml in list_fml]\n\npy4st.compare_ols(list_models = list_fitted1) # 表の作成\n\n\n\n\n\n\n\n\n\nterm\nmodel 1\nmodel 2\nmodel 3\n\n\n\n\nIntercept\n153.7397\n-1742.7202 ***\n843.9812 **\n\n\n\n(268.9012)\n(313.7697)\n(403.5956)\n\n\nspecies[T.Chinstrap]\n-885.8121 ***\n-539.6864 ***\n-245.1516 ***\n\n\n\n(88.2502)\n(86.9425)\n(84.5952)\n\n\nspecies[T.Gentoo]\n578.6292 ***\n1492.8283 ***\n1443.3525 ***\n\n\n\n(75.3623)\n(118.4442)\n(107.7844)\n\n\nbill_length_mm\n91.4358 ***\n55.6461 ***\n26.5366 ***\n\n\n\n(6.8871)\n(7.2326)\n(7.2436)\n\n\nbill_depth_mm\n\n179.0434 ***\n87.9328 ***\n\n\n\n\n(19.0997)\n(20.2192)\n\n\nsex[T.male]\n\n\n437.2007 ***\n\n\n\n\n\n(49.1098)\n\n\nrsquared_adj\n0.7810\n0.8258\n0.8613\n\n\nnobs\n342\n342\n333\n\n\ndf\n3\n4\n5\n\n\n\n\nplt.rcParams[\"figure.autolayout\"] = True\n\nfig, ax = plt.subplots(1, 3, figsize = (3.2 * 5, 5), dpi = 100)\n\nfor k, mod in enumerate(list_fitted1):\n  py4st.coefplot(mod, ax = ax[k])\n  ax[k].set_xlim(-1200, 1800)\n  ax[k].set_title(f'model {k + 1}')\n  ax[k].set_xlabel(f'coefficient (n = {mod.nobs:,.0f})')\n\n\n# グループ別の回帰分析の実行\ndef group_ols(data):\n  res = smf.ols(\n      'body_mass_g ~ bill_length_mm + bill_depth_mm + sex', \n      data = data).fit()\n  return res\n\npenguins2 = penguins.groupby('species')\n\nlist_fitted2 = penguins2.apply(group_ols).to_list()\n\nlist_groups = list(penguins2.groups.keys())\n\npy4st.compare_ols(\n    list_models = list_fitted2,\n    model_name = list_groups\n    )\n\n\n\nterm\nAdelie\nChinstrap\nGentoo\n\n\n\n\nIntercept\n984.4166\n286.2540\n1829.0302 ***\n\n\n\n(601.1999)\n(980.5230)\n(638.6999)\n\n\nsex[T.male]\n476.6000 ***\n102.9407\n536.5500 ***\n\n\n\n(69.9994)\n(119.3246)\n(80.3899)\n\n\nbill_length_mm\n26.8589 **\n18.4218\n33.6324 ***\n\n\n\n(11.4707)\n(16.0333)\n(11.2907)\n\n\nbill_depth_mm\n78.5228 ***\n135.4873 **\n92.5900 **\n\n\n\n(25.1993)\n(51.1571)\n(41.9318)\n\n\nrsquared_adj\n0.5822\n0.3687\n0.6956\n\n\nnobs\n146\n68\n119\n\n\ndf\n3\n3\n3\n\n\n\nplt.rcParams[\"figure.autolayout\"] = True\n\nfig, ax = plt.subplots(1, 3, figsize = (3.2 * 5, 5), dpi = 100)\n\nfor k, mod in enumerate(list_fitted2):\n  py4st.coefplot(mod, ax = ax[k])\n  ax[k].set_xlim(-500, 1000)\n  ax[k].set_title(list_groups[k])\n  ax[k].set_xlabel(f'coefficient (n = {mod.nobs:,.0f})')\n\n\n\nscaling_up_regression2",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>scaling up regression</span>"
    ]
  },
  {
    "objectID": "articles/scaling_up_regression.html#ブートストラップ回帰",
    "href": "articles/scaling_up_regression.html#ブートストラップ回帰",
    "title": "scaling up regression",
    "section": "ブートストラップ回帰",
    "text": "ブートストラップ回帰\n　前節でグループ別の回帰分析を行なった方法を応用すると、ブートストラップ法を簡単に実装することができます。\ndef est_ols(data):\n  fitted = smf.ols(\n      'body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex',\n      data = data).fit()\n  return fitted\n　次にブートストラップ法の実行部分を作成します。ここでは pandas の DataFrame.sample() メソッドを使い、引数に frac = 1, replace = True を指定することで復元抽出を行います。また、ここでは反復回数を Efron, Hastie(2016, p.161)などで推奨されている \\(B = 1000\\) を指定しています。\n# ブートストラップ法の実装\nB = 1000 # ブートストラップ法の反復回数\nmodel_list = [\n    penguins.sample(frac = 1, replace = True, random_state = 123)\\\n    .pipe(est_ols) \n    for b in range(B)\n]\n\nboot_sample = pd.concat([py4st.tidy(mod) for mod in model_list])\n\nlen(boot_sample)\n#&gt; 6000\n次にブートストラップ統計量を集計して結果を確認しますが、ここではごく簡単に py4st.mean_qi() を使って、説明変数別に回帰係数の平均値と分位点を求めています。\nres = boot_sample.groupby(['term'])[['estimate']]\\\n    .apply(py4st.mean_qi)\n\nprint(res.round(4))\n#&gt;                         variable       mean      lower      upper\n#&gt; term                                                             \n#&gt; Intercept            0  estimate   823.7098   823.7098   823.7098\n#&gt; bill_depth_mm        0  estimate   109.9439   109.9439   109.9439\n#&gt; bill_length_mm       0  estimate    17.8235    17.8235    17.8235\n#&gt; sex[T.male]          0  estimate   474.2673   474.2673   474.2673\n#&gt; species[T.Chinstrap] 0  estimate  -191.4717  -191.4717  -191.4717\n#&gt; species[T.Gentoo]    0  estimate  1487.5680  1487.5680  1487.5680\nブートストラップ法を使うと、次のような回帰係数の分布のグラフを描くこともできます。\nimport ptitprince as pt\n\nfig, ax = plt.subplots(figsize = (1.618 * 4, 4), dpi = 100)\n\npt.RainCloud(\n    data = boot_sample.sort_index().reset_index()\\\n      .query('~term.str.contains(\"Intercept\")'),\n    x = 'term',\n    y = 'estimate',\n    orient = 'h',\n    hue = 'term',\n    ax = ax\n);\n\nax.axvline(0, ls = \"--\", color = '#969696');\n\n\n\nscaling_up_regression3\n\n\n\n補足\n\nデータセットが大きい場合、ブートストラップ法の実行には時間がかかるので boot_sample.to_csv('output/boot_sample.csv') を追加して保存しておいた方が、事後的な分析がしやすいと思います。\n今回のような通常の回帰分析であれば、回帰係数の標準誤差は簡単に計算できるためブートストラップ法を使う必要性を感じにくいですが、傾向スコアを用いたIPW推定量など、標準誤差の推定にブートストラップ法が必要になる場合もあります。\n今回は DataFrame.sample() メソッドを使ったごく簡単な方法でブートストラップ法を実装していますが、もう少し効率的な方法もあるのではないかと思います。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>scaling up regression</span>"
    ]
  },
  {
    "objectID": "articles/scaling_up_regression.html#参考文献",
    "href": "articles/scaling_up_regression.html#参考文献",
    "title": "scaling up regression",
    "section": "参考文献",
    "text": "参考文献\n\nEfron, Bradley, and Trevor Hastie. (2016). Computer age statistical inference. Cambridge University Press.\n末石直也(2015)『計量経済学：ミクロデータ分析へのいざない』 日本評論社.",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>scaling up regression</span>"
    ]
  },
  {
    "objectID": "articles/narwhals_in_py4stats.html",
    "href": "articles/narwhals_in_py4stats.html",
    "title": "Technical Notes: py4stats.eda_tools における narwhals ベースの実装",
    "section": "",
    "text": "概要\npy4stats.eda_tools モジュールは、複数の DataFrame バックエンドに対して共通の API を提供することを目的として、narwhals ライブラリを用いて実装されています。\n本ドキュメントでは、本モジュールの内部実装に関する前提条件や、バックエンドの違いに起因する挙動上の注意点について説明します。\n通常の利用にあたって本ドキュメントを読む必要はありませんが、実装の詳細や挙動の違いが気になる場合には参考にしてください。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Technical Notes: py4stats.eda_tools における narwhals ベースの実装</span>"
    ]
  },
  {
    "objectID": "articles/narwhals_in_py4stats.html#対応している-dataframe-バックエンドについて",
    "href": "articles/narwhals_in_py4stats.html#対応している-dataframe-バックエンドについて",
    "title": "Technical Notes: py4stats.eda_tools における narwhals ベースの実装",
    "section": "対応している DataFrame バックエンドについて",
    "text": "対応している DataFrame バックエンドについて\n　py4stats.eda_tools モジュールの関数は、第一引数として narwhals.from_native() によって nw.DataFrame 型へ変換可能な DataFrame オブジェクトを受け取ります。\n具体的には、以下のようなバックエンドを想定しています。\n\npandas.DataFrame（主に動作検証を行っているバックエンド）\npolars.DataFrame（簡易的な動作確認のみ）\npyarrow.Table（簡易的な動作確認のみ）\n\n本ライブラリの動作確認は、基本的に pandas.DataFrame を用いて実施しています。そのため、polars や pyarrow を使用した場合には、バックエンド固有の仕様差や未検証の挙動により、一部の関数でエラーが発生する可能性があります。そのような挙動が確認された場合は、Issue 等での報告を歓迎します。\n　また、バックエンド別の実装状況については eda_tools開発状況 も参照して下さい。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Technical Notes: py4stats.eda_tools における narwhals ベースの実装</span>"
    ]
  },
  {
    "objectID": "articles/narwhals_in_py4stats.html#narwhals-を用いた関数の返り値の型について",
    "href": "articles/narwhals_in_py4stats.html#narwhals-を用いた関数の返り値の型について",
    "title": "Technical Notes: py4stats.eda_tools における narwhals ベースの実装",
    "section": "narwhals を用いた関数の返り値の型について",
    "text": "narwhals を用いた関数の返り値の型について\npy4stats.eda_tools モジュールの関数のうち、py4stats.diagnose() など、第一引数にデータフレームを取る関数の返り値の型は、to_native 引数の値によって変化します。 　初期設定である to_nativ = True の場合には、第一引数に入力されたデータフレームと同じ型のデータフレームが出力され、to_nativ = False の場合には narwhals.DataFrame 型のデータフレームが出力されます。to_nativ = False のオプションは、主にライブラリ内部での利用や、データフレームのバックエンドに依存しない後続処理を行いたい場合を想定したオプションです。\nimport py4stats as py4st\nimport pandas as pd\nimport polars as pl\nimport pyarrow as pa\nimport wooldridge\nmroz_pd = wooldridge.data('mroz')       # pd.DataFrame\nmroz_pl = pl.from_pandas(mroz_pd)       # pl.DataFrame\nmroz_pa = pa.Table.from_pandas(mroz_pd) # pyarrow.lib.Table\n# to_nativ = True の場合(初期設定): 入力されたデータフレームと同じ型\n\nprint(type(py4st.diagnose(mroz_pd, to_native = True)))\n#&gt; &lt;class 'pandas.core.frame.DataFrame'&gt;\n\nprint(type(py4st.diagnose(mroz_pl, to_native = True)))\n#&gt; &lt;class 'polars.dataframe.frame.DataFrame'&gt;\n\nprint(type(py4st.diagnose(mroz_pa, to_native = True)))\n#&gt; &lt;class 'pyarrow.lib.Table'&gt;\n# to_nativ = False の場合: narwhals.DataFrame 型\n\nprint(type(py4st.diagnose(mroz_pd, to_native = False)))\n#&gt; &lt;class 'narwhals.dataframe.DataFrame'&gt;\n\nprint(type(py4st.diagnose(mroz_pl, to_native = False)))\n#&gt; &lt;class 'narwhals.dataframe.DataFrame'&gt;\n\nprint(type(py4st.diagnose(mroz_pa, to_native = False)))\n#&gt; &lt;class 'narwhals.dataframe.DataFrame'&gt;",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Technical Notes: py4stats.eda_tools における narwhals ベースの実装</span>"
    ]
  },
  {
    "objectID": "articles/narwhals_in_py4stats.html#narwhals-を用いた実装方針について",
    "href": "articles/narwhals_in_py4stats.html#narwhals-を用いた実装方針について",
    "title": "Technical Notes: py4stats.eda_tools における narwhals ベースの実装",
    "section": "narwhals を用いた実装方針について",
    "text": "narwhals を用いた実装方針について\n　内部実装では、関数の冒頭で\nnw.from_native(data)\nを用いて入力データを nw.DataFrame に変換し、以降の処理を narwhals の抽象 API 上で行っています。\nこの設計により、DataFrame バックエンドごとの差異を最小限に抑えつつ、将来的な拡張性を確保することを目的としています。\n一方で、narwhals は各バックエンドの完全な互換性を保証するものではないため、特定の操作や型変換についてはバックエンドごとに挙動が異なる場合があります。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Technical Notes: py4stats.eda_tools における narwhals ベースの実装</span>"
    ]
  },
  {
    "objectID": "articles/narwhals_in_py4stats.html#pandas_flavor-を用いた-dataframe-メソッドの登録について",
    "href": "articles/narwhals_in_py4stats.html#pandas_flavor-を用いた-dataframe-メソッドの登録について",
    "title": "Technical Notes: py4stats.eda_tools における narwhals ベースの実装",
    "section": "pandas_flavor を用いた DataFrame メソッドの登録について",
    "text": "pandas_flavor を用いた DataFrame メソッドの登録について\npy4stats.eda_tools の関数のうち、単一の DataFrame オブジェクトを引数として受け取る関数については、pandas_flavor.register_dataframe_method を用いて DataFrame メソッドとして登録されています。その結果、以下のような使い方が可能です。\ndf.diagnose()\nただし、pandas_flavor は pandas の拡張を前提とした仕組みであるため、このメソッド形式の呼び出しは、pandas.DataFrame を対象としています。 　polars.DataFrame や pyarrow ベースのオブジェクトを使用する場合には、関数として直接呼び出す形での利用を推奨します。\nimport py4stats as py4st\n\npy4st.diagnose(df)",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Technical Notes: py4stats.eda_tools における narwhals ベースの実装</span>"
    ]
  },
  {
    "objectID": "articles/narwhals_in_py4stats.html#今後について",
    "href": "articles/narwhals_in_py4stats.html#今後について",
    "title": "Technical Notes: py4stats.eda_tools における narwhals ベースの実装",
    "section": "今後について",
    "text": "今後について\n　py4stats.eda_tools モジュールは、今後も narwhals ベースの実装を主軸として改良・拡張を行っていく予定です。一方で、従来の pandas ベースの実装については、互換性のために当面は保持される予定ですが、機能追加は行わない予定です。バックエンドごとの挙動差や制限事項については、必要に応じて本ドキュメントを更新していきます。",
    "crumbs": [
      "**Articles**",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Technical Notes: py4stats.eda_tools における narwhals ベースの実装</span>"
    ]
  },
  {
    "objectID": "articles/project_guide.html",
    "href": "articles/project_guide.html",
    "title": "Project Guide",
    "section": "",
    "text": "Py4Stats ライブラリのモジュール構成",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Project Guide</span>"
    ]
  },
  {
    "objectID": "articles/project_guide.html#py4stats-ライブラリのモジュール構成",
    "href": "articles/project_guide.html#py4stats-ライブラリのモジュール構成",
    "title": "Project Guide",
    "section": "",
    "text": "py4stats\n├ メインモジュール               # Import py4stats で直接読み込み\n│ ├ eda_tools                   # 探索的データ解析と前処理\n│ │ ├ _.nw                         # narwhals ベースの現行実装\n│ │ └ _.pandas                     # Pandas ベースの旧実装（廃止予定）\n│ └ regression_tools            # 回帰分析の可視化と表作成\n└ サブモジュール                 # Import py4stats では読み込まれない\n　 ├ heckit_helper               #regression_tools の追加メソッド\n　 └ building_block              # 内部実装用のアサーション関数とユーティリティ関数を提供",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Project Guide</span>"
    ]
  },
  {
    "objectID": "articles/project_guide.html#py4stats-ライブラリのインポート",
    "href": "articles/project_guide.html#py4stats-ライブラリのインポート",
    "title": "Project Guide",
    "section": "Py4Stats ライブラリのインポート",
    "text": "Py4Stats ライブラリのインポート\n# ライブラリの読み込み（推奨）\nimport py4stats as py4st\n\n# サブモジュールの読み込み\nfrom py4stats import heckit_helper\nfrom py4stats import building_block as build \n\n# eda_tools のバックエンド別実装の明示的な読み込み\nfrom py4stats.eda_tools import _nw as eda_nw\nfrom py4stats.eda_tools import _pandas as eda_pd",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Project Guide</span>"
    ]
  },
  {
    "objectID": "articles/project_guide.html#リポジトリのディレクトリ構成",
    "href": "articles/project_guide.html#リポジトリのディレクトリ構成",
    "title": "Project Guide",
    "section": "リポジトリのディレクトリ構成",
    "text": "リポジトリのディレクトリ構成\n2026年1月24日 現在\nPy4Stats \n├── README.md                           # GitHub リポジトリのトップページ用ファイル\n├── index.qmd                           # APIドキュメント(Quarto Book)のトップページ\n├── _quarto.yml                         # Quarto Book の設定ファイル\n├── introduction.qmd\n├── articles                            # APIドキュメント以外の公開記事\n├── man                                 # APIドキュメントのうち、関数のドキュメント\n│   ├── diagnose.qmd\n│   ├── compare_ols.qmd\n│   ...\n│   └── image                           # ドキュメントに使用する画像\n├── py4stats\n│   ├── __init__.py                     # Py4Stats の Import 時に読み込まれる関数を定義\n│   ├── building_block.py               # 引数のアサーションなどユーティリティモジュール\n│   ├── eda_tools                       # 探索的データ解析\n│   │   ├── __init__.py\n│   │   ├── _nw.py                      # バックエンドに narwhals を使用した実装\n│   │   └── _pandas.py                  # バックエンドに pandas を使用した旧仕様\n│   ├── heckit_helper.py\n│   └── regression_tools.py             # 回帰分析の可視化と作表\n├── pyproject.toml\n├── reference.md                        # man/ の関数ドキュメントへのリンク集\n├── setup.ipynb\n├── setup.py\n└── tests                              # APIのテストコード\n    ├── fixtures                       # 自動テストで参照するデータ\n    ├── test_building_block.py\n    ├── test_eda_tools_nw.py\n    ├── test_eda_tools_pandas.py\n    ├── test_heckit_helper.py\n    └── test_regression_tools.py\n注意：eda_tools._pandas.py は 非推奨扱いで将来的に廃止する予定です。詳細は以下を参照してください。\n\nTechnical Notes\neda_tools開発状況",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Project Guide</span>"
    ]
  },
  {
    "objectID": "articles/project_guide.html#リポジトリの運用方針",
    "href": "articles/project_guide.html#リポジトリの運用方針",
    "title": "Project Guide",
    "section": "リポジトリの運用方針",
    "text": "リポジトリの運用方針\n\n\n\nPy4Statsリポジトリの運用方針",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Project Guide</span>"
    ]
  },
  {
    "objectID": "articles/project_guide.html#セマンティック-バージョニングについてのメモ",
    "href": "articles/project_guide.html#セマンティック-バージョニングについてのメモ",
    "title": "Project Guide",
    "section": "セマンティック バージョニングについてのメモ",
    "text": "セマンティック バージョニングについてのメモ\nPy4Stats ライブラリのバージョンは次の方式のセマンティック バージョニングで管理します(e.g. v 0.1.0)。\nv MAJOR.MINOR.PATCH\nv MAJOR.MINOR.PATCH の各要素は、次の規則で更新します。\n\nMAJOR APIの変更に互換性のない場合はメジャーバージョンを上げる\nMINOR 後方互換性があり機能性を追加した場合はマイナーバージョンを上げる\nPATCH 後方互換性を伴うバグ修正をした場合はパッチバージョンを上げる",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Project Guide</span>"
    ]
  },
  {
    "objectID": "articles/project_guide.html#デザインパターン",
    "href": "articles/project_guide.html#デザインパターン",
    "title": "Project Guide",
    "section": "デザインパターン",
    "text": "デザインパターン\n\n引数のアサーション\nfrom py4stats import building_block as build \n# 文字列引数のアサーション（選択肢を制限）\narg = build.arg_match(\n    arg, values = ['option_1', 'option_2'], \n    arg_name = 'arg', \n    )\nbuild.assert_logical(arg, arg_name = 'arg')   # ブール値\nbuild.assert_character(arg, arg_name = 'arg') # 文字列\nbuild.assert_numeric(arg, arg_name = 'arg')   # 数値(int or float)\nbuild.assert_integer(arg, arg_name = 'arg')   # 整数値(int)\nbuild.assert_count(arg, arg_name = 'arg')     # 非負整数値(int)\nbuild.assert_float(arg, arg_name = 'arg')     # フロート値(float)\n\n\nnarwhals が受け入れ可能な互換オブジェクトに singledispatch する方法\n\n結論\n\nDataFrame の場合 @foo.register(nw.typing.IntoDataFrame) を使う\nSeries の場合 @foo.register(nw.typing.IntoSeries) を使う\n\n\n\n詳細\nfunctools.singledispatch を使って総称関数を定義する場合、@singledispatch デコレータで総称関数を定義したあと、@foo.register(Class) デコレータでクラス毎のメソッド関数を定義します。\nnarwhals が受け入れ可能な DataFrame 互換オブジェクトに対するメソッドを定義する場合には、nw.typing.IntoDataFrame を使い、Series 互換オブジェクトに対するメソッドを定義する場合には nw.typing.IntoSeries を使います。\n# 実装例\nimport narwhals as nw\nfrom functools import singledispatch\n\n@singledispatch\ndef foo(x):\n    return 'I am some object'\n\n@foo.register(nw.typing.IntoDataFrame)\ndef foo_df(x):\n    return  'I am a DataFrame'\n\n@foo.register(nw.typing.IntoSeries)\ndef foo_s(x):\n    return 'I am a Series'\n# 動作例\nimport pandas as pd\nimport polars as pl\nimport pyarrow as pa\n\ndata_pd = pd.DataFrame({'x':[1, 2, 3], 'y':['a', 'b', 'c']})\ndata_pl = pl.from_pandas(data_pd)\ndata_pa = pa.Table.from_pandas(data_pd)\ndata_nw = nw.from_native(data_pd)\n\ndata_dict = {\n    'df_pd' :data_pd, 'df_pl' :data_pl, 'df_pa' :data_pa, 'df_nw' :data_nw,\n    's_pd' :data_pd['x'], 's_pl' :data_pl['x'], 's_pa' :data_pa['x'], 's_nw':data_nw['x'],\n    'int': 1 \n}\n\n[f\"{k}: {foo(x)}\" for k, x in zip(data_dict.keys(), data_dict.values())]\n#&gt; [\"df_pd: 'I am a DataFrame'\",\n#&gt;  \"df_pl: 'I am a DataFrame'\",\n#&gt;  \"df_pa: 'I am a DataFrame'\",\n#&gt;  \"df_nw: 'I am a DataFrame'\",\n#&gt;  \"s_pd: 'I am a Series'\",\n#&gt;  \"s_pl: 'I am a Series'\",\n#&gt;  \"s_pa: 'I am a Series'\",\n#&gt;  \"s_nw: 'I am a Series'\",\n#&gt;  \"int: 'I am some object'\"]",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Project Guide</span>"
    ]
  },
  {
    "objectID": "articles/project_guide.html#総称関数の実装に関する覚書",
    "href": "articles/project_guide.html#総称関数の実装に関する覚書",
    "title": "Project Guide",
    "section": "総称関数の実装に関する覚書",
    "text": "総称関数の実装に関する覚書\n\n総称関数に登録されたメソッドの確認\n\n結論\n\nある関数に登録されたメソッド全体を確認するには foo.registry を使い\nある関数に登録された特定のクラスのメソッドを確認するには foo.dispatch(Class) を使います\n\n\n\n詳細\nある総称関数に、どのようなメソッドが登録されているかは、.registry 属性で確認することができます。.registry は {型: 実装関数} の辞書であり、object クラスはデフォルト実装に対応しています。\nimport py4stats as py4st\nimport pandas as pd\n\nregistry = py4st.is_dummy.registry\nprint(pd.Series(registry).apply(lambda x: x.__name__))\n#&gt; &lt;class 'object'&gt;                                         is_dummy\n#&gt; &lt;class 'narwhals._native.NativeSeries'&gt;           is_dummy_series\n#&gt; &lt;class 'narwhals.series.Series'&gt;                  is_dummy_series\n#&gt; &lt;class 'narwhals._native.NativeDataFrame'&gt;    is_dummy_data_frame\n#&gt; &lt;class 'narwhals.dataframe.DataFrame'&gt;        is_dummy_data_frame\n#&gt; &lt;class 'tuple'&gt;                                     is_dummy_list\n#&gt; &lt;class 'list'&gt;                                      is_dummy_list\n#&gt; dtype: object\nまた、.dispatch(Class) メソッドで特定のオブジェクトクラスに対して実装されたメソッド関数を確認することができます。\nprint(py4st.is_dummy.dispatch(pd.DataFrame).__name__)\n#&gt; is_dummy_data_frame\n\nprint(py4st.is_dummy.dispatch(pd.Series).__name__)\n#&gt; is_dummy_series\n\nprint(py4st.is_dummy.dispatch(list).__name__)\n#&gt; is_dummy_list\n\nprint(py4st.is_dummy.dispatch(int).__name__) # デフォルト実装\n#&gt; is_dummy",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Project Guide</span>"
    ]
  },
  {
    "objectID": "articles/eda_tools_development_status.html",
    "href": "articles/eda_tools_development_status.html",
    "title": "eda_toolsの開発状況",
    "section": "",
    "text": "関数の実装状況一覧\n2026年1月24日",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>eda_toolsの開発状況</span>"
    ]
  },
  {
    "objectID": "articles/eda_tools_development_status.html#関数の実装状況一覧",
    "href": "articles/eda_tools_development_status.html#関数の実装状況一覧",
    "title": "eda_toolsの開発状況",
    "section": "",
    "text": "関数の実装状況一覧\n\n\n\n\n\n\n\n\n\n\nfunctions\nInput\nPandas\nPolars\nPyarrow\n補足\n\n\n\n\nMean\npd.Series\n✅\n❌\n❌\npd.DataFrame.eval() での使用を想定した関数\n\n\nMedian\npd.Series\n✅\n❌\n❌\npd.DataFrame.eval() での使用を想定した関数\n\n\nMax\npd.Series\n✅\n❌\n❌\npd.DataFrame.eval() での使用を想定した関数\n\n\nMin\npd.Series\n✅\n❌\n❌\npd.DataFrame.eval() での使用を想定した関数\n\n\nPareto_plot\nDataFrame\n✅\n✅\n✅\n\n\n\nSum\npd.Series\n✅\n❌\n❌\npd.DataFrame.eval() での使用を想定した関数\n\n\ncheck_that\nDataFrame\n✅\n⭕️\n⭕️\n実装に pd.DataFrame.eval() を使用\n\n\ncheck_viorate\nDataFrame\n✅\n⭕️\n⭕️\n実装に pd.DataFrame.eval() を使用\n\n\ncompare_df_cols\nDataFrame\n✅\n✅\n✅\n\n\n\ncompare_df_record\nDataFrame\n✅\n✅\n✅\n\n\n\ncompare_df_stats\nDataFrame\n✅\n✅\n✅\n\n\n\ncompare_group_means\nDataFrame\n✅\n✅\n✅\n\n\n\ncompare_group_median\nDataFrame\n✅\n✅\n✅\n\n\n\ncrosstab\nDataFrame\n✅\n✅\n⭕️\nPyarrow は Polars 依存の実装\n\n\ndiagnose\nDataFrame\n✅\n✅\n✅\n\n\n\ndiagnose_category\nDataFrame\n✅\n✅\n✅\n\n\n\nfiltering_out\nDataFrame\n✅\n✅\n✅\n\n\n\nfreq_table\nDataFrame\n✅\n✅\n✅\n\n\n\nimplies_exper\npd.Series\n✅\n❌\n❌\npd.DataFrame.eval() での使用を想定した関数\n\n\nis_dummy\nDataFrame/Series\n✅\n✅\n✅\n\n\n\nis_number\nSeries\n✅\n✅\n✅\n\n\n\nis_ymd_like\nSeries\n✅\n✅\n✅\n\n\n\nis_ymd\nSeries\n✅\n✅\n✅\n\n\n\nmean_ci\nDataFrame/Series\n✅\n✅\n✅\n\n\n\nmean_qi\nDataFrame/Series\n✅\n✅\n✅\n\n\n\nmedian_qi\nDataFrame/Series\n✅\n✅\n✅\n\n\n\nmin_max\nSeries\n✅\n✅\n✅\n\n\n\nplot_mean_diff\nDataFrame\n✅\n✅\n✅\n\n\n\nplot_median_diff\nDataFrame\n✅\n✅\n✅\n\n\n\nplot_miss_var\nDataFrame\n✅\n✅\n✅\n\n\n\nscale\nSeries\n✅\n✅\n✅\n\n\n\nset_miss\nSeries\n✅\n✅\n✅\n\n\n\nrelocate\nDataFrame\n✅\n✅\n✅\n\n\n\nremove_constant\nDataFrame\n✅\n✅\n✅\n\n\n\nremove_empty\nDataFrame\n✅\n✅\n✅\n\n\n\ntabyl\nDataFrame\n✅\n⭕️\n⭕️\n一部の処理が Pandas 依存\n\n\nweighted_mean\nSeries\n✅\n✅\n✅",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>eda_toolsの開発状況</span>"
    ]
  },
  {
    "objectID": "articles/eda_tools_development_status.html#凡例",
    "href": "articles/eda_tools_development_status.html#凡例",
    "title": "eda_toolsの開発状況",
    "section": "凡例",
    "text": "凡例\n\n✅ 実装済/テスト済\n⭕️ 実装済/テスト済（異なるバックエンドに依存）\n🔼 実装済/テスト未\n❌ 未実装",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>eda_toolsの開発状況</span>"
    ]
  },
  {
    "objectID": "articles/narwhalsについての考察.html",
    "href": "articles/narwhalsについての考察.html",
    "title": "narwhals についての考察",
    "section": "",
    "text": "narwhals での再現が難しい Pandas の機能",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>narwhals についての考察</span>"
    ]
  },
  {
    "objectID": "articles/narwhalsについての考察.html#narwhals-での再現が難しい-pandas-の機能",
    "href": "articles/narwhalsについての考察.html#narwhals-での再現が難しい-pandas-の機能",
    "title": "narwhals についての考察",
    "section": "",
    "text": "異なるデータフレーム間の二項演算\nPandas の場合、2つのデータフレーム df1 と df2 が共通の columns と index をもつ限り、df3 = df1 + df2 によって二項演算を行うことができ、このとき、columns と index をもつ要素同士が加算されます。しかし、narwhals には Pandas のような index が存在しないため、この計算は再現が困難です。\n\n\nデータフレームへの値の代入\nPandas の場合、df.loc[i, j] = x という形でデータフレーム df の i, j 要素に値 x を代入することができますが、narwhals ではこれに相当する演算 df[i, j] = x は禁止されています。\n異なるデータフレーム間の二項演算に制約があること、そしてデータフレームへの値の代入が難しいことから、tabyl() 関数では、集計後の作表処理の一部を Pandas に依存しています。\n\n\n任意の関数でグループ別集計を行う\n自作関数を使ってグループ別集計を行いたい場合、Pandas であれば df.groupby(group)[x].agg(my_func) で行うことができます。同じく narwhals でも\ndata_nw.group_by(nw.col(group)).agg(nw.col('x').mean())\nという形でグループ別の集計がサポートされているものの、ここで使用できる集計関数は narwhals で実装されているものに限定されるようで、次のような方法で自作関数を使用することはできません。\ndata_nw.group_by(nw.col(group)).agg(nw.col('x').my_func())\ndata_nw.group_by(nw.col(group)).agg(my_func(nw.col('x')))\n例えば Py4Stats では、Pareto_plot() 関数の内部実装に使用している make_rank_table() 関数において、任意の関数をグループ別集計に使うために、サブセッティングを使って group_by() メソッドの使用を回避するという変則的（かつ、おそらく非効率 ）な実装を行なっています。\nstat_values = [\n            aggfunc(\n                data_nw.filter(nw.col(group) == g)[values]\n                .drop_nulls().to_native()\n                ) \n            for g in group_value\n            ]\nまた、上記の回避策のもう1つの問題として、data_nw.filter(nw.col(group) == g) では、複数の変数に基づくグループ化に対応できないことも挙げられます。make_rank_table() 関数については、Pareto_plot() 関数でパレート図を作図するときに横軸になる group が多変数だと対応できないので、group が1変数（= 引数として1つの文字列だけを受け付ける）とすることで妥協しています。\nただ、現時点で narwhals.GroupBy クラスに実装されているメソッドは .agg() しかなく、開発が進めばより柔軟な関数適用が可能になるのではないかと期待しています。",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>narwhals についての考察</span>"
    ]
  },
  {
    "objectID": "articles/narwhalsについての考察.html#narwhals-におけるバックエンドとその書き換え",
    "href": "articles/narwhalsについての考察.html#narwhals-におけるバックエンドとその書き換え",
    "title": "narwhals についての考察",
    "section": "narwhals におけるバックエンドとその書き換え",
    "text": "narwhals におけるバックエンドとその書き換え\n\nバックエンドの基本的な理解\nnarwhals におけるバックエンドによる型変換の基本的な理解として（不正確かもしれませんが）、nw.from_native(data) の実行時に data の型に応じて backend が記録され、.to_native() メソッドを呼び出すと、記録された backend に応じて元の型に変換されます。\nbackend の情報は .select() .filter() などのメソッドを使って data_nw を加工しても保持され、これによって入力された input_pd と同じ型のデータフレームを返すことが可能になっています。\ndata_nw = nw.from_native(input_pd) # ここで backend が記録される\ndata_nw.implementation       # -&gt; Pandas\nresult = data_nw.to_native() # -&gt; pd.DataFrame が出力される\n一方で、処理の途中で pd.DataFrame や pl.DataFrame などの native オブジェクトを経由した場合、改めて nw.from_native() を使って nw.DataFrame に変換し直したとしても、その時点で backend が上書きされるので、.to_native() メソッドを使用しても引数として入力された input_pd と同じ型に復元される保証はありません。\ndata_nw = nw.from_native(input_pd)              # ここで backend が記録される\ndata_nw2 = nw.from_native(data_nw.to_polars())  # ここで backend が上書きされる\ndata_nw2.implementation                         # -&gt; polars\nresult = data_nw2.to_native()                   # -&gt; pl.DataFrame が出力される\n従って、result が input_pd と同じ型をもつことを保証するには、data_nw を nw.DataFrame クラスのまま維持する（≒ narwhals ベースのメソッドだけで処理を書く）必要があり、これが narwhals ベースの実装としてのあるべき姿だと思われます。\n一方で、一部の処理が特定のバックエンド（e.g. Pandas）に依存している場合にはどうするべきでしょうか。これには次のような2つの選択肢があると考えています。\n\n処理が依存しているバックエンドのオブジェクト（e.g. pd.DataFrame）として出力する〔推奨〕\nnarwhals の仕様を迂回してバックエンドを書き換える〔非推奨ですが次節で考察〕\n\nこれら2つの可能性の間での選択は、技術的な問題であると同時にユーザーとのコミュニケーションの問題です。入力と同型のデータフレームを返す関数の中に pd.DataFrame を返す関数が混ざっていることをユーザーにどう説明するのか。あるいは、narwhals の仕様を迂回をしたことで非効率性やカラムレベルでデータ型（dtype）の一貫性が失われる問題が生じたとして、それをユーザーにどう説明するのか、という問いです。\n\n\nバックエンドの書き換え (非推奨)\nいま、some_computation() として実装された処理の一部が Pandas に依存しており、結果が result_pd という pd.DataFrame 型のオブジェクトとして得られているとします。このとき、result_pd をもとのデータフレーム data_pl と同型にする方法の1つとして、result_pd を pd.Series.to_dict() などを使って辞書のリスト（list of dict）に変換したのち、nw.from_dicts() を使って data_pl と同じバックエンドをもつ nw.DataFrame に変換するという方法があります。\n以上の変換の実例を見てみましょう。まずは、data_pl\ndata_pl = pl.from_pandas(load_penguins())[:10, :2]\n\ndata_pl = data_pl.with_columns(\n        pl.all().cast(pl.Categorical)\n    )\nprint(type(data_pl))\n#&gt; &lt;class 'polars.dataframe.frame.DataFrame'&gt;\nprint(data_pl.schema)\n#&gt; Schema({'species': Categorical, 'island': Categorical})\n\ndata_nw_pl = nw.from_native(data_pl) # ここでバックエンドを記録、後ほど復元に使います。\n\n# 何かしらの処理の結果 pd.DataFrame に変換されたとする\nresult_pd = data_nw_pl.to_pandas()\nprint(type(result_pd))\n#&gt; &lt;class 'pandas.core.frame.DataFrame'&gt;\n次に、pl.DataFrame 型をもつ result_pd を pl.DataFrame に変換します。\nここでポイントとなるのが、nw.from_dicts() 関数の引数の (1)schema 引数と、(2)backend引数に、それぞれ data_nw_pl から取得した値を入力することで、result_pl の列が data_pl と同じく Categorical 型になるようにしています(指定しないと String 型として解釈されてしまいます)。\n# Pandas -&gt; polars の変換\ndict_list = [result_pd.loc[i, :].to_dict() for i in result_pd.index]\n\nresult_nw_pl = nw.from_dicts(\n    dict_list, \n    schema = data_nw_pl.schema,         # (1)\n    backend = data_nw_pl.implementation # (2)\n    )\nresult_pl = result_nw_pl.to_native()\n\nprint(type(result_pl))\n#&gt; &lt;class 'polars.dataframe.frame.DataFrame'&gt;\n\nprint(result_pl.schema)\n#&gt; Schema({'species': Categorical, 'island': Categorical})\nまた、Series については、nw.Series.from_iterable() 関数を使うことで、次のようにバックエンドを書き換えることができます。\nx_pl = data_pl['island']\nprint(type(x_pl))\n#&gt; &lt;class 'polars.series.series.Series'&gt;\nprint(x_pl.dtype)\n#&gt; Categorical\n\nx_nw = nw.from_native(x_pl, allow_series = True)\nx_pd = x_nw.to_pandas()\nprint(type(x_pd))\n#&gt; &lt;class 'pandas.core.series.Series'&gt;\nx_pl2 = nw.Series.from_iterable(\n    name = x_pd.name,\n    values = x_pd.to_list(),\n    backend = x_nw.implementation,\n    dtype = x_nw.dtype\n).to_native()\n\nprint(type(x_pl2))\n#&gt; &lt;class 'polars.series.series.Series'&gt;\nprint(x_pl2.dtype)\n#&gt; Categorical\nnarwhals の仕様を迂回してバックエンドを書き換えることは可能ですが、この方法には次のような問題があります。 ただし、以上のような方法でバックエンドの書き換えは可能ですが、\n\n小さいデータフレームでない限り時間がかかる\n\n恐らく、dict_list を作成するための for ループによるもの\n\n上記の (1) に代入する正しい schema が用意できないと、カラムレベルでデータ型の一貫性保証できない。\n\n特に2番目の問題点については、集計処理によって列名が変わった場合には正しい schema(≒ {列名:dtype} の辞書オブジェクト)を用意することが難しくなります。そして、schema を指定できないと、pd.Categorical、pl.Categorical あるいは pl.Enum といったカテゴリー変数は文字列型に変換されてしまい、データ型の一貫性が失われます。\nカラムレベルで型の一貫性が失われると、返り値が入力値とは異なる型になるよりも把握しづらく、また挙動の予測が難しいため、上記のような処理は採用するとしても、他に方法がないときの最終手段として扱うべきでしょう。",
    "crumbs": [
      "**Contributing Notes**",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>narwhals についての考察</span>"
    ]
  }
]