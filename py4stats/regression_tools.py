# -*- coding: utf-8 -*-
"""regression_tools.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1toh4Gqspni3ApwQUZgfOXg2wjHK8sI1l

# `reg_tools`：回帰分析の結果を要約する関数群
"""

# 依存するライブラリーの読込
import pandas as pd
import numpy as np
import scipy as sp
from scipy.stats import t
from scipy.stats import f
from functools import singledispatch
import matplotlib.pyplot as plt

import seaborn as sns
import matplotlib.pyplot as plt

import statsmodels.api as sm
import statsmodels.formula.api as smf

import sys

from py4stats import bilding_block as bild # py4stats のプログラミングを補助する関数群

"""## 回帰分析の結果をデータフレームに変換する関数"""

from statsmodels.iolib.summary import summary_params_frame
from scipy.stats import t

# definition of tidy --------------------------------------------------
def tidy(
  x,
  name_of_term = None,
  conf_level = 0.95,
  add_one_sided = False,
  to_jp = False,
  ):
  tidied = summary_params_frame(x, alpha = 1 - conf_level, xname = name_of_term)

  tidied.index.name = 'term'

  rename_cols = {
      'std err':'std_err',
      't':'statistics', 'P>|t|': 'p_value',
      'Conf. Int. Low': 'conf_lower',
      'Conf. Int. Upp.': 'conf_higher'
  }

  tidied = tidied.rename(columns = rename_cols)

  if add_one_sided:
      tidied = add_one_sided_p_value(x, tidied)

  # 列名を日本語に変換
  if to_jp:
      tidied = tidy_to_jp(tidied, conf_level = 0.95)

  return tidied


def tidy_to_jp(tidied, conf_level = 0.95):
  tidied = tidied\
      .rename(columns = {
          'term':'説明変数',
          'coef':'回帰係数', 'std_err':'標準誤差',
          'statistics':'t-値', 'p_value':'p-値',
          'conf_lower': str(int(conf_level*100)) + '%信頼区間下側',
          'conf_higher': str(int(conf_level*100)) + '%信頼区間上側',
          'one_sided_p_value':'片側p-値'
          })

  tidied.index.name = '説明変数'

  return tidied

def add_one_sided_p_value(x, tidied):
      tidied['one_sided_p_value'] = t.sf(abs(tidied['statistics']), x.df_resid)
      return tidied

# # `tidy_heckit()` の旧バージョン-------------------------
# def tidy_heckit(fit, name_of_term = [], alpha = 0.05, to_jp = False, add_one_sided = False):
#     tidied = pd.DataFrame({
#         'coef':fit.params,
#         'std_err':fit.bse,
#         'statistics':fit.tvalues,
#         'p_value':fit.pvalues,
#         'conf_lower':fit.conf_int(alpha = alpha)[:, 0],
#         'conf_higher':fit.conf_int(alpha = alpha)[:, 1]
#         }
#     )

#     if add_one_sided:
#         tidied = add_one_sided_p_value(fit, tidied)

#     if(len(name_of_term) > 0):
#         tidied['term'] = name_of_term
#         tidied = tidied.set_index('term')

#     # 列名を日本語に変換
#     if to_jp:
#         tidied = tidy_to_jp(tidied, alpha = alpha)

#     return  tidied

def glance(fit_lm):
    res = pd.DataFrame({
        'rsquared':fit_lm.rsquared,
        'rsquared_adj':fit_lm.rsquared_adj,
        'nobs':int(fit_lm.nobs),
        'df':int(fit_lm.df_model),
        'sigma':np.sqrt(fit_lm.mse_resid),
        'F_values':fit_lm.fvalue,
        'p_values':fit_lm.f_pvalue,
        'AIC':fit_lm.aic,
        'BIC':fit_lm.bic
    }, index = [0])
    return res

def glance_jp(fit_lm):
    res = pd.DataFrame({
        'サンプルサイズ':int(fit_lm.nobs),
        'モデルの自由度':int(fit_lm.df_model),
        '自由度調整済み決定係数':fit_lm.rsquared_adj,
        'モデルMSE':fit_lm.mse_model,
        '残差MSE':fit_lm.mse_resid,
        'F値':fit_lm.fvalue,
        'F検定のp-値':fit_lm.f_pvalue
    }, index = [0])
    return res

def log_to_pct(est): return 100 * (np.exp(est) - 1)

# 有意性を表すアスタリスクを作成する関数
def p_stars_row(p_value):
    stars = np.where(p_value <= 0.1, ' *', '')
    stars = np.where(p_value <= 0.05, ' **', stars)
    stars = np.where(p_value <= 0.01, ' ***', stars)
    return stars

p_stars = np.vectorize(p_stars_row)

def pad_zero_row(x, digits = 2):
    s = str(x)
    # もし s が整数値なら、何もしない。
    if s.find('.') != -1:
        s_digits = len(s[s.find('.'):])       # 小数点以下の桁数を計算
        s = s + '0' * (digits + 1 - s_digits) # 足りない分だけ0を追加
    return s

pad_zero = np.vectorize(pad_zero_row, excluded = 'digits')

"""## `reg.compare_ols()`

### 概要

　`reg.compare_ols()` は計量経済学の実証論文でよく用いられる、回帰分析の結果を縦方向に並べて比較する表をする関数です。
　使用方法は次の通りで、`sm.ols()` や `smf.ols()` で作成した分析結果のオブジェクトのリストを代入します。  

```python
penguins = load_penguins() # サンプルデータの読み込み

fit1 = smf.ols('body_mass_g ~ bill_length_mm + species', data = penguins).fit()
fit2 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species', data = penguins).fit()
fit3 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex', data = penguins).fit()

compare_tab1 = reg.compare_ols([fit1, fit2, fit3])
compare_tab1
```
"""

# 複数のモデルを比較する表を作成する関数
def compare_ols(
    list_models,
    model_name = None,
    subset = None,
    stats = 'std_err',
    add_stars = True,
    stats_glance = ['rsquared_adj', 'nobs', 'df'],
    digits = 4,
    table_style = 'two_line',
    line_break = '\n',
    **kwargs
    ):
    assert isinstance(list_models, list), 'list_models is must be a list of models.'

    tidy_list = [tidy(mod) for mod in list_models]

    # モデル名が指定されていない場合、連番を作成する
    if model_name is None:
        model_name = [f'model {i + 1}' for i in range(len(tidy_list))]

    # lineup_models() を適用してモデルを比較する表を作成
    res = lineup_models(
            tidy_list, model_name = model_name,
            digits = digits, stats = stats,
            add_stars = add_stars, table_style = table_style,
            line_break = line_break,
            **kwargs
        )

    # 表の下部にモデルの当てはまりに関する統計値を追加
    if len(stats_glance) > 0: # もし stats_glance が空のリストなら統計値を追加しない
    # 引数に妥当な値が指定されているかを検証
        choices = ['rsquared', 'rsquared_adj', 'nobs', 'df', 'sigma', 'F_values', 'p_values', 'AIC', 'BIC']
        stats_glance = [bild.arg_match(stats, choices, arg_name = 'stats_glance') for stats in stats_glance]

        res2 = pd.concat([glance(mod) for mod in list_models])\
            .loc[:, stats_glance].round(digits)\
            .apply(bild.pad_zero, digits = digits).T

        res2.columns = model_name
        res = pd.concat([res, res2])

    res.index.name = 'term'

    return res

# 複数のモデルを比較する表を作成する関数 対象を sm.ols() に限定しないバージョン
def lineup_models(tidy_list, model_name = None, subset = None, **kwargs):

    # モデル名が指定されていない場合、連番を作成する
    if model_name is None:
        model_name = [f'model {i + 1}' for i in range(len(tidy_list))]

    # tidy_list の各要素に gazer() 関数を適用
    list_gazer = [gazer(df, **kwargs) for df in tidy_list]

    # model_name が列名になるように、辞書の key に設定してから pd.concat() で結合
    res = pd.concat(dict(zip(model_name, list_gazer)), axis = 'columns')\
        .droplevel(1, axis = 'columns') # 列名が2重に設定されるので、これを削除して1つにします。

    # subset が指定された場合は該当する変数を抽出します。
    if subset is not None:
        res = res.loc[subset, :]

    # モデルで使用されていない変数について NaN が発生するので、空白で置き換えます。
    res = res.fillna('')

    return res

# 回帰係数と検定統計量を縦に並べる関数
# 2024年1月30日変更 引数 stats と table_style について
# 妥当な値が指定されているかを検証する機能を追加しました。
def gazer(
    res_tidy, estimate = 'coef', stats = 'std_err',
    digits = 4, add_stars = True, style_p = False, p_min = 0.01,
    table_style = 'two_line', line_break = '\n'
    ):

    # 引数に妥当な値が指定されているかを検証
    stats = bild.arg_match(
        stats, ['std_err', 'statistics', 'p_value'],
        arg_name = 'stats'
        )
    # こちらは部分一致可としています。
    table_style = bild.match_arg(
        table_style, ['two_line', 'one_line'],
        arg_name = 'table_style'
        )

    # --------------------
    res = res_tidy.copy()

    res['stars'] = p_stars(res['p_value'])

    res[[estimate, stats]] = res[[estimate, stats]].round(digits).astype(str)\
        .apply(bild.pad_zero, digits = digits)

    if (stats == 'p_value') & style_p:
        res['p_val'] = res['p_value']

        res['p_value'] = np.where(
            res['p_val'] < p_min,
            f'p < {p_min}',
            res['p_value']
            )
    # # table_style に応じて改行とアスタリスクを追加する
    if(table_style == 'two_line'):
        sep = line_break
        if add_stars:
            sep = res['stars'] + sep
        sufix = ''

    elif(table_style == 'one_line'):
        sep = ''
        if add_stars:
            sufix = res['stars']
        else:
            sufix = ''

    res['value'] = res[estimate] + sep + '(' + res[stats] + ')' + sufix

    # モデルで使用されていない変数について NaN が発生するので、空白で置き換えます。
    res = res.fillna('')

    return res[['value']]

"""### `gazer()` 関数の多項ロジットモデルバージョン

## 回帰係数の視覚化関数
"""

# 利用するライブラリー
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import japanize_matplotlib #日本語化matplotlib
from statsmodels.iolib.summary import summary_params_frame

# 回帰分析の結果から回帰係数のグラフを作成する関数 --------
def coefplot(
    mod,
    subset = None,
    conf_level = [0.95, 0.99],
    palette = ['#1b69af', '#629CE7'],
    show_Intercept = False,
    show_vline = True,
    ax = None,
    **kwargs
    ):
    '''model object から回帰係数のグラフを作成する関数'''

    # 回帰係数の表を抽出
    tidy_ci_high = tidy(mod, conf_level = conf_level[0])
    tidy_ci_row = tidy(mod, conf_level = conf_level[1])

    # subset が指定されていれば、回帰係数の部分集合を抽出する
    if subset is not None:
        tidy_ci_high = tidy_ci_high.loc[subset, :]
        tidy_ci_row = tidy_ci_row.loc[subset, :]

    # グラフの作成
    coef_dot(
        tidy_ci_high, tidy_ci_row, palette = palette,
        show_Intercept = show_Intercept, show_vline = show_vline,
        ax = ax, **kwargs
        )


def coef_dot(
    tidy_ci_high, tidy_ci_low,
    ax = None,
    show_Intercept = False,
    show_vline = True,
    palette = ['#1b69af', '#629CE7'],
    estimate = 'coef', conf_lower = 'conf_lower', conf_higher = 'conf_higher',
    ):
    '''tidy_talbe から回帰係数のグラフを作成する関数'''
    tidy_ci_high = tidy_ci_high.copy()
    tidy_ci_low = tidy_ci_low.copy()

    # 切片項を除外する
    if not show_Intercept:
        tidy_ci_high = tidy_ci_high.loc[~ tidy_ci_high.index.isin(['Intercept']), :]
        tidy_ci_low = tidy_ci_low.loc[~ tidy_ci_low.index.isin(['Intercept']), :]


    if ax is None:
        fig, ax = plt.subplots()

    # 図の描画 -----------------------------
    # 垂直線の描画
    if show_vline:
        ax.axvline(0, ls = "--", color = '#969696')

    # エラーバーの作図
    ax.hlines(
        y = tidy_ci_low.index, xmin = tidy_ci_low[conf_lower], xmax = tidy_ci_low[conf_higher],
        linewidth = 1.5,
        color = palette[1]
    )
    ax.hlines(
        y = tidy_ci_high.index, xmin = tidy_ci_high[conf_lower], xmax = tidy_ci_high[conf_higher],
        linewidth = 3,
        color = palette[0]
    )

    # 回帰係数の推定値を表す点の作図
    ax.scatter(
      x = tidy_ci_high[estimate],
      y = tidy_ci_high.index,
      c = palette [0],
      s = 60
    )
    ax.set_ylabel('');

def gazer_MNlogit(MNlogit_margeff, endog_categories = None, **kwargs):

    if ~pd.Series(MNlogit_margeff.columns).isin(['endog']).any():
        MNlogit_margeff = MNlogit_margeff.reset_index(level = 'endog')

    if endog_categories is None:
        endog_categories = MNlogit_margeff['endog'].unique()

    # gazer 関数で扱えるように列名を修正します。
    MNlogit_margeff = MNlogit_margeff.rename(columns = {
            'Std. Err.':'std_err',
            'z':'statistics',
            'Pr(>|z|)':'p_value',
            'Conf. Int. Low':'conf_lower',
            'Cont. Int. Hi.':'conf_higher'
            }
    )

    list_gazer = list(map(
        lambda categ : gazer(
        MNlogit_margeff.query('endog == @categ'),
        estimate = 'dy/dx',
        **kwargs
        ),
        endog_categories
        ))

    endog_categories2 = [i.split('[')[1].split(']')[0] for i in endog_categories]

    # # flm_total.keys() で回帰式を作成したときに設定したモデル名を抽出し、列名にします。
    res = pd.concat(dict(zip(list(endog_categories2), list_gazer)), axis = 'columns')\
        .droplevel(1, axis = 'columns') # 列名が2重に設定されるので、これを削除して1つにします。

    return res

"""## 回帰係数の線型結合に関するに関するt検定"""

def lincomb(model, const_mat, beta_H0 = 0, alpha = 0.05, stars = False, pct_change = False):
    '''回帰係数の線型結合に関するに関するt検定'''
    from scipy.stats import t

    const_mat = np.array(const_mat)

    beta = model.params

    vcov = model.cov_params()

    t_alpha = t.isf(alpha / 2, df = model.df_resid)

    estimate = pd.Series(np.dot(const_mat, beta)) # 回帰係数の線型結合を計算

    vars = const_mat @ vcov @ const_mat.T # 回帰係数の分散


    se_beta = pd.Series(np.sqrt(vars))

    t_value = (estimate - beta_H0) / se_beta

    res = pd.DataFrame({
        'estimate':estimate,
        'std_err':se_beta,
        'statistics':t_value,
        'p_value': 2 * t.sf(abs(t_value), df = model.df_resid),
        'conf_lower':estimate - t_alpha * se_beta,
        'conf_higher':estimate + t_alpha * se_beta
    }, index = range(len(estimate)))

    if pct_change:
        res['estimate'] = log_to_pct(res['estimate'])
        res['conf_lower'] = log_to_pct(res['conf_lower'])
        res['conf_higher'] = log_to_pct(res['conf_higher'])

    if stars:
        res['stars'] = p_stars(res['p_value'])

    return res

def lincomb_test(model, const_mat, beta_H0 = 0, alpha = 0.05, stars = False, pct_change = False):
    # const_mat がデータフレームとして与えられたときの処理
    if(isinstance(const_mat, pd.DataFrame)):
        const_list = const_mat.columns

        res_list = [
            lincomb(
                model, const_mat[idx],
                beta_H0 = beta_H0, alpha = alpha,
                stars = stars, pct_change = pct_change
                )
            for idx in const_list
            ]
        res_df = pd.concat(res_list)
        res_df.index = const_list

    elif(isinstance(const_mat, pd.Series) or isinstance(const_mat, list)):
        res_df = lincomb(
                model, const_mat,
                beta_H0 = beta_H0, alpha = alpha,
                stars = stars, pct_change = pct_change
                )
    else:
        sys.exit('const_matには pd.DataFrame, pd.Series もしくはリストを指定してください')


    return res_df

"""# $F$検定による回帰モデルの比較

- `restriction`：制約モデル。`statsmodels.ols()` などで作成されたモデルオブジェクト
- `full`：フルモデル。`statsmodels.ols()` などで作成されたモデルオブジェクト
"""

from scipy.stats import f
def F_test_lm(restriction, full):
    q = restriction.df_resid - full.df_resid
    F_val = ((restriction.ssr - full.ssr) / q) / full.mse_resid

    p_value = f.sf(F_val, dfn = q , dfd = full.df_resid)

    res_df = pd.DataFrame({
        'df_resid':[restriction.df_resid, full.df_resid],
        'RSS':[restriction.ssr, full.ssr],
        'DF':[np.nan, int(q)],
        'statistics': [np.nan, F_val],
        'p_value': [np.nan, p_value]
    }, index = ['restriction', 'full'])

    res_df[['df_resid', 'DF']] = res_df[['df_resid', 'DF']].astype(pd.Int64Dtype())

    res_df.index.name = "model"

    return res_df

"""## `reg.compare_mfx()`

"""

def tidy_mfx(mod, at = 'overall', method = 'dydx', dummy = False, conf_level = 0.95, **kwargs):
  # 引数に妥当な値が指定されているかを検証
  at = bild.arg_match(at, ['overall', 'mean', 'median', 'zero'], arg_name = 'at')

  method = bild.arg_match(
      method,
      choices = ['coef', 'dydx', 'eyex', 'dyex', 'eydx'],
      arg_name = 'method'
      )
  # 限界効果の推定
  est_margeff = mod.get_margeff(dummy = dummy, at = at, method = method, **kwargs)
  tab = est_margeff.summary_frame()

  method_dict = {
            'coef':'coef',
            'dydx':'dy/dx',
            'eyex':'d(lny)/d(lnx)',
            'dyex':'dy/d(lnx)',
            'eydx':'d(lny)/dx',
        }

  tab = tab.rename(columns = {
            method_dict[method]:method,
            'Std. Err.':'std_err',
            'z':'statistics',
            'Pr(>|z|)':'p_value',
            'Conf. Int. Low':'conf_lower',
            'Cont. Int. Hi.':'conf_higher'
            })

  # conf_level に 0.95 以外の値が指定されていた場合は、信頼区間を個別に推定して値を書き換えます。
  if(conf_level != 0.95):
    CI = est_margeff.conf_int(alpha = 1 - conf_level)
    tab['conf_lower'] = CI[:, 0]
    tab['conf_higher'] = CI[:, 1]

  return tab


# 複数のロジットモデルを比較する表を作成する関数
def compare_mfx(
    list_models,
    model_name = None,
    subset = None,
    stats = 'std_err',
    add_stars = True,
    at = 'overall',
    method = 'dydx',
    dummy = False,
    digits = 4,
    table_style = 'two_line',
    line_break = '\n',
    **kwargs
    ):
    assert isinstance(list_models, list), 'list_models is must be a list of models.'
    # 限界効果の推定-------------
    if method == 'coef':
        tidy_list = [tidy(mod) for mod in list_models]
    else:
        tidy_list = [
            tidy_mfx(mod, at = at, method = method, dummy = dummy)
            for mod in list_models
            ]

    # モデル名が指定されていない場合、連番を作成する
    if model_name is None:
        model_name = [f'model {i + 1}' for i in range(len(tidy_list))]

    # lineup_models() を適用してモデルを比較する表を作成
    res = lineup_models(
        tidy_list,
        model_name = model_name,
        digits = digits,
        stats = stats,
        add_stars = add_stars,
        table_style = table_style,
        estimate = method,
        line_break = line_break,
        **kwargs
        )

    # 表の下部にモデルの当てはまりに関する統計値を追加
    res.loc['prsquared', :] = [mod.prsquared.round(digits) for mod in list_models]
    res.loc['nobs', :] = [mod.nobs for mod in list_models]
    res.loc['df', :] = [int(mod.df_model) for mod in list_models]

    res.index.name = 'term'

    return res

# 回帰分析の結果から回帰係数のグラフを作成する関数 --------
def mfxplot(
    mod,
    subset = None,
    conf_level = [0.95, 0.99],
    at = 'overall',
    method = 'dydx',
    dummy = False,
    palette = ['#1b69af', '#629CE7'],
    show_Intercept = False,
    show_vline = True,
    ax = None,
    **kwargs
    ):
    '''model object から回帰係数のグラフを作成する関数'''
    # 回帰係数の表を抽出
    tidy_ci_high = tidy_mfx(
        mod, at = at, method = method, dummy = dummy, conf_level = conf_level[0]
        )
    tidy_ci_row =  tidy_mfx(
        mod, at = at, method = method, dummy = dummy, conf_level = conf_level[1]
        )

    # subset が指定されていれば、回帰係数の部分集合を抽出する
    if subset is not None:
        tidy_ci_high = tidy_ci_high.loc[subset, :]
        tidy_ci_row = tidy_ci_row.loc[subset, :]

    # グラフの作成
    coef_dot(
        tidy_ci_high, tidy_ci_row, estimate = method, palette = palette,
        show_Intercept = show_Intercept, show_vline = show_vline,
        ax = ax, **kwargs
        )
