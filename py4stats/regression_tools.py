# -*- coding: utf-8 -*-
"""regression_tools.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1toh4Gqspni3ApwQUZgfOXg2wjHK8sI1l

# `reg_tools`：回帰分析の結果を要約する関数群
"""

# 依存するライブラリーの読込
import pandas as pd
import numpy as np
import scipy as sp
from scipy.stats import t
from scipy.stats import f
from functools import singledispatch
import matplotlib.pyplot as plt

import seaborn as sns
import matplotlib.pyplot as plt

import statsmodels.api as sm
import statsmodels.formula.api as smf

import sys

import argparse

def match_arg(value, choices):
    """
    Simulates the functionality of R's match.arg() function with partial matching in Python.

    Args:
    - value: The value to match against the choices (partially).
    - choices: List of valid choices.

    Returns:
    - The matched value if found in choices (partially), otherwise raises an ArgumentError.
    """
    matches = [c for c in choices if value.lower() in c.lower()]
    if len(matches) == 1:
        return matches[0]
    elif len(matches) > 1:
        raise ValueError(f"Ambiguous value: '{value}'. Matches multiple choices: {', '.join(matches)}.")
    else:
        # raise ValueError(f"No match found for value: '{value}'.")
        raise argparse.ArgumentTypeError(f"Invalid choice: '{value}'. Should be one of: {', '.join(choices)}.")

"""## 回帰分析の結果をデータフレームに変換する関数"""

from statsmodels.iolib.summary import summary_params_frame
from scipy.stats import t

# definition of tidy --------------------------------------------------
def tidy(fit, alpha = 0.05, to_jp = False, add_one_sided = False, name_of_term = None):

    tidied = summary_params_frame(fit, alpha = alpha, xname = name_of_term)

    tidied.index.name = 'term'

    rename_cols = {
        'std err':'std_err',
        't':'statistics', 'P>|t|': 'p_value',
        'Conf. Int. Low': 'conf_lower',
        'Conf. Int. Upp.': 'conf_higher'
    }

    tidied = tidied.rename(columns = rename_cols)

    if add_one_sided:
        tidied = add_one_sided_p_value(fit, tidied)

    # 列名を日本語に変換
    if to_jp:
        tidied = tidy_to_jp(tidied, alpha = alpha)

    return tidied


def tidy_to_jp(tidied, alpha = 0.05):
    tidied = tidied\
       .rename(columns = {
           'term':'説明変数',
           'coef':'回帰係数', 'std_err':'標準誤差',
           'statistics':'t-値', 'p_value':'p-値',
           'conf_lower': str(int((1-alpha)*100)) + '%信頼区間下側',
           'conf_higher': str(int((1-alpha)*100)) + '%信頼区間上側',
           'one_sided_p_value':'片側p-値'
           })

    tidied.index.name = '説明変数'

    return tidied

def add_one_sided_p_value(fit, tidied):
        tidied['one_sided_p_value'] = t.sf(abs(tidied['statistics']), fit.df_resid)
        return tidied

# `tidy_heckit()` の旧バージョン-------------------------
def tidy_heckit(fit, name_of_term = [], alpha = 0.05, to_jp = False, add_one_sided = False):
    tidied = pd.DataFrame({
        'coef':fit.params,
        'std_err':fit.bse,
        'statistics':fit.tvalues,
        'p_value':fit.pvalues,
        'conf_lower':fit.conf_int(alpha = alpha)[:, 0],
        'conf_higher':fit.conf_int(alpha = alpha)[:, 1]
        }
    )

    if add_one_sided:
        tidied = add_one_sided_p_value(fit, tidied)

    if(len(name_of_term) > 0):
        tidied['term'] = name_of_term
        tidied = tidied.set_index('term')

    # 列名を日本語に変換
    if to_jp:
        tidied = tidy_to_jp(tidied, alpha = alpha)

    return  tidied

def glance(fit_lm):
    res = pd.DataFrame({
        'rsquared':fit_lm.rsquared,
        'rsquared_adj':fit_lm.rsquared_adj,
        'nobs':int(fit_lm.nobs),
        'df':int(fit_lm.df_model),
        'sigma':np.sqrt(fit_lm.mse_resid),
        'F_values':fit_lm.fvalue,
        'p_values':fit_lm.f_pvalue,
        'AIC':fit_lm.aic,
        'BIC':fit_lm.bic
    }, index = [0])
    return res

def glance_jp(fit_lm):
    res = pd.DataFrame({
        'サンプルサイズ':int(fit_lm.nobs),
        'モデルの自由度':int(fit_lm.df_model),
        '自由度調整済み決定係数':fit_lm.rsquared_adj,
        'モデルMSE':fit_lm.mse_model,
        '残差MSE':fit_lm.mse_resid,
        'F値':fit_lm.fvalue,
        'F検定のp-値':fit_lm.f_pvalue
    }, index = [0])
    return res

def est_pct_change(est): return 100 * (np.exp(est) - 1)

# 有意性を表すアスタリスクを作成する関数
def p_stars(p_value):
    stars = np.where(p_value <= 0.1, ' *', '')
    stars = np.where(p_value <= 0.05, ' **', stars)
    stars = np.where(p_value <= 0.01, ' ***', stars)
    return stars

def pad_z(s, digits = 4):
    s = str(s)
    # もし s が整数値なら、何もしない。
    if s.find('.') != -1:
        s_digits = len(s[s.find('.'):])
        s = s + '0' * (digits + 1 - s_digits)
    return s

pad_zero = np.vectorize(pad_z, excluded = 'digits')

"""## `reg.compare_ols()`

### 概要

　`reg.compare_ols()` は計量経済学の実証論文でよく用いられる、回帰分析の結果を縦方向に並べて比較する表をする関数です。
　使用方法は次の通りで、`sm.ols()` や `smf.ols()` で作成した分析結果のオブジェクトのリストを代入します。  

```python
penguins = load_penguins() # サンプルデータの読み込み

fit1 = smf.ols('body_mass_g ~ bill_length_mm + species', data = penguins).fit()
fit2 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species', data = penguins).fit()
fit3 = smf.ols('body_mass_g ~ bill_length_mm + bill_depth_mm + species + sex', data = penguins).fit()

compare_tab1 = reg.compare_ols([fit1, fit2, fit3])
compare_tab1
```

### 引数

　`reg.compare_ols()` 関数では必要に応じて表の体裁を調整できるようにしています。`reg.compare_ols()` 関数に指定できる引数は次の通りです。

- `list_models`：推定結果を表示する分析結果のリスト。`sm.ols()` や `smf.ols()` で作成された回帰分析の結果を `list_models = [fit1, fit2]` のような形で指定してください。
- `model_name`：表頭に表示するモデルの名前。`['モデル1', 'モデル2']` のように文字列のリストを指定してください。何もしていされなければ、自動的に `model 1, model 2, model 3 …` と連番が振られます。
- `stats`：表中の() 内に表示する統計値の設定。次の値が指定できます（部分一致可）。
    - `'p_value'` p-値（初期設定）
    - `'std_err'` 標準誤差
    - `'statistics'` t統計量

- `add_stars`：回帰係数の統計的有意性を表すアスタリスク `*` を表示するかどうかを表すブール値。`add_stars = True`（初期設定）なら表示、`add_stars = False`なら非表示となります。`table_style` に `'two_line'` を指定した場合はアスタリスクは回帰係数の直後に表示され、`'one_line'` を指定した場合は統計値の後に表示されます。アスタリスクはp-値の値に応じて次のように表示されます。
    - p ≤ 0.1 `*`
    - p ≤ 0.05 `**`
    - p ≤ 0.01 `***`
    - p > 0.1 表示なし

- `digits`：回帰係数と統計値について表示する小数点以下の桁数。初期設定は4です。
- `table_style`：表の書式設定。次の値から選択できます（部分一致可）。
    - `'two_line'`回帰係数と統計値を2行に分ける（初期設定）
    - `'one_line'`回帰係数と統計値を1行で表示する

- `stats_glance`：表の下部に追加する回帰モデル全体に関する統計値の種類を表す文字列のリスト。初期設定は `['rsquared_adj', 'nobs', 'df']`。リストの値には次の値を指定できます（部分一致可）。
    - `'rsquared'`：決定係数
    - `'rsquared_adj'`：自由度調整済み決定係数
    - `'nobs'`：サインプルサイズ
    - `'df'`：モデルの自由度（説明変数の数）
    - `'sigma'`：回帰式の標準誤差
    - `'F_values'`：全ての回帰係数がゼロであることを帰無仮説とするF検定の統計量
    - `'p_values'`：F検定のP-値
    - `'AIC'`：赤池情報量基準
    - `'BIC'`：ベイズ情報量基準

　**注意**：pandas データフレームとしの表示では、`table_style = 'two_line'` としたときの回帰係数とp-値の間の改行が、改行記号「\n」が表示されますが、Excel ファイルとして保存すると、正しくセル内での改行として扱われます。

### 論文での利用方法

　 `reg.compare_ols()` の出力は pandas データフレームです。そのため `.to_excel()` メソッドでExcel ファイルとして保存でき、そこから Word へ貼り付けると良いと思います。
"""

# 複数のモデルを比較する表を作成する関数
def compare_ols(
    list_models, model_name = None,
    digits = 4, stats = 'std_err', add_stars = True,
    table_style = 'two_line',
    stats_glance = ['rsquared_adj', 'nobs', 'df'],
    **kwargs
    ):
    tidy_list = [tidy(mod) for mod in list_models]

    # モデル名が指定されていない場合、連番を作成する
    if model_name is None:
        model_name = [f'model {i + 1}' for i in range(len(tidy_list))]

    # lineup_models() を適用してモデルを比較する表を作成
    res = lineup_models(
            tidy_list, model_name = model_name,
            digits = digits, stats = stats,
            add_stars = add_stars, table_style = table_style,
            **kwargs
        )

    # 表の下部にモデルの当てはまりに関する統計値を追加
    if len(stats_glance) > 0: # もし stats_glance が空のリストなら統計値を追加しない
    # 引数に妥当な値が指定されているかを検証
        choices = ['rsquared', 'rsquared_adj', 'nobs', 'df', 'sigma', 'F_values', 'p_values', 'AIC', 'BIC']
        stats_glance = [match_arg(stats, choices) for stats in stats_glance]

        res2 = pd.concat([glance(mod) for mod in list_models])\
            .loc[:, stats_glance].round(digits)\
            .apply(pad_zero, digits = digits).T

        res2.columns = model_name
        res = pd.concat([res, res2])

    res.index.name = 'term'

    return res

# 複数のモデルを比較する表を作成する関数 対象を sm.ols() に限定しないバージョン
def lineup_models(tidy_list, model_name = None, **kwargs):

    # モデル名が指定されていない場合、連番を作成する
    if model_name is None:
        model_name = [f'model {i + 1}' for i in range(len(tidy_list))]

    # tidy_list の各要素に gazer() 関数を適用
    list_gazer = [gazer(df, **kwargs) for df in tidy_list]

    # model_name が列名になるように、辞書の key に設定してから pd.concat() で結合
    res = pd.concat(dict(zip(model_name, list_gazer)), axis = 'columns')\
        .droplevel(1, axis = 'columns') # 列名が2重に設定されるので、これを削除して1つにします。

    # モデルで使用されていない変数について NaN が発生するので、空白で置き換えます。
    res = res.fillna('')

    return res

# 回帰係数と検定統計量を縦に並べる関数
# 2024年1月30日変更 引数 stats と table_style について
# 妥当な値が指定されているかを検証する機能を追加しました。
def gazer(
    res_tidy, estimate = 'coef', stats = 'std_err',
    digits = 4, add_stars = True, style_p = False, p_min = 0.01,
    table_style = 'two_line', line_break = '\n'
    ):

    # 引数に妥当な値が指定されているかを検証
    stats = match_arg(stats, ['std_err', 'statistics', 'p_value', 'conf_lower', 'conf_higher'])
    table_style = match_arg(table_style, ['two_line', 'one_line'])

    # --------------------
    res = res_tidy.copy()
    res['stars'] = p_stars(res['p_value'])

    res[[estimate, stats]] = res[[estimate, stats]].round(digits).astype(str)\
        .apply(pad_zero, digits = digits)

    res[estimate] = pad_zero(res[estimate], digits)
    res[stats] = pad_zero(res[stats], digits)


    if (stats == 'p_value') & style_p:
        res['p_val'] = res['p_value']

        res['p_value'] = np.where(
            res['p_val'] < p_min,
            f'p < {p_min}',
            res['p_value']
            )
    # # table_style に応じて改行とアスタリスクを追加する
    if(table_style == 'two_line'):
        sep = line_break
        if add_stars:
            sep = res['stars'] + sep

        sufix = ''

    elif(table_style == 'one_line'):
        sep = ''
        if add_stars:
            sufix = res['stars']
        else:
            sufix = ''

    res['value'] = res[estimate] + sep + '(' + res[stats] + ')' + sufix

    # モデルで使用されていない変数について NaN が発生するので、空白で置き換えます。
    res = res.fillna('')

    return res[['value']]

"""### `gazer()` 関数の多項ロジットモデルバージョン"""

def gazer_MNlogit(MNlogit_margeff, endog_categories = None, **kwargs):

    if ~pd.Series(MNlogit_margeff.columns).isin(['endog']).any():
        MNlogit_margeff = MNlogit_margeff.reset_index(level = 'endog')

    if endog_categories is None:
        endog_categories = MNlogit_margeff['endog'].unique()

    # gazer 関数で扱えるように列名を修正します。
    MNlogit_margeff = MNlogit_margeff.rename(columns = {
            'Std. Err.':'std_err',
            'z':'statistics',
            'Pr(>|z|)':'p_value',
            'Conf. Int. Low':'conf_lower',
            'Cont. Int. Hi.':'conf_higher'
            }
    )

    list_gazer = list(map(
        lambda categ : gazer(
        MNlogit_margeff.query('endog == @categ'),
        estimate = 'dy/dx',
        **kwargs
        ),
        endog_categories
        ))

    endog_categories2 = [i.split('[')[1].split(']')[0] for i in endog_categories]

    # # flm_total.keys() で回帰式を作成したときに設定したモデル名を抽出し、列名にします。
    res = pd.concat(dict(zip(list(endog_categories2), list_gazer)), axis = 'columns')\
        .droplevel(1, axis = 'columns') # 列名が2重に設定されるので、これを削除して1つにします。

    return res

"""## 回帰係数の視覚化関数

　`coefplot()` 関数は次のように使用できます。

```python
coefplot(fit1) # 回帰係数の視覚化
```

　グラフ上の縦軸が説明変数、横軸回帰係数の値です。点が回帰係数の推定値を、エラーバー（横棒）が信頼区間を表し、β = 0 を帰無仮説とする仮説検定の結果によって有意であれば青色に、有意でなければグレーに色分けされます。`coefplot_dot()` 関数の引数は次の通りです。

- `mod`：statsmodelsで作成した回帰分析の結果。

以下の引数は指定しなくても使用できます。

- `subset`：グラフに回帰係数を表示する説明変数のリスト。指定しなければモデルに含まれる全ての説明変数を使用します。また `subset` を指定することで、表内での回帰係数の並び順を調整できます。
- `alpha`：信頼区間と有意性による色分けに使う有意水準。初期設定は5％です。
- `palette`：グラフに使用する色。{True:'有意な回帰係数の色',  False:'有意ではない回帰係数の色'} の形で定義された辞書オブジェクトで指定します。グラフ上の垂直線は有意ではない回帰係数の色で描画されます。
- `show_Intercept`：切片の係数を表示するかどうか。True だと切片の係数を表示し、False（初期設定）だと表示しません。
- `show_vline`：回帰係数 = 0 の垂直線を表示するかどうか。True （初期設定）を指定すると垂直線を表示し、False を指定すると表示されません。
- `ax`：matplotlib の ax オブジェクト。複数のグラフを並べる場合などに使用します。

　基本的な使用方法は次のとおりです。グラフ上の点が回帰係数の推定値を、エラーバー（横棒）が信頼区間を表します。β = 0 を帰無仮説とする仮説検定の結果が有意であれば青色に、有意でなければグレーに色分けされます。

### 色の変更と説明変数の指定

グラフで使用する色と表示する説明変数は次のように指定することができます。


```python
# カラーパレット
my_pal = {
    True:'#FF6F91',  # 統計的に有意な回帰係数の色
    False:'#D3C8CA'  # 統計的に有意ではない回帰係数の色
          }


# 表示する説明変数
var_list = [
    'sex[T.male]', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm',
    'C(year)[T.2008]', 'C(year)[T.2009]'
    ]

coefplot(fit1, subset = var_list, palette = my_pal);
plt.xlabel(f'回帰係数(n = {int(fit1.nobs)})'); # x軸ラベルにサンプルサイズを表示
```
"""

# 利用するライブラリー
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import japanize_matplotlib #日本語化matplotlib
from statsmodels.iolib.summary import summary_params_frame

# 回帰分析の結果から回帰係数のグラフを作成する関数 --------
def coefplot(mod, subset = None, alpha = [0.05, 0.01], palette = ['#1b69af', '#629CE7'], **kwargs):
    '''model object から回帰係数のグラフを作成する関数'''

    # 回帰係数の表を抽出
    tidy_ci_high = tidy(mod, alpha = alpha[0])
    tidy_ci_row = tidy(mod, alpha = alpha[1])

    # subset が指定されていれば、回帰係数の部分集合を抽出する
    if subset is not None:
        tidy_ci_high = tidy_ci_high.loc[subset, :]
        tidy_ci_row = tidy_ci_row.loc[subset, :]

    # グラフの作成
    coef_dot(tidy_ci_high, tidy_ci_row, palette = palette, **kwargs)


def coef_dot(
    tidy_ci_high, tidy_ci_low, ax = None, show_Intercept = False,
    palette = ['#1b69af', '#629CE7'], show_vline = True,
    estimate = 'coef', conf_lower = 'conf_lower', conf_higher = 'conf_higher',
    ):
    '''tidy_talbe から回帰係数のグラフを作成する関数'''
    tidy_ci_high = tidy_ci_high.copy()
    tidy_ci_low = tidy_ci_low.copy()


    # 切片項を除外する
    if not show_Intercept:
        tidy_ci_high = tidy_ci_high.loc[~ tidy_ci_high.index.isin(['Intercept']), :]
        tidy_ci_low = tidy_ci_low.loc[~ tidy_ci_low.index.isin(['Intercept']), :]


    if ax is None:
        fig, ax = plt.subplots()

    # 図の描画 -----------------------------
    # 垂直線の描画
    if show_vline:
        ax.axvline(0, ls = "--", color = '#969696')

    # エラーバーの作図
    ax.hlines(
        y = tidy_ci_low.index, xmin = tidy_ci_low[conf_lower], xmax = tidy_ci_low[conf_higher],
        linewidth = 1.5,
        color = palette[1]
    )
    ax.hlines(
        y = tidy_ci_high.index, xmin = tidy_ci_high[conf_lower], xmax = tidy_ci_high[conf_higher],
        linewidth = 3,
        color = palette[0]
    )

    # 回帰係数の推定値を表す点の作図
    sns.scatterplot(
        data = tidy_ci_high, x = estimate, y = tidy_ci_high.index,
        palette = palette[0],
        s = 85,
        ax = ax
    );
    ax.set_ylabel('');

"""## 回帰係数の線型結合に関するに関するt検定"""

def lincomb(model, const_mat, beta_H0 = 0, alpha = 0.05, stars = False, pct_change = False):
    '''回帰係数の線型結合に関するに関するt検定'''
    from scipy.stats import t

    const_mat = np.array(const_mat)

    beta = model.params

    vcov = model.cov_params()

    t_alpha = t.isf(alpha / 2, df = model.df_resid)

    estimate = pd.Series(np.dot(const_mat, beta)) # 回帰係数の線型結合を計算

    vars = const_mat @ vcov @ const_mat.T # 回帰係数の分散


    se_beta = pd.Series(np.sqrt(vars))

    t_value = (estimate - beta_H0) / se_beta

    res = pd.DataFrame({
        'estimate':estimate,
        'std_err':se_beta,
        'statistics':t_value,
        'p_value': 2 * t.sf(abs(t_value), df = model.df_resid),
        'conf_lower':estimate - t_alpha * se_beta,
        'conf_higher':estimate + t_alpha * se_beta
    }, index = range(len(estimate)))

    if pct_change:
        res['estimate'] = est_pct_change(res['estimate'])
        res['conf_lower'] = est_pct_change(res['conf_lower'])
        res['conf_higher'] = est_pct_change(res['conf_higher'])

    if stars:
        res['stars'] = p_stars(res['p_value'])

    return res

def lincomb_test(model, const_mat, beta_H0 = 0, alpha = 0.05, stars = False, pct_change = False):
    # const_mat がデータフレームとして与えられたときの処理
    if(isinstance(const_mat, pd.DataFrame)):
        const_list = const_mat.columns

        res_list = [
            lincomb(
                model, const_mat[idx],
                beta_H0 = beta_H0, alpha = alpha,
                stars = stars, pct_change = pct_change
                )
            for idx in const_list
            ]
        res_df = pd.concat(res_list)
        res_df.index = const_list

    elif(isinstance(const_mat, pd.Series) or isinstance(const_mat, list)):
        res_df = lincomb(
                model, const_mat,
                beta_H0 = beta_H0, alpha = alpha,
                stars = stars, pct_change = pct_change
                )
    else:
        sys.exit('const_matには pd.DataFrame, pd.Series, もしくはリストを指定してください')


    return res_df

"""# $F$検定による回帰モデルの比較

- `mod_restriction`：制約モデル。`statsmodels.ols()` などで作成されたモデルオブジェクト
- `mod_full`：フルモデル。`statsmodels.ols()` などで作成されたモデルオブジェクト
"""

from scipy.stats import f
def F_test_lm(mod_restriction, mod_full):
    q = mod_restriction.df_resid - mod_full.df_resid
    F_val = ((mod_restriction.ssr - mod_full.ssr) / q) / mod_full.mse_resid

    p_value = f.sf(F_val, dfn = q , dfd = mod_full.df_resid)

    res_df = pd.DataFrame({
        'df_resid':[mod_restriction.df_resid, mod_full.df_resid],
        'RSS':[mod_restriction.ssr, mod_full.ssr],
        'DF':[np.nan, int(q)],
        'statistics': [np.nan, F_val],
        'p_value': [np.nan, p_value]
    }, index = ['restriction', 'full'])

    res_df[['df_resid', 'DF']] = res_df[['df_resid', 'DF']].astype(pd.Int64Dtype())

    res_df.index.name = "model"

    return res_df

"""## `reg.compare_mfx()`

### 概要

　`reg.compare_mfx()` は計量経済学の実証論文でよく用いられる、回帰分析の結果を縦方向に並べて比較する表をする関数です。
　使用方法は次の通りで、`smf.logit()` や `smf.probit()` で作成した分析結果のオブジェクトのリストを代入します。  


### 引数

　　`reg.compare_mfx()` 関数に指定できる引数は次の通りです。

- `list_models`：推定結果を表示する分析結果のリスト。`sm.ols()` や `smf.ols()` で作成された回帰分析の結果を `list_models = [fit1, fit2]` のような形で指定してください。
- `model_name`：表頭に表示するモデルの名前。`['モデル1', 'モデル2']` のように文字列のリストを指定してください。何もしていされなければ、自動的に `model 1, model 2, model 3 …` と連番が振られます。
- `stats`：表中の( ) 内に表示する統計値の設定。次の値を指定できます（部分一致可）。
    - `'p_value'` p-値（初期設定）
    - `'std_err'` 標準誤差
    - `'statistics'` t統計量

- `add_stars`：回帰係数の統計的有意性を表すアスタリスク `*` を表示するかどうかを表すブール値。`add_stars = True`（初期設定）なら表示、`add_stars = False`なら非表示となります。`table_style` に `'two_line'` を指定した場合はアスタリスクは回帰係数の直後に表示され、`'one_line'` を指定した場合は統計値の後に表示されます。アスタリスクはp-値の値に応じて次のように表示されます。
    - p ≤ 0.1 `*`
    - p ≤ 0.05 `**`
    - p ≤ 0.01 `***`
    - p > 0.1 表示なし

- `digits`：回帰係数と統計値について表示する小数点以下の桁数。初期設定は4です。
- `table_style`：表の書式設定。次の値から選択できます（部分一致可）。
    - `'two_line'`回帰係数と統計値を2行に分ける（初期設定）
    - `'one_line'`回帰係数と統計値を1行で表示する


- `at`：限界効果の集計方法。基本的には[`statsmodels.discrete.discrete_model.DiscreteResults.get_margeff()`](https://www.statsmodels.org/devel/generated/statsmodels.discrete.discrete_model.DiscreteResults.get_margeff.html)の引数 `at` と同様に次の値を指定できます。ただし、`method = 'coef'` を指定した場合、この引数は無視されます（部分一致可）。
    - `'overall'`：各観測値の限界効果の平均値を表示（初期設定）
    - `'mean'`：各説明変数の平均値における限界効果を表示
    - `'median'`：各説明変数の中央値における限界効果を表示
    - `'zero'`：各説明変数の値がゼロであるときの限界効果を表示

- `method`：表中に表示する推定値の種類。次の値を指定でき、`'coef'` なら回帰係数の推定値がそのままま表示され、それ以外なら限界効果の推定値が表示されます。基本的には[`statsmodels.discrete.discrete_model.DiscreteResults.get_margeff()`](https://www.statsmodels.org/devel/generated/statsmodels.discrete.discrete_model.DiscreteResults.get_margeff.html)の引数 `method` と同様です。
    - `'coef'`：回帰係数の推定値を表示
    - `'dydx'`：限界効果の値を変換なしでそのまま表。（初期設定）
    - `'eyex'`：弾力性 d(lny)/d(lnx) の推定値を表示
    - `'dyex'`：準弾力性 dy /d(lnx) の推定値を表示
    - `'eydx'`：準弾力性 d(lny)/dx の推定値を表
"""

def tidy_mfx(mod, at = 'overall', method = 'dydx', dummy = False):
  # 引数に妥当な値が指定されているかを検証
  at = match_arg(at, ['overall', 'mean', 'median', 'zero'])
  method = match_arg(method, ['coef', 'dydx', 'eyex', 'dyex', 'eydx'])

  tab = mod.get_margeff(dummy = dummy, at = at, method = method).summary_frame()

  method_dict = {
            'coef':'coef',
            'dydx':'dy/dx',
            'eyex':'d(lny)/d(lnx)',
            'dyex':'dy/d(lnx)',
            'eydx':'d(lny)/dx',
        }


  tab = tab.rename(columns = {
            method_dict[method]:method,
            'Std. Err.':'std_err',
            'z':'statistics',
            'Pr(>|z|)':'p_value',
            'Conf. Int. Low':'conf_lower',
            'Cont. Int. Hi.':'conf_higher'
            })
  return tab


# 複数のロジットモデルを比較する表を作成する関数
def compare_mfx(
    list_models, model_name = None,
    digits = 4, stats = 'std_err', add_stars = True,
    table_style = 'two_line',
    # stats_glance = ['rsquared_adj', 'nobs', 'df'],
    at = 'overall',
    method = 'dydx',
    dummy = False,
    **kwargs
    ):
    # 引数に妥当な値が指定されているかを検証
    at = match_arg(at, ['overall', 'mean', 'median', 'zero'])
    method = match_arg(method, ['coef', 'dydx', 'eyex', 'dyex', 'eydx'])

    # 限界効果の推定-------------
    if method == 'coef':
        tidy_list = [tidy(mod) for mod in list_models]
    else:
        tidy_list = [tidy_mfx(mod) for mod in list_models]

    # モデル名が指定されていない場合、連番を作成する
    if model_name is None:
        model_name = [f'model {i + 1}' for i in range(len(tidy_list))]

    # lineup_models() を適用してモデルを比較する表を作成
    res = lineup_models(
        tidy_list,
        model_name = model_name,
        digits = digits,
        stats = stats,
        add_stars = add_stars,
        table_style = table_style,
        estimate = method,
        **kwargs
        )

    # 表の下部にモデルの当てはまりに関する統計値を追加
    res.loc['prsquared', :] = [mod.prsquared.round(digits) for mod in list_models]
    res.loc['nobs', :] = [mod.nobs for mod in list_models]
    res.loc['df', :] = [int(mod.df_model) for mod in list_models]

    res.index.name = 'term'

    return res

# 限界効果の推定結果グラフを作成する関数 --------
def mfxplot(
    mod, subset = None, show_vline = True,
    palette = {True:'#1b69af', False:'#969696'}, ax = None, alpha = 0.05,
    at = 'overall', method = 'dydx', dummy = False, p_value = 'p_value',
    conf_lower = 'conf_lower', conf_higher = 'conf_higher',

    ):
    '''model object から回帰係数のグラフを作成する関数'''

    # 回帰係数の表を抽出
    tidy_table = tidy_mfx(mod, at = at, method = method, dummy = dummy)

    # subset が指定されていれば、回帰係数の部分集合を抽出する
    if subset is not None:
        tidy_ci_high = tidy_ci_high.loc[subset, :]
        tidy_ci_row = tidy_ci_row.loc[subset, :]

        tidy_table = tidy_table.copy()

    # 有意性による色分けを設定する -----------------------------
    threshold = f'p <= {100 * alpha:.2g}%' # 凡例のラベルを作成

    tidy_table[threshold] = tidy_table[p_value] <= alpha

    tidy_table['.color'] = np.where(tidy_table[threshold], palette[True], palette[False])

    if ax is None:
        fig, ax = plt.subplots()

    # 図の描画 -----------------------------
    # 垂直線の描画
    if show_vline:
        ax.axvline(0, ls = "--", color = palette[False])
   # エラーバーの作図
    ax.hlines(
        y = tidy_table.index, xmin = tidy_table[conf_lower], xmax = tidy_table[conf_higher],
        linewidth = 3, color = tidy_table['.color']
    )

    # 回帰係数の推定値を表す点の作図
    sns.scatterplot(
        data = tidy_table, x = method, y = tidy_table.index,
        hue = tidy_table[threshold], palette = palette, s = 85,
        ax = ax
    );
    ax.set_ylabel('');
